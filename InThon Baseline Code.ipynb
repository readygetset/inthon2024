{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"db111d3dd0dd48cb9112f4eb22dfecdc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74a5282434a247cd9151e453cac73b86","IPY_MODEL_79c5eef141ec47aeb419ae05432e3625","IPY_MODEL_ece7969f88e148feb060c3bf8ac22629"],"layout":"IPY_MODEL_42f63c988c304bbdad5625fe07713e39"}},"74a5282434a247cd9151e453cac73b86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1fb2833b50f464c929dafff7e104367","placeholder":"​","style":"IPY_MODEL_1602fab013644431bc909743f16deca3","value":"preprocessor_config.json: 100%"}},"79c5eef141ec47aeb419ae05432e3625":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a7b431cca34487ab18987e3a9ebed06","max":439,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6077267836bd4a67a007a37927a58f6f","value":439}},"ece7969f88e148feb060c3bf8ac22629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5e9fe874fdf40f5b9421e217ab66681","placeholder":"​","style":"IPY_MODEL_cb189c811ef04dfe865491e55a4faa7b","value":" 439/439 [00:00&lt;00:00, 33.3kB/s]"}},"42f63c988c304bbdad5625fe07713e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1fb2833b50f464c929dafff7e104367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1602fab013644431bc909743f16deca3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a7b431cca34487ab18987e3a9ebed06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6077267836bd4a67a007a37927a58f6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5e9fe874fdf40f5b9421e217ab66681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb189c811ef04dfe865491e55a4faa7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08d2808a665d4933bbf831ba94012408":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ccecfbc91174a67b1a2611239b29199","IPY_MODEL_59bb010300a043c286a1a239824c2282","IPY_MODEL_a423e1cc867040738b970058a9ab1e99"],"layout":"IPY_MODEL_50b7b93103b64b089b4905487074e56d"}},"4ccecfbc91174a67b1a2611239b29199":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db0dc8045e044ef6bea4ab78cd4925b3","placeholder":"​","style":"IPY_MODEL_1dd3cb9993ee419592ed7f6b407bfb42","value":"tokenizer_config.json: 100%"}},"59bb010300a043c286a1a239824c2282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea15178c11114f599895f93a8216718d","max":2424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38ce839e07ba44ea9ecfecf70279af23","value":2424}},"a423e1cc867040738b970058a9ab1e99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75c32c9653734f9e9ce3b5154cfcd1d7","placeholder":"​","style":"IPY_MODEL_a56778756b554570a1dfe812d9ef1b13","value":" 2.42k/2.42k [00:00&lt;00:00, 192kB/s]"}},"50b7b93103b64b089b4905487074e56d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db0dc8045e044ef6bea4ab78cd4925b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd3cb9993ee419592ed7f6b407bfb42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea15178c11114f599895f93a8216718d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38ce839e07ba44ea9ecfecf70279af23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75c32c9653734f9e9ce3b5154cfcd1d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a56778756b554570a1dfe812d9ef1b13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b402682389554b7ea37410923496dbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc1ffc697da841cf80e9e0ababaa6728","IPY_MODEL_5ad961356c3e4d79ab2eee256ad58204","IPY_MODEL_93073219d7704ce88affae10aee28965"],"layout":"IPY_MODEL_48928f38c87a43128390390d8dbe8b35"}},"fc1ffc697da841cf80e9e0ababaa6728":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abab3188e1bd4f109aae362e14a1903d","placeholder":"​","style":"IPY_MODEL_fa14cd485e764ec0ae8a6ccc8adb9219","value":"spiece.model: 100%"}},"5ad961356c3e4d79ab2eee256ad58204":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43de9aa7b5694753a3c5bb3cba8fb456","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a91f0290db44d2b9eb7f3edce1e8c35","value":791656}},"93073219d7704ce88affae10aee28965":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d21d7d23dbf4693854808a1b2f66f60","placeholder":"​","style":"IPY_MODEL_2d31552d52144bc58ad7763a8a115ad8","value":" 792k/792k [00:00&lt;00:00, 23.2MB/s]"}},"48928f38c87a43128390390d8dbe8b35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abab3188e1bd4f109aae362e14a1903d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa14cd485e764ec0ae8a6ccc8adb9219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43de9aa7b5694753a3c5bb3cba8fb456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a91f0290db44d2b9eb7f3edce1e8c35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d21d7d23dbf4693854808a1b2f66f60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d31552d52144bc58ad7763a8a115ad8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3139421478844b55bd13d0a41f197714":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d1c89bf31114883a7e71720b3ba3700","IPY_MODEL_af7a98878f5e4a0e9a82db76800da556","IPY_MODEL_bdedd613ab4d40ffa5092ccc15c5ecff"],"layout":"IPY_MODEL_406d231ae4ad4785b220a00ada4b5e9e"}},"3d1c89bf31114883a7e71720b3ba3700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0f79c31c83f48e2ab70a2efae2e499b","placeholder":"​","style":"IPY_MODEL_c34f3c6fae99432484c18fcc3fbfe631","value":"tokenizer.json: 100%"}},"af7a98878f5e4a0e9a82db76800da556":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d645f46a4b4b6ab59deb73bdea021d","max":2422164,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bffbdb1deb2946aa9ebdd3c07478c1ef","value":2422164}},"bdedd613ab4d40ffa5092ccc15c5ecff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33f159e1bf84187ac4fef6249dfc82a","placeholder":"​","style":"IPY_MODEL_ee3e70fb21964830ab9439e1edb2163b","value":" 2.42M/2.42M [00:01&lt;00:00, 2.28MB/s]"}},"406d231ae4ad4785b220a00ada4b5e9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0f79c31c83f48e2ab70a2efae2e499b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c34f3c6fae99432484c18fcc3fbfe631":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65d645f46a4b4b6ab59deb73bdea021d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bffbdb1deb2946aa9ebdd3c07478c1ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d33f159e1bf84187ac4fef6249dfc82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee3e70fb21964830ab9439e1edb2163b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8dcdad20f1b4f789aee274dca4d8885":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a8666e4199e44df94f0b288867d9afc","IPY_MODEL_4add21c5ff0a4aa181e46fcf435923f5","IPY_MODEL_2c2bd33e495b4cc7a87935e60c110d09"],"layout":"IPY_MODEL_cc41e145c5994fe3990dcd221128bd1c"}},"2a8666e4199e44df94f0b288867d9afc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f1ba05e71424e0fbed60a22fc9a4486","placeholder":"​","style":"IPY_MODEL_522d3233663d4bba81ab91e5e841c04c","value":"special_tokens_map.json: 100%"}},"4add21c5ff0a4aa181e46fcf435923f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_841f891da6c94afe8597984660d7f854","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1a480d596964dcdaf266f99a47504b3","value":2201}},"2c2bd33e495b4cc7a87935e60c110d09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2270b956230f4856a1e6d94684d16ffe","placeholder":"​","style":"IPY_MODEL_dab0f5bca5154b57a35eff593be6d8b9","value":" 2.20k/2.20k [00:00&lt;00:00, 188kB/s]"}},"cc41e145c5994fe3990dcd221128bd1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f1ba05e71424e0fbed60a22fc9a4486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"522d3233663d4bba81ab91e5e841c04c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"841f891da6c94afe8597984660d7f854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1a480d596964dcdaf266f99a47504b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2270b956230f4856a1e6d94684d16ffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dab0f5bca5154b57a35eff593be6d8b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eee23a4354b4dd59850941345c42a8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d344b1d228a54fdfb85fd74263eecbf9","IPY_MODEL_d81e94b25a5e4d4d9880b242e245bb79","IPY_MODEL_d1bbeaf7d01a4fee95a1782713cb8a13"],"layout":"IPY_MODEL_08ef53cbc47646d6b939c353c2f2109d"}},"d344b1d228a54fdfb85fd74263eecbf9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a56d44f2e374174bc000db454ec8e5f","placeholder":"​","style":"IPY_MODEL_23727b8c101e4aa0ad51910612c6e86e","value":"qformer_tokenizer/tokenizer_config.json: 100%"}},"d81e94b25a5e4d4d9880b242e245bb79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7d18704f424496fa2c4168cf5d50579","max":343,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d15e42b89a36467580802f9d30b754f5","value":343}},"d1bbeaf7d01a4fee95a1782713cb8a13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc63af7872944316b3365e8dccb10fa9","placeholder":"​","style":"IPY_MODEL_aa06f0dd84414fbca0dc6128168cf27f","value":" 343/343 [00:00&lt;00:00, 25.8kB/s]"}},"08ef53cbc47646d6b939c353c2f2109d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a56d44f2e374174bc000db454ec8e5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23727b8c101e4aa0ad51910612c6e86e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7d18704f424496fa2c4168cf5d50579":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15e42b89a36467580802f9d30b754f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc63af7872944316b3365e8dccb10fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa06f0dd84414fbca0dc6128168cf27f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98e59a64118a4c7aa32c6c815ca6d688":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b71062d84d5486293dc99b9cef16a28","IPY_MODEL_8db8e172019242ea8525f8b4d3a81c11","IPY_MODEL_507a03ea56594615987405be8f662a78"],"layout":"IPY_MODEL_31d12b20326b4fda9cccc48f0d3adba2"}},"9b71062d84d5486293dc99b9cef16a28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_769a5d8e564e4ce4bf39a0737f753c02","placeholder":"​","style":"IPY_MODEL_6bc18f94a25f49a8905c971189c29a36","value":"qformer_tokenizer/vocab.txt: 100%"}},"8db8e172019242ea8525f8b4d3a81c11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1c22586814140be9cda1c9945f49dc3","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dceb8b52372c4a4380b17679bf4b4001","value":231508}},"507a03ea56594615987405be8f662a78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0abe5d03ef24f18ab86295be49cfa2b","placeholder":"​","style":"IPY_MODEL_c569e0bf87f24f09bbdeafb3d7781746","value":" 232k/232k [00:00&lt;00:00, 497kB/s]"}},"31d12b20326b4fda9cccc48f0d3adba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"769a5d8e564e4ce4bf39a0737f753c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc18f94a25f49a8905c971189c29a36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1c22586814140be9cda1c9945f49dc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dceb8b52372c4a4380b17679bf4b4001":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0abe5d03ef24f18ab86295be49cfa2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c569e0bf87f24f09bbdeafb3d7781746":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f18835c4b2b4c3dae5d931b6ec927ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6730bd35717d48c0971c5bc67fdde57f","IPY_MODEL_20547eef0ffb41278b60a867547cdfd7","IPY_MODEL_2c0e891d5b4647be8fda95c16c04f749"],"layout":"IPY_MODEL_654c8087e6fa44cfaf3d895c7c9736ae"}},"6730bd35717d48c0971c5bc67fdde57f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f54a2cc3ba8447c85b0abedc4cab4ac","placeholder":"​","style":"IPY_MODEL_fece712be89141c0926c7c12d2d8e8eb","value":"qformer_tokenizer/tokenizer.json: 100%"}},"20547eef0ffb41278b60a867547cdfd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b594e7624364f5ea15aeddbcf35e16c","max":711577,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f83c40e2c2474ff19038d719e2695dea","value":711577}},"2c0e891d5b4647be8fda95c16c04f749":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_734c5843f9694a1194be3bb497cd6089","placeholder":"​","style":"IPY_MODEL_bd0259458db147ef931778af4a0b8879","value":" 712k/712k [00:00&lt;00:00, 1.07MB/s]"}},"654c8087e6fa44cfaf3d895c7c9736ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f54a2cc3ba8447c85b0abedc4cab4ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fece712be89141c0926c7c12d2d8e8eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b594e7624364f5ea15aeddbcf35e16c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83c40e2c2474ff19038d719e2695dea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"734c5843f9694a1194be3bb497cd6089":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd0259458db147ef931778af4a0b8879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f1a1d0a9dec471897601f91f1b68515":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68d735a0c89744d5b036b7b2d27fb05f","IPY_MODEL_c587f6b5f61a4b1bb6b18b2b718a0cec","IPY_MODEL_06c4838600c840b5a499823e459d4845"],"layout":"IPY_MODEL_9328a9ff78144b9fa0a5cd33dfa21c89"}},"68d735a0c89744d5b036b7b2d27fb05f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f47f8c1abe634dbda510d17828c23308","placeholder":"​","style":"IPY_MODEL_b1fab137a20f4a6eafd103c859cd0d33","value":"qformer_tokenizer/added_tokens.json: 100%"}},"c587f6b5f61a4b1bb6b18b2b718a0cec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef84276507794f8094c54adde0975487","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a545161f4714ef2838f301c0b29b595","value":21}},"06c4838600c840b5a499823e459d4845":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9f7b93b07524120bca4fc14c9d9d43a","placeholder":"​","style":"IPY_MODEL_6c82308d10be450aa65035401ceb48d8","value":" 21.0/21.0 [00:00&lt;00:00, 1.33kB/s]"}},"9328a9ff78144b9fa0a5cd33dfa21c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47f8c1abe634dbda510d17828c23308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1fab137a20f4a6eafd103c859cd0d33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef84276507794f8094c54adde0975487":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a545161f4714ef2838f301c0b29b595":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9f7b93b07524120bca4fc14c9d9d43a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c82308d10be450aa65035401ceb48d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ebbb7c6220842eeae402e77925f089f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a89ffa4874fb4eb4821cc7365ce70317","IPY_MODEL_1e04859105804a4ba758cf7331f54f07","IPY_MODEL_5855f87646c1454eb460462eefdc92f1"],"layout":"IPY_MODEL_91e85f7903674b21b888e82d101e4b17"}},"a89ffa4874fb4eb4821cc7365ce70317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e302ac6902834f40b7a2bc63e9b43815","placeholder":"​","style":"IPY_MODEL_52d5834b0afc404bae9d6056eb751e2e","value":"(…)former_tokenizer/special_tokens_map.json: 100%"}},"1e04859105804a4ba758cf7331f54f07":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46d97dfc169d43ada374b3fb4563deac","max":149,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d204839deba84f119fdb26947cc60404","value":149}},"5855f87646c1454eb460462eefdc92f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdd605b8c639432a8380d24298479768","placeholder":"​","style":"IPY_MODEL_8cf1a9f5ed1b49928a9fb0cae343a4b0","value":" 149/149 [00:00&lt;00:00, 12.1kB/s]"}},"91e85f7903674b21b888e82d101e4b17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e302ac6902834f40b7a2bc63e9b43815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52d5834b0afc404bae9d6056eb751e2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46d97dfc169d43ada374b3fb4563deac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d204839deba84f119fdb26947cc60404":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdd605b8c639432a8380d24298479768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cf1a9f5ed1b49928a9fb0cae343a4b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b538258aca1c41319b712ad6bc13bc43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7052f10491ce4e57b1b59214e1e8d642","IPY_MODEL_f1d0b0716951496d8a1a239edacc0adc","IPY_MODEL_77b0d437d3804788967a74c8163b5d47"],"layout":"IPY_MODEL_6590cc01d1e44178a8e6b58e18a4e1a6"}},"7052f10491ce4e57b1b59214e1e8d642":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d0a212f07ad49df9bd0d0215f1c3ea6","placeholder":"​","style":"IPY_MODEL_5b22e956e88d42a8976e7df39d9c1b8f","value":"config.json: 100%"}},"f1d0b0716951496d8a1a239edacc0adc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e73557eb7264e8c8c3f82a0ebe1f446","max":7743,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cddf09307cac40689d09dd7430b23ad2","value":7743}},"77b0d437d3804788967a74c8163b5d47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8015aa19d1d94435922f9ec1b63a6d18","placeholder":"​","style":"IPY_MODEL_db21b7dfc1f04f438671b96657b37781","value":" 7.74k/7.74k [00:00&lt;00:00, 613kB/s]"}},"6590cc01d1e44178a8e6b58e18a4e1a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d0a212f07ad49df9bd0d0215f1c3ea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b22e956e88d42a8976e7df39d9c1b8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e73557eb7264e8c8c3f82a0ebe1f446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cddf09307cac40689d09dd7430b23ad2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8015aa19d1d94435922f9ec1b63a6d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db21b7dfc1f04f438671b96657b37781":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca6d66edbae04f1aa7b77a3023bcb31b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c511cf095bb945bf81b69c3a7fd0a276","IPY_MODEL_7dca5a6ef4834e8b8be68a77f50e9ed4","IPY_MODEL_bdf0fae6e820480f9c7b27081ba36ca5"],"layout":"IPY_MODEL_067eef1705e8441999258f7e68c80c98"}},"c511cf095bb945bf81b69c3a7fd0a276":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b4ec2312734e61a99cbaf13c03c71f","placeholder":"​","style":"IPY_MODEL_f3a2425df9984b41bf9983e1ff3256da","value":"model.safetensors.index.json: 100%"}},"7dca5a6ef4834e8b8be68a77f50e9ed4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a00e855f41264beaaf2e00461fcf90d1","max":140252,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fcd1170341e45c8ac1c4a1a898d784d","value":140252}},"bdf0fae6e820480f9c7b27081ba36ca5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f89c54046412485fa1253445dd81a077","placeholder":"​","style":"IPY_MODEL_d79ad805a39e4a91a1f13d4ad353e9ef","value":" 140k/140k [00:00&lt;00:00, 8.35MB/s]"}},"067eef1705e8441999258f7e68c80c98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b4ec2312734e61a99cbaf13c03c71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3a2425df9984b41bf9983e1ff3256da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a00e855f41264beaaf2e00461fcf90d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fcd1170341e45c8ac1c4a1a898d784d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f89c54046412485fa1253445dd81a077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79ad805a39e4a91a1f13d4ad353e9ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8ff6f238c524498bcfcdbb2c26a3bcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0bc25af276f42c09188e67207d7d5d0","IPY_MODEL_94388a85f2274b4cabd9ed2d19036474","IPY_MODEL_58656470ba764406878d5d983819b8fd"],"layout":"IPY_MODEL_a89017e6ea614924971e5c2d85939dc5"}},"a0bc25af276f42c09188e67207d7d5d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a54923bf964251b1181e4ea866ef84","placeholder":"​","style":"IPY_MODEL_e60d36ec3a2f41a0a3566d0f143b62b4","value":"Downloading shards: 100%"}},"94388a85f2274b4cabd9ed2d19036474":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac16d3a4e06743c0aa2b7dae43601669","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bdafdceded945218847371bf9502631","value":2}},"58656470ba764406878d5d983819b8fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23803356b62041d28460249720551bcf","placeholder":"​","style":"IPY_MODEL_929f4ff1faef40d68b207c522b95ad62","value":" 2/2 [01:16&lt;00:00, 36.78s/it]"}},"a89017e6ea614924971e5c2d85939dc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0a54923bf964251b1181e4ea866ef84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e60d36ec3a2f41a0a3566d0f143b62b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac16d3a4e06743c0aa2b7dae43601669":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bdafdceded945218847371bf9502631":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23803356b62041d28460249720551bcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929f4ff1faef40d68b207c522b95ad62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c808c1db491461790149b5835d0492a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b2842fba053443490d6c3c94fddc363","IPY_MODEL_76122504b69445968737aa5175b22c7b","IPY_MODEL_a363edcc3ffc4f988d375cc7df2766da"],"layout":"IPY_MODEL_362eac9a5c064c11b69baa21c5b27eb0"}},"9b2842fba053443490d6c3c94fddc363":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eee1aa3003204ba08d00721cf19d62d9","placeholder":"​","style":"IPY_MODEL_f932a08e91174222bc0414e4b1ae1998","value":"model-00001-of-00002.safetensors: 100%"}},"76122504b69445968737aa5175b22c7b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17bcf1ffaa4d49c1980db634c175acfa","max":9981404928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3849d9ce5e7742b3a8c2afaf800da258","value":9981404928}},"a363edcc3ffc4f988d375cc7df2766da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b2fc9158d604fcc928adcfcf3bab0c0","placeholder":"​","style":"IPY_MODEL_327662f998b745ba8036b1bfdd95aeeb","value":" 9.98G/9.98G [00:46&lt;00:00, 210MB/s]"}},"362eac9a5c064c11b69baa21c5b27eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee1aa3003204ba08d00721cf19d62d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f932a08e91174222bc0414e4b1ae1998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17bcf1ffaa4d49c1980db634c175acfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3849d9ce5e7742b3a8c2afaf800da258":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b2fc9158d604fcc928adcfcf3bab0c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"327662f998b745ba8036b1bfdd95aeeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dced97c0177d474fae4a26802a45d8dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_717615aa85cd4dc0b437d033ef8d255c","IPY_MODEL_68eef7fa0d844270966af2b84d4767d8","IPY_MODEL_40395b5420f94321888a58da10785e8b"],"layout":"IPY_MODEL_b12eac363f9443a0bf9a928ac5d2fdf0"}},"717615aa85cd4dc0b437d033ef8d255c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e5a091275dd4cd3b3227bd0787611de","placeholder":"​","style":"IPY_MODEL_a5a9e45c20b54ec684faf45832d9d059","value":"model-00002-of-00002.safetensors: 100%"}},"68eef7fa0d844270966af2b84d4767d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8749803f977b4d8895e5d64f1714b16b","max":6110652864,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f44c1d61e814bf6bac95a6e5e790cb3","value":6110652864}},"40395b5420f94321888a58da10785e8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cdf4e39a3e24db9a74ff18f6f182255","placeholder":"​","style":"IPY_MODEL_2106a1d4a0604d72890755d812e01322","value":" 6.11G/6.11G [00:29&lt;00:00, 235MB/s]"}},"b12eac363f9443a0bf9a928ac5d2fdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e5a091275dd4cd3b3227bd0787611de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a9e45c20b54ec684faf45832d9d059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8749803f977b4d8895e5d64f1714b16b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f44c1d61e814bf6bac95a6e5e790cb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4cdf4e39a3e24db9a74ff18f6f182255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2106a1d4a0604d72890755d812e01322":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe7e4e8b88f64bc8b374ec182392c0eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a22c98d7ff4e4e7b8e8925f197be4b49","IPY_MODEL_65692348428e43ecbea5dcbe939d5319","IPY_MODEL_7fbe7937335f4607a8eb140763e031c1"],"layout":"IPY_MODEL_dee7188bc321496c95953a8517a6218e"}},"a22c98d7ff4e4e7b8e8925f197be4b49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02bfecd04744698b09d65df601459b6","placeholder":"​","style":"IPY_MODEL_d8548435405f4168871a90c880f3b65d","value":"Loading checkpoint shards: 100%"}},"65692348428e43ecbea5dcbe939d5319":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65a4f442146b475aa7f04ec338ada80d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43dcdccaef7e415abb5a70fb2330b515","value":2}},"7fbe7937335f4607a8eb140763e031c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede99a634f40476bba77e9f56ef3130c","placeholder":"​","style":"IPY_MODEL_f38ab94029ec434b847a2a1b2f2d00d3","value":" 2/2 [00:04&lt;00:00,  2.25s/it]"}},"dee7188bc321496c95953a8517a6218e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02bfecd04744698b09d65df601459b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8548435405f4168871a90c880f3b65d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65a4f442146b475aa7f04ec338ada80d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43dcdccaef7e415abb5a70fb2330b515":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ede99a634f40476bba77e9f56ef3130c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f38ab94029ec434b847a2a1b2f2d00d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45ab943b65da4c589af68ea8a7300240":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99775743652148399d977b6676380252","IPY_MODEL_17d725e60ffc4a7daf6124a646d48606","IPY_MODEL_94d4b2eb39e34949ba847aff64d0d210"],"layout":"IPY_MODEL_c8925c5744424139a528e6339010106e"}},"99775743652148399d977b6676380252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_741fcdc1801743d6a2cfdb4f9f3bc2a7","placeholder":"​","style":"IPY_MODEL_aa6a9266359b47609445edc09c769d39","value":"config.json: 100%"}},"17d725e60ffc4a7daf6124a646d48606":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6c9f8554a944b7885e89188e9418847","max":4186,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0afb5ddfaf9a4d1d8013d75d5e7318b0","value":4186}},"94d4b2eb39e34949ba847aff64d0d210":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd9de7381db54669b295c4f3403c01d8","placeholder":"​","style":"IPY_MODEL_4f6292585a35414d9dc70d55e43c653a","value":" 4.19k/4.19k [00:00&lt;00:00, 333kB/s]"}},"c8925c5744424139a528e6339010106e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"741fcdc1801743d6a2cfdb4f9f3bc2a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa6a9266359b47609445edc09c769d39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6c9f8554a944b7885e89188e9418847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0afb5ddfaf9a4d1d8013d75d5e7318b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd9de7381db54669b295c4f3403c01d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f6292585a35414d9dc70d55e43c653a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"851acae8bdee4488bf5ee8a8dc4ac48c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17c00bb9e5714958a3da2909f6291db0","IPY_MODEL_176a302b07ef4ea8910ac02c1dd2022a","IPY_MODEL_f7d480b879f34dcab2baa19147bf5785"],"layout":"IPY_MODEL_0c9bfb3d86d8461582e62f0ba7481974"}},"17c00bb9e5714958a3da2909f6291db0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8c98f19d39c464392d617cc26c6afed","placeholder":"​","style":"IPY_MODEL_5240b5c61e0e48a5a9f98762e8485b93","value":"pytorch_model.bin: 100%"}},"176a302b07ef4ea8910ac02c1dd2022a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a2bcb86f6e4a27808dfc3533eea4d0","max":605247071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4dde289fce2417da3c0072f61c4fd5b","value":605247071}},"f7d480b879f34dcab2baa19147bf5785":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94b2cf3933a9492b812f96a1ca83e758","placeholder":"​","style":"IPY_MODEL_9aa4a57077fb416bbc7080a56618d0db","value":" 605M/605M [00:02&lt;00:00, 194MB/s]"}},"0c9bfb3d86d8461582e62f0ba7481974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8c98f19d39c464392d617cc26c6afed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5240b5c61e0e48a5a9f98762e8485b93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03a2bcb86f6e4a27808dfc3533eea4d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4dde289fce2417da3c0072f61c4fd5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94b2cf3933a9492b812f96a1ca83e758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa4a57077fb416bbc7080a56618d0db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51d91bf6aed54064b6bc8bb6f2986cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_549ee42eee5d4cf1ba40028d7e358fba","IPY_MODEL_0b685c2d613f49cc90e064f2da509b7d","IPY_MODEL_20d4f1caf6b04bf49c40971c29ba38a2"],"layout":"IPY_MODEL_b8c6e1c340a24abdbbb8e9c70f9356e0"}},"549ee42eee5d4cf1ba40028d7e358fba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad5bb27a29bd4c11b07fceb7b1a1a144","placeholder":"​","style":"IPY_MODEL_839d1d370a3b4b389c9388aa40567d2f","value":"preprocessor_config.json: 100%"}},"0b685c2d613f49cc90e064f2da509b7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0981b2d1072c4d7080f54e11083f107f","max":316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1ef901dffe44e2f90aef04c3d9ff227","value":316}},"20d4f1caf6b04bf49c40971c29ba38a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a942da0cf44492ead62003d9648a3c6","placeholder":"​","style":"IPY_MODEL_6e143360a7e04774b64cae65d109c618","value":" 316/316 [00:00&lt;00:00, 28.2kB/s]"}},"b8c6e1c340a24abdbbb8e9c70f9356e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad5bb27a29bd4c11b07fceb7b1a1a144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"839d1d370a3b4b389c9388aa40567d2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0981b2d1072c4d7080f54e11083f107f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ef901dffe44e2f90aef04c3d9ff227":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a942da0cf44492ead62003d9648a3c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e143360a7e04774b64cae65d109c618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ce4638005484627a0d9061ecd0dc489":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6560c72cadd340299defd1036941a295","IPY_MODEL_5303ab8805244e27a062d849c2ff219f","IPY_MODEL_6014125b23914301b0cb051bf50064d8"],"layout":"IPY_MODEL_dad3744ea7934aa4841590ffbdc27223"}},"6560c72cadd340299defd1036941a295":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84248ef7f7744b559e3b7570a30fe26a","placeholder":"​","style":"IPY_MODEL_b15c4ae8ab2f47a0aa55827b9c46b73f","value":"tokenizer_config.json: 100%"}},"5303ab8805244e27a062d849c2ff219f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0848fba6740a428b95b883c345c70df1","max":592,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6396b4176b1b451abb6bd90cb8e305ae","value":592}},"6014125b23914301b0cb051bf50064d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4b0623e31aa4c3198299eeb81a45be8","placeholder":"​","style":"IPY_MODEL_a633333a21dc41f0a566e59ea37d22dc","value":" 592/592 [00:00&lt;00:00, 51.0kB/s]"}},"dad3744ea7934aa4841590ffbdc27223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84248ef7f7744b559e3b7570a30fe26a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15c4ae8ab2f47a0aa55827b9c46b73f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0848fba6740a428b95b883c345c70df1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6396b4176b1b451abb6bd90cb8e305ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4b0623e31aa4c3198299eeb81a45be8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a633333a21dc41f0a566e59ea37d22dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd1698916bb44852b0aa82cde1c49e8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdfbaa7d1d734b68abce234fa2fe03e4","IPY_MODEL_d49b439af7af4157be0acb64040fa780","IPY_MODEL_5e0ffb7c8d48496f88e4a51d12e2dd44"],"layout":"IPY_MODEL_d0768f0121fa4d2fb8bf807395c8b1e2"}},"fdfbaa7d1d734b68abce234fa2fe03e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_784eb7a88644417d88ac082658c940a7","placeholder":"​","style":"IPY_MODEL_abfb996b5a674757a055814c5652aa16","value":"vocab.json: 100%"}},"d49b439af7af4157be0acb64040fa780":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_190a993dfec84fa9b8a9ad73fa3fb0a0","max":862328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf69cd44b20f423483d709c6dce2a0e9","value":862328}},"5e0ffb7c8d48496f88e4a51d12e2dd44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_839cb52704aa43fdacd6fda62c17eec2","placeholder":"​","style":"IPY_MODEL_4af50359562a4f9b9e53f38dd4f29a85","value":" 862k/862k [00:00&lt;00:00, 1.02MB/s]"}},"d0768f0121fa4d2fb8bf807395c8b1e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"784eb7a88644417d88ac082658c940a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abfb996b5a674757a055814c5652aa16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"190a993dfec84fa9b8a9ad73fa3fb0a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf69cd44b20f423483d709c6dce2a0e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"839cb52704aa43fdacd6fda62c17eec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4af50359562a4f9b9e53f38dd4f29a85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f06c1e2d049543619f73cef84368b276":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7710fe20a764e57b450022813b0711d","IPY_MODEL_00b1e7a3f6714bc68b1c22ca22538496","IPY_MODEL_64a7cfdb8bb54b4b8b0b4127a1176610"],"layout":"IPY_MODEL_c99f1557728141c9916b1302dab59f38"}},"e7710fe20a764e57b450022813b0711d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2072220aece142e18e1b7b06abe6ec57","placeholder":"​","style":"IPY_MODEL_70a4491f1db1459789cff72336f0ea5b","value":"merges.txt: 100%"}},"00b1e7a3f6714bc68b1c22ca22538496":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72263af83be445058fb089f7b143148a","max":524657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efa0c8c5ab0c43449666f1f99542e200","value":524657}},"64a7cfdb8bb54b4b8b0b4127a1176610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa724c65a44473a9c310214bf825d52","placeholder":"​","style":"IPY_MODEL_a78b3ec7b73e4777b646e77fe913dba8","value":" 525k/525k [00:00&lt;00:00, 763kB/s]"}},"c99f1557728141c9916b1302dab59f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2072220aece142e18e1b7b06abe6ec57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70a4491f1db1459789cff72336f0ea5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72263af83be445058fb089f7b143148a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efa0c8c5ab0c43449666f1f99542e200":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fa724c65a44473a9c310214bf825d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a78b3ec7b73e4777b646e77fe913dba8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"991efcb219f74207a898c3510198e12b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5320ffe4c60f44b68c686077aef39712","IPY_MODEL_59352a463b7046de852de0210c38489c","IPY_MODEL_f823e2b8faa145b9b8295cd7bbd4d963"],"layout":"IPY_MODEL_390fc5399ef04b85998ff5d5025f8bec"}},"5320ffe4c60f44b68c686077aef39712":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_376c320effc04f4c96348f88e68b28d5","placeholder":"​","style":"IPY_MODEL_a48e1e7ce45d4c8089de03f92ab80e3a","value":"tokenizer.json: 100%"}},"59352a463b7046de852de0210c38489c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c290fae9ac2a4bc6832dfbec72909178","max":2224041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d96ec60add0346fdbf4c3dba0157e58a","value":2224041}},"f823e2b8faa145b9b8295cd7bbd4d963":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a712bf350df84a3bba696ca16655d379","placeholder":"​","style":"IPY_MODEL_0b3216eda1be469f9a5173dbd1196cc8","value":" 2.22M/2.22M [00:00&lt;00:00, 4.85MB/s]"}},"390fc5399ef04b85998ff5d5025f8bec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"376c320effc04f4c96348f88e68b28d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a48e1e7ce45d4c8089de03f92ab80e3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c290fae9ac2a4bc6832dfbec72909178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d96ec60add0346fdbf4c3dba0157e58a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a712bf350df84a3bba696ca16655d379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b3216eda1be469f9a5173dbd1196cc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b63be9fc9e844a3aaf364ab77290bd8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88892d5ee18841dd8b1018f9f0600f5b","IPY_MODEL_f636c702707b4e7ea0858c460df05da8","IPY_MODEL_85d87b4089a44daaa7592606e07a3f8f"],"layout":"IPY_MODEL_c4c6767545e14964a505beb403230ab8"}},"88892d5ee18841dd8b1018f9f0600f5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_977b8d771d5b44afbaa7356386647599","placeholder":"​","style":"IPY_MODEL_86bd943773fc44c490922f306777f43a","value":"special_tokens_map.json: 100%"}},"f636c702707b4e7ea0858c460df05da8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b516a25612ea40bcaafb09a39fd5af3d","max":389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4667abd8cb274a37ad16d5a871a26245","value":389}},"85d87b4089a44daaa7592606e07a3f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d40a0c50334b9ebf6ce34a12f842d8","placeholder":"​","style":"IPY_MODEL_6a5efa5def894b65a4c6bdd46d485fa1","value":" 389/389 [00:00&lt;00:00, 35.7kB/s]"}},"c4c6767545e14964a505beb403230ab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977b8d771d5b44afbaa7356386647599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86bd943773fc44c490922f306777f43a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b516a25612ea40bcaafb09a39fd5af3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4667abd8cb274a37ad16d5a871a26245":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85d40a0c50334b9ebf6ce34a12f842d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5efa5def894b65a4c6bdd46d485fa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PmYTVHFIqym","executionInfo":{"status":"ok","timestamp":1731126313193,"user_tz":-540,"elapsed":22114,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"a23f8609-9fcc-4618-da62-1251d63fb2f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# InThon Baseline Code"],"metadata":{"id":"nSpyBik--bLw"}},{"cell_type":"markdown","source":["## 1. 라이브러리 설치\n","필요한 라이브러리를 설치합니다.\n","\n","먼저, 이 코드는 Hugging Face의 `peft`(Parameter-Efficient Fine-Tuning) 라이브러리를 활용하여 모델 파인튜닝을 합니다. 이를 통해 큰 모델을 메모리 효율적으로 파인튜닝할 수 있습니다. `bitsandbytes`는 모델을 저비트 수 형식(예: 4비트)으로 변환하여 메모리 사용량을 줄입니다."],"metadata":{"id":"44Og9skt-hdd"}},{"cell_type":"code","source":["!pip install -q git+https://github.com/huggingface/peft.git transformers bitsandbytes datasets\n","!pip install git+https://github.com/salaniz/pycocoevalcap\n","\n","import torch\n","from PIL import Image\n","import requests\n","from transformers import Blip2Processor, Blip2ForConditionalGeneration, InstructBlipProcessor, InstructBlipForConditionalGeneration, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from torch.utils.data import DataLoader"],"metadata":{"id":"eNnfFxl-diRP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731126291088,"user_tz":-540,"elapsed":48806,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"596283d4-4c4b-4550-b3ea-1c6ebc768139"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mCollecting git+https://github.com/salaniz/pycocoevalcap\n","  Cloning https://github.com/salaniz/pycocoevalcap to /tmp/pip-req-build-_zum6z3g\n","  Running command git clone --filter=blob:none --quiet https://github.com/salaniz/pycocoevalcap /tmp/pip-req-build-_zum6z3g\n","  Resolved https://github.com/salaniz/pycocoevalcap to commit a24f74c408c918f1f4ec34e9514bc8a76ce41ffd\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap==1.2) (2.0.8)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap==1.2) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap==1.2) (1.16.0)\n","Building wheels for collected packages: pycocoevalcap\n","  Building wheel for pycocoevalcap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocoevalcap: filename=pycocoevalcap-1.2-py3-none-any.whl size=104312245 sha256=c531672b6b511611106e70bbd1a5d3e5e5e89f57ee1ce48d0e2ea9c80340238b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-lk23ka4g/wheels/43/54/73/3e2c6d4ace7657958cde52ac6fd47b342cd4aae5a7aa4fcbf9\n","Successfully built pycocoevalcap\n","Installing collected packages: pycocoevalcap\n","Successfully installed pycocoevalcap-1.2\n"]}]},{"cell_type":"markdown","source":["## 2. 환경 및 디바이스 설정\n","**PyTorch**와 **CUDA**를 사용하여 훈련에 사용할 디바이스를 확인합니다.\n","\n","여기서 `torch.device`를 통해 모델을 `cuda`(GPU)에서 실행할지 `cpu`에서 실행할지를 결정합니다. GPU는 병렬 연산을 빠르게 처리할 수 있기 때문에, 가능하면 GPU를 사용하는 것이 학습 속도에 유리합니다."],"metadata":{"id":"ff8z4SvR-kqR"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"사용 중인 디바이스: {device}\")"],"metadata":{"id":"JKwRbavGdkTR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731126313194,"user_tz":-540,"elapsed":9,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"26735e95-ae87-4aae-ce50-40ffbb61e700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["사용 중인 디바이스: cuda\n"]}]},{"cell_type":"markdown","source":["## 3. 모델 및 프로세서 설정\n","`BitsAndBytesConfig`를 사용하여 4비트 양자화를 설정하고, `Blip2Processor`와 `Blip2ForConditionalGeneration`을 설정합니다.\n","\n","일반적으로 모델 파라미터는 32비트로 저장되지만, 이를 4비트로 줄이면 메모리 사용량이 크게 감소합니다. `Blip2Processor`는 이미지와 텍스트를 같이 처리하는 프로세서로, 입력 데이터를 모델이 이해할 수 있는 형태로 변환해 줍니다.\n","\n","### 양자화 (Quantization)\n","**4비트, 8비트 양자화**는 모델의 각 숫자(파라미터)를 4비트로 저장하여 메모리를 절약하는 방법입니다. 모델의 성능에 약간의 손실이 있을 수 있지만, 많은 경우 큰 차이가 없습니다.\n","\n","#### 양자화 원리\n","양자화는 부동소수점 수(floating point)로 표현된 파라미터를 더 적은 비트의 정수(integer)로 근사하여 표현하는 방식입니다. 이때, 수의 범위가 줄어들기 때문에 정밀도가 다소 감소할 수 있지만, 모델의 효율성은 크게 향상됩니다.\n","\n","1. **연속 값에서 이산 값으로 변환**:\n","   주어진 범위 내에서 연속적인 값들을 정해진 개수의 **이산 값(discrete values)**으로 변환합니다. 예를 들어, 4비트 양자화에서는 $2^4 = 16$개의 이산 값으로 모든 파라미터 값을 근사하게 됩니다.\n","\n","2. **스케일링 (Scaling)**:\n","   원래의 실수 값 $x$를 정수 값 $q$로 변환하기 위해, 스케일링 인자 $s$와 오프셋 $z$를 사용하여 양자화를 수행합니다. 변환 수식은 다음과 같습니다.\n","\n","   $$\n","   q = \\text{round}\\left(\\frac{x}{s} + z\\right)\n","   $$\n","\n","   여기서:\n","   - $s$는 스케일링 인자(양자화된 값의 크기를 조절).\n","   - $z$는 오프셋 값으로, 일반적으로 0이나 양자화 범위의 중앙값으로 설정됩니다.\n","   - $\\text{round}$는 반올림 함수로, 실수 값을 가장 가까운 정수 값으로 변환합니다.\n","\n","3. **복원 (Dequantization)**:\n","   양자화된 값을 다시 원래의 값에 가깝게 복원하려면 다음과 같은 복원식을 사용합니다.\n","\n","   $$\n","   x \\approx s \\cdot (q - z)\n","   $$\n","\n","   이를 통해 양자화된 정수 값을 부동소수점 값으로 다시 근사할 수 있으며, 복원된 값은 원래 값과 약간의 차이가 있을 수 있지만, 모델 성능에 큰 영향을 주지 않도록 설계합니다.\n","\n","4. **정밀도와 메모리 효율의 균형**:\n","   양자화는 모델 크기와 메모리 사용을 줄이는 데 효과적이며, 특히 저비트 양자화(예: 4비트)는 모델을 더 작고 빠르게 만듭니다. 4비트 양자화로 인해 수치의 정밀도가 약간 감소하지만, 학습 중 적절한 조정이 이루어지면 성능 저하를 최소화할 수 있습니다.\n","\n","이와 같은 4비트 양자화 기법을 통해 모델의 메모리 효율성을 극대화하면서도, 예측 성능을 유지할 수 있습니다."],"metadata":{"id":"sY7S3LFo-o3-"}},{"cell_type":"code","source":["bnb_config = BitsAndBytesConfig(\n","    load_in_8bit=True,\n","    # load_in_4bit=True,\n","    # bnb_4bit_use_double_quant=True,\n","    # bnb_4bit_quant_type=\"nf4\",\n","    # bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-flan-t5-xl\")\n","model = InstructBlipForConditionalGeneration.from_pretrained(\n","    \"Salesforce/instructblip-flan-t5-xl\",\n","    quantization_config=bnb_config,\n","    # device_map=\"auto\"\n",")"],"metadata":{"id":"7BFTUbVEeCsa","colab":{"base_uri":"https://localhost:8080/","height":730,"referenced_widgets":["db111d3dd0dd48cb9112f4eb22dfecdc","74a5282434a247cd9151e453cac73b86","79c5eef141ec47aeb419ae05432e3625","ece7969f88e148feb060c3bf8ac22629","42f63c988c304bbdad5625fe07713e39","b1fb2833b50f464c929dafff7e104367","1602fab013644431bc909743f16deca3","0a7b431cca34487ab18987e3a9ebed06","6077267836bd4a67a007a37927a58f6f","f5e9fe874fdf40f5b9421e217ab66681","cb189c811ef04dfe865491e55a4faa7b","08d2808a665d4933bbf831ba94012408","4ccecfbc91174a67b1a2611239b29199","59bb010300a043c286a1a239824c2282","a423e1cc867040738b970058a9ab1e99","50b7b93103b64b089b4905487074e56d","db0dc8045e044ef6bea4ab78cd4925b3","1dd3cb9993ee419592ed7f6b407bfb42","ea15178c11114f599895f93a8216718d","38ce839e07ba44ea9ecfecf70279af23","75c32c9653734f9e9ce3b5154cfcd1d7","a56778756b554570a1dfe812d9ef1b13","b402682389554b7ea37410923496dbb7","fc1ffc697da841cf80e9e0ababaa6728","5ad961356c3e4d79ab2eee256ad58204","93073219d7704ce88affae10aee28965","48928f38c87a43128390390d8dbe8b35","abab3188e1bd4f109aae362e14a1903d","fa14cd485e764ec0ae8a6ccc8adb9219","43de9aa7b5694753a3c5bb3cba8fb456","6a91f0290db44d2b9eb7f3edce1e8c35","8d21d7d23dbf4693854808a1b2f66f60","2d31552d52144bc58ad7763a8a115ad8","3139421478844b55bd13d0a41f197714","3d1c89bf31114883a7e71720b3ba3700","af7a98878f5e4a0e9a82db76800da556","bdedd613ab4d40ffa5092ccc15c5ecff","406d231ae4ad4785b220a00ada4b5e9e","a0f79c31c83f48e2ab70a2efae2e499b","c34f3c6fae99432484c18fcc3fbfe631","65d645f46a4b4b6ab59deb73bdea021d","bffbdb1deb2946aa9ebdd3c07478c1ef","d33f159e1bf84187ac4fef6249dfc82a","ee3e70fb21964830ab9439e1edb2163b","a8dcdad20f1b4f789aee274dca4d8885","2a8666e4199e44df94f0b288867d9afc","4add21c5ff0a4aa181e46fcf435923f5","2c2bd33e495b4cc7a87935e60c110d09","cc41e145c5994fe3990dcd221128bd1c","3f1ba05e71424e0fbed60a22fc9a4486","522d3233663d4bba81ab91e5e841c04c","841f891da6c94afe8597984660d7f854","b1a480d596964dcdaf266f99a47504b3","2270b956230f4856a1e6d94684d16ffe","dab0f5bca5154b57a35eff593be6d8b9","3eee23a4354b4dd59850941345c42a8d","d344b1d228a54fdfb85fd74263eecbf9","d81e94b25a5e4d4d9880b242e245bb79","d1bbeaf7d01a4fee95a1782713cb8a13","08ef53cbc47646d6b939c353c2f2109d","5a56d44f2e374174bc000db454ec8e5f","23727b8c101e4aa0ad51910612c6e86e","a7d18704f424496fa2c4168cf5d50579","d15e42b89a36467580802f9d30b754f5","fc63af7872944316b3365e8dccb10fa9","aa06f0dd84414fbca0dc6128168cf27f","98e59a64118a4c7aa32c6c815ca6d688","9b71062d84d5486293dc99b9cef16a28","8db8e172019242ea8525f8b4d3a81c11","507a03ea56594615987405be8f662a78","31d12b20326b4fda9cccc48f0d3adba2","769a5d8e564e4ce4bf39a0737f753c02","6bc18f94a25f49a8905c971189c29a36","c1c22586814140be9cda1c9945f49dc3","dceb8b52372c4a4380b17679bf4b4001","d0abe5d03ef24f18ab86295be49cfa2b","c569e0bf87f24f09bbdeafb3d7781746","5f18835c4b2b4c3dae5d931b6ec927ab","6730bd35717d48c0971c5bc67fdde57f","20547eef0ffb41278b60a867547cdfd7","2c0e891d5b4647be8fda95c16c04f749","654c8087e6fa44cfaf3d895c7c9736ae","3f54a2cc3ba8447c85b0abedc4cab4ac","fece712be89141c0926c7c12d2d8e8eb","8b594e7624364f5ea15aeddbcf35e16c","f83c40e2c2474ff19038d719e2695dea","734c5843f9694a1194be3bb497cd6089","bd0259458db147ef931778af4a0b8879","5f1a1d0a9dec471897601f91f1b68515","68d735a0c89744d5b036b7b2d27fb05f","c587f6b5f61a4b1bb6b18b2b718a0cec","06c4838600c840b5a499823e459d4845","9328a9ff78144b9fa0a5cd33dfa21c89","f47f8c1abe634dbda510d17828c23308","b1fab137a20f4a6eafd103c859cd0d33","ef84276507794f8094c54adde0975487","4a545161f4714ef2838f301c0b29b595","d9f7b93b07524120bca4fc14c9d9d43a","6c82308d10be450aa65035401ceb48d8","4ebbb7c6220842eeae402e77925f089f","a89ffa4874fb4eb4821cc7365ce70317","1e04859105804a4ba758cf7331f54f07","5855f87646c1454eb460462eefdc92f1","91e85f7903674b21b888e82d101e4b17","e302ac6902834f40b7a2bc63e9b43815","52d5834b0afc404bae9d6056eb751e2e","46d97dfc169d43ada374b3fb4563deac","d204839deba84f119fdb26947cc60404","fdd605b8c639432a8380d24298479768","8cf1a9f5ed1b49928a9fb0cae343a4b0","b538258aca1c41319b712ad6bc13bc43","7052f10491ce4e57b1b59214e1e8d642","f1d0b0716951496d8a1a239edacc0adc","77b0d437d3804788967a74c8163b5d47","6590cc01d1e44178a8e6b58e18a4e1a6","3d0a212f07ad49df9bd0d0215f1c3ea6","5b22e956e88d42a8976e7df39d9c1b8f","1e73557eb7264e8c8c3f82a0ebe1f446","cddf09307cac40689d09dd7430b23ad2","8015aa19d1d94435922f9ec1b63a6d18","db21b7dfc1f04f438671b96657b37781","ca6d66edbae04f1aa7b77a3023bcb31b","c511cf095bb945bf81b69c3a7fd0a276","7dca5a6ef4834e8b8be68a77f50e9ed4","bdf0fae6e820480f9c7b27081ba36ca5","067eef1705e8441999258f7e68c80c98","b3b4ec2312734e61a99cbaf13c03c71f","f3a2425df9984b41bf9983e1ff3256da","a00e855f41264beaaf2e00461fcf90d1","0fcd1170341e45c8ac1c4a1a898d784d","f89c54046412485fa1253445dd81a077","d79ad805a39e4a91a1f13d4ad353e9ef","b8ff6f238c524498bcfcdbb2c26a3bcf","a0bc25af276f42c09188e67207d7d5d0","94388a85f2274b4cabd9ed2d19036474","58656470ba764406878d5d983819b8fd","a89017e6ea614924971e5c2d85939dc5","e0a54923bf964251b1181e4ea866ef84","e60d36ec3a2f41a0a3566d0f143b62b4","ac16d3a4e06743c0aa2b7dae43601669","3bdafdceded945218847371bf9502631","23803356b62041d28460249720551bcf","929f4ff1faef40d68b207c522b95ad62","2c808c1db491461790149b5835d0492a","9b2842fba053443490d6c3c94fddc363","76122504b69445968737aa5175b22c7b","a363edcc3ffc4f988d375cc7df2766da","362eac9a5c064c11b69baa21c5b27eb0","eee1aa3003204ba08d00721cf19d62d9","f932a08e91174222bc0414e4b1ae1998","17bcf1ffaa4d49c1980db634c175acfa","3849d9ce5e7742b3a8c2afaf800da258","6b2fc9158d604fcc928adcfcf3bab0c0","327662f998b745ba8036b1bfdd95aeeb","dced97c0177d474fae4a26802a45d8dd","717615aa85cd4dc0b437d033ef8d255c","68eef7fa0d844270966af2b84d4767d8","40395b5420f94321888a58da10785e8b","b12eac363f9443a0bf9a928ac5d2fdf0","4e5a091275dd4cd3b3227bd0787611de","a5a9e45c20b54ec684faf45832d9d059","8749803f977b4d8895e5d64f1714b16b","6f44c1d61e814bf6bac95a6e5e790cb3","4cdf4e39a3e24db9a74ff18f6f182255","2106a1d4a0604d72890755d812e01322","fe7e4e8b88f64bc8b374ec182392c0eb","a22c98d7ff4e4e7b8e8925f197be4b49","65692348428e43ecbea5dcbe939d5319","7fbe7937335f4607a8eb140763e031c1","dee7188bc321496c95953a8517a6218e","c02bfecd04744698b09d65df601459b6","d8548435405f4168871a90c880f3b65d","65a4f442146b475aa7f04ec338ada80d","43dcdccaef7e415abb5a70fb2330b515","ede99a634f40476bba77e9f56ef3130c","f38ab94029ec434b847a2a1b2f2d00d3"]},"executionInfo":{"status":"ok","timestamp":1731126409274,"user_tz":-540,"elapsed":96086,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"2a89ff38-2f9c-417b-c02a-eb9f1fa2e90a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/439 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db111d3dd0dd48cb9112f4eb22dfecdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.42k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d2808a665d4933bbf831ba94012408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b402682389554b7ea37410923496dbb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3139421478844b55bd13d0a41f197714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8dcdad20f1b4f789aee274dca4d8885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["qformer_tokenizer/tokenizer_config.json:   0%|          | 0.00/343 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eee23a4354b4dd59850941345c42a8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["qformer_tokenizer/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98e59a64118a4c7aa32c6c815ca6d688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["qformer_tokenizer/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f18835c4b2b4c3dae5d931b6ec927ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["qformer_tokenizer/added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1a1d0a9dec471897601f91f1b68515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)former_tokenizer/special_tokens_map.json:   0%|          | 0.00/149 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebbb7c6220842eeae402e77925f089f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/7.74k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b538258aca1c41319b712ad6bc13bc43"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/140k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6d66edbae04f1aa7b77a3023bcb31b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ff6f238c524498bcfcdbb2c26a3bcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c808c1db491461790149b5835d0492a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/6.11G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dced97c0177d474fae4a26802a45d8dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe7e4e8b88f64bc8b374ec182392c0eb"}},"metadata":{}}]},{"cell_type":"markdown","source":["## 4. 모델 준비 및 LoRA 설정\n","`prepare_model_for_kbit_training`로 모델을 준비하고, **LoRA** 파인튜닝을 위한 설정을 합니다.\n","\n","### LoRA (Low-Rank Adaptation)\n","\n","**LoRA**는 큰 모델을 파인튜닝할 때 모든 파라미터를 조정하면 메모리가 많이 필요하므로, 모델의 일부 중요한 파라미터만 선택적으로 학습하여 메모리 효율성을 높이는 기법입니다.\n","\n","#### 이론 및 수식\n","LoRA는 모델의 가중치 행렬 $W \\in \\mathbb{R}^{d \\times k}$을 두 개의 저랭크 행렬 $A \\in \\mathbb{R}^{d \\times r}$과 $B \\in \\mathbb{R}^{r \\times k}$로 근사합니다. 여기서 $r$은 저랭크 차원(rank)을 의미하며, $r$이 작을수록 메모리 절약 효과가 큽니다.\n","\n","1. **가중치 행렬 분해**:\n","   $W$를 LoRA로 근사하기 위해 다음과 같이 표현합니다.\n","   \n","   $$\n","   W \\approx W_0 + \\Delta W = W_0 + A B\n","   $$\n","   \n","   여기서:\n","   - $W_0$는 기존의 고정된 원본 가중치입니다.\n","   - $\\Delta W = A B$는 학습 가능한 저랭크 행렬의 곱으로, 파인튜닝 시 학습됩니다.\n","\n","2. **저랭크 근사**:\n","   저랭크 근사에서 $A$와 $B$의 차원을 $d \\times r$ 및 $r \\times k$로 설정하면, 전체 파라미터 수는 $d \\times k$에서 $d \\times r + r \\times k$로 줄어듭니다. 즉, 전체 파라미터 수는 다음과 같습니다.\n","   \n","   $$\n","   \\text{파라미터 수} = d \\times r + r \\times k\n","   $$\n","\n","   이는 원래 파라미터 수 $d \\times k$에 비해 훨씬 적은 파라미터를 사용하여 근사할 수 있음을 의미합니다.\n","\n","3. **파라미터 효율성**:\n","   LoRA의 저랭크 차원 $r$이 작을수록 메모리 효율성이 높아집니다. 예를 들어 $r$을 $d$나 $k$에 비해 매우 작은 값으로 설정하면, 파라미터 수가 크게 줄어듭니다.\n","\n","이와 같은 LoRA 기법을 통해, 모델의 일부 주요 파라미터를 저랭크 행렬로 근사하여 메모리 사용량을 줄이면서도 파인튜닝 성능을 유지할 수 있습니다.\n","\n","LoRA: https://arxiv.org/abs/2106.09685\n"],"metadata":{"id":"cXiJ_7KO-2HU"}},{"cell_type":"code","source":["for name, module in model.named_modules():\n","    print(name)"],"metadata":{"id":"KLmB7BH6Id12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731126409275,"user_tz":-540,"elapsed":26,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"72ea2882-9f47-4c31-ae32-ab7bd97b58d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","vision_model\n","vision_model.embeddings\n","vision_model.embeddings.patch_embedding\n","vision_model.encoder\n","vision_model.encoder.layers\n","vision_model.encoder.layers.0\n","vision_model.encoder.layers.0.self_attn\n","vision_model.encoder.layers.0.self_attn.dropout\n","vision_model.encoder.layers.0.self_attn.qkv\n","vision_model.encoder.layers.0.self_attn.projection\n","vision_model.encoder.layers.0.layer_norm1\n","vision_model.encoder.layers.0.mlp\n","vision_model.encoder.layers.0.mlp.activation_fn\n","vision_model.encoder.layers.0.mlp.fc1\n","vision_model.encoder.layers.0.mlp.fc2\n","vision_model.encoder.layers.0.layer_norm2\n","vision_model.encoder.layers.1\n","vision_model.encoder.layers.1.self_attn\n","vision_model.encoder.layers.1.self_attn.dropout\n","vision_model.encoder.layers.1.self_attn.qkv\n","vision_model.encoder.layers.1.self_attn.projection\n","vision_model.encoder.layers.1.layer_norm1\n","vision_model.encoder.layers.1.mlp\n","vision_model.encoder.layers.1.mlp.activation_fn\n","vision_model.encoder.layers.1.mlp.fc1\n","vision_model.encoder.layers.1.mlp.fc2\n","vision_model.encoder.layers.1.layer_norm2\n","vision_model.encoder.layers.2\n","vision_model.encoder.layers.2.self_attn\n","vision_model.encoder.layers.2.self_attn.dropout\n","vision_model.encoder.layers.2.self_attn.qkv\n","vision_model.encoder.layers.2.self_attn.projection\n","vision_model.encoder.layers.2.layer_norm1\n","vision_model.encoder.layers.2.mlp\n","vision_model.encoder.layers.2.mlp.activation_fn\n","vision_model.encoder.layers.2.mlp.fc1\n","vision_model.encoder.layers.2.mlp.fc2\n","vision_model.encoder.layers.2.layer_norm2\n","vision_model.encoder.layers.3\n","vision_model.encoder.layers.3.self_attn\n","vision_model.encoder.layers.3.self_attn.dropout\n","vision_model.encoder.layers.3.self_attn.qkv\n","vision_model.encoder.layers.3.self_attn.projection\n","vision_model.encoder.layers.3.layer_norm1\n","vision_model.encoder.layers.3.mlp\n","vision_model.encoder.layers.3.mlp.activation_fn\n","vision_model.encoder.layers.3.mlp.fc1\n","vision_model.encoder.layers.3.mlp.fc2\n","vision_model.encoder.layers.3.layer_norm2\n","vision_model.encoder.layers.4\n","vision_model.encoder.layers.4.self_attn\n","vision_model.encoder.layers.4.self_attn.dropout\n","vision_model.encoder.layers.4.self_attn.qkv\n","vision_model.encoder.layers.4.self_attn.projection\n","vision_model.encoder.layers.4.layer_norm1\n","vision_model.encoder.layers.4.mlp\n","vision_model.encoder.layers.4.mlp.activation_fn\n","vision_model.encoder.layers.4.mlp.fc1\n","vision_model.encoder.layers.4.mlp.fc2\n","vision_model.encoder.layers.4.layer_norm2\n","vision_model.encoder.layers.5\n","vision_model.encoder.layers.5.self_attn\n","vision_model.encoder.layers.5.self_attn.dropout\n","vision_model.encoder.layers.5.self_attn.qkv\n","vision_model.encoder.layers.5.self_attn.projection\n","vision_model.encoder.layers.5.layer_norm1\n","vision_model.encoder.layers.5.mlp\n","vision_model.encoder.layers.5.mlp.activation_fn\n","vision_model.encoder.layers.5.mlp.fc1\n","vision_model.encoder.layers.5.mlp.fc2\n","vision_model.encoder.layers.5.layer_norm2\n","vision_model.encoder.layers.6\n","vision_model.encoder.layers.6.self_attn\n","vision_model.encoder.layers.6.self_attn.dropout\n","vision_model.encoder.layers.6.self_attn.qkv\n","vision_model.encoder.layers.6.self_attn.projection\n","vision_model.encoder.layers.6.layer_norm1\n","vision_model.encoder.layers.6.mlp\n","vision_model.encoder.layers.6.mlp.activation_fn\n","vision_model.encoder.layers.6.mlp.fc1\n","vision_model.encoder.layers.6.mlp.fc2\n","vision_model.encoder.layers.6.layer_norm2\n","vision_model.encoder.layers.7\n","vision_model.encoder.layers.7.self_attn\n","vision_model.encoder.layers.7.self_attn.dropout\n","vision_model.encoder.layers.7.self_attn.qkv\n","vision_model.encoder.layers.7.self_attn.projection\n","vision_model.encoder.layers.7.layer_norm1\n","vision_model.encoder.layers.7.mlp\n","vision_model.encoder.layers.7.mlp.activation_fn\n","vision_model.encoder.layers.7.mlp.fc1\n","vision_model.encoder.layers.7.mlp.fc2\n","vision_model.encoder.layers.7.layer_norm2\n","vision_model.encoder.layers.8\n","vision_model.encoder.layers.8.self_attn\n","vision_model.encoder.layers.8.self_attn.dropout\n","vision_model.encoder.layers.8.self_attn.qkv\n","vision_model.encoder.layers.8.self_attn.projection\n","vision_model.encoder.layers.8.layer_norm1\n","vision_model.encoder.layers.8.mlp\n","vision_model.encoder.layers.8.mlp.activation_fn\n","vision_model.encoder.layers.8.mlp.fc1\n","vision_model.encoder.layers.8.mlp.fc2\n","vision_model.encoder.layers.8.layer_norm2\n","vision_model.encoder.layers.9\n","vision_model.encoder.layers.9.self_attn\n","vision_model.encoder.layers.9.self_attn.dropout\n","vision_model.encoder.layers.9.self_attn.qkv\n","vision_model.encoder.layers.9.self_attn.projection\n","vision_model.encoder.layers.9.layer_norm1\n","vision_model.encoder.layers.9.mlp\n","vision_model.encoder.layers.9.mlp.activation_fn\n","vision_model.encoder.layers.9.mlp.fc1\n","vision_model.encoder.layers.9.mlp.fc2\n","vision_model.encoder.layers.9.layer_norm2\n","vision_model.encoder.layers.10\n","vision_model.encoder.layers.10.self_attn\n","vision_model.encoder.layers.10.self_attn.dropout\n","vision_model.encoder.layers.10.self_attn.qkv\n","vision_model.encoder.layers.10.self_attn.projection\n","vision_model.encoder.layers.10.layer_norm1\n","vision_model.encoder.layers.10.mlp\n","vision_model.encoder.layers.10.mlp.activation_fn\n","vision_model.encoder.layers.10.mlp.fc1\n","vision_model.encoder.layers.10.mlp.fc2\n","vision_model.encoder.layers.10.layer_norm2\n","vision_model.encoder.layers.11\n","vision_model.encoder.layers.11.self_attn\n","vision_model.encoder.layers.11.self_attn.dropout\n","vision_model.encoder.layers.11.self_attn.qkv\n","vision_model.encoder.layers.11.self_attn.projection\n","vision_model.encoder.layers.11.layer_norm1\n","vision_model.encoder.layers.11.mlp\n","vision_model.encoder.layers.11.mlp.activation_fn\n","vision_model.encoder.layers.11.mlp.fc1\n","vision_model.encoder.layers.11.mlp.fc2\n","vision_model.encoder.layers.11.layer_norm2\n","vision_model.encoder.layers.12\n","vision_model.encoder.layers.12.self_attn\n","vision_model.encoder.layers.12.self_attn.dropout\n","vision_model.encoder.layers.12.self_attn.qkv\n","vision_model.encoder.layers.12.self_attn.projection\n","vision_model.encoder.layers.12.layer_norm1\n","vision_model.encoder.layers.12.mlp\n","vision_model.encoder.layers.12.mlp.activation_fn\n","vision_model.encoder.layers.12.mlp.fc1\n","vision_model.encoder.layers.12.mlp.fc2\n","vision_model.encoder.layers.12.layer_norm2\n","vision_model.encoder.layers.13\n","vision_model.encoder.layers.13.self_attn\n","vision_model.encoder.layers.13.self_attn.dropout\n","vision_model.encoder.layers.13.self_attn.qkv\n","vision_model.encoder.layers.13.self_attn.projection\n","vision_model.encoder.layers.13.layer_norm1\n","vision_model.encoder.layers.13.mlp\n","vision_model.encoder.layers.13.mlp.activation_fn\n","vision_model.encoder.layers.13.mlp.fc1\n","vision_model.encoder.layers.13.mlp.fc2\n","vision_model.encoder.layers.13.layer_norm2\n","vision_model.encoder.layers.14\n","vision_model.encoder.layers.14.self_attn\n","vision_model.encoder.layers.14.self_attn.dropout\n","vision_model.encoder.layers.14.self_attn.qkv\n","vision_model.encoder.layers.14.self_attn.projection\n","vision_model.encoder.layers.14.layer_norm1\n","vision_model.encoder.layers.14.mlp\n","vision_model.encoder.layers.14.mlp.activation_fn\n","vision_model.encoder.layers.14.mlp.fc1\n","vision_model.encoder.layers.14.mlp.fc2\n","vision_model.encoder.layers.14.layer_norm2\n","vision_model.encoder.layers.15\n","vision_model.encoder.layers.15.self_attn\n","vision_model.encoder.layers.15.self_attn.dropout\n","vision_model.encoder.layers.15.self_attn.qkv\n","vision_model.encoder.layers.15.self_attn.projection\n","vision_model.encoder.layers.15.layer_norm1\n","vision_model.encoder.layers.15.mlp\n","vision_model.encoder.layers.15.mlp.activation_fn\n","vision_model.encoder.layers.15.mlp.fc1\n","vision_model.encoder.layers.15.mlp.fc2\n","vision_model.encoder.layers.15.layer_norm2\n","vision_model.encoder.layers.16\n","vision_model.encoder.layers.16.self_attn\n","vision_model.encoder.layers.16.self_attn.dropout\n","vision_model.encoder.layers.16.self_attn.qkv\n","vision_model.encoder.layers.16.self_attn.projection\n","vision_model.encoder.layers.16.layer_norm1\n","vision_model.encoder.layers.16.mlp\n","vision_model.encoder.layers.16.mlp.activation_fn\n","vision_model.encoder.layers.16.mlp.fc1\n","vision_model.encoder.layers.16.mlp.fc2\n","vision_model.encoder.layers.16.layer_norm2\n","vision_model.encoder.layers.17\n","vision_model.encoder.layers.17.self_attn\n","vision_model.encoder.layers.17.self_attn.dropout\n","vision_model.encoder.layers.17.self_attn.qkv\n","vision_model.encoder.layers.17.self_attn.projection\n","vision_model.encoder.layers.17.layer_norm1\n","vision_model.encoder.layers.17.mlp\n","vision_model.encoder.layers.17.mlp.activation_fn\n","vision_model.encoder.layers.17.mlp.fc1\n","vision_model.encoder.layers.17.mlp.fc2\n","vision_model.encoder.layers.17.layer_norm2\n","vision_model.encoder.layers.18\n","vision_model.encoder.layers.18.self_attn\n","vision_model.encoder.layers.18.self_attn.dropout\n","vision_model.encoder.layers.18.self_attn.qkv\n","vision_model.encoder.layers.18.self_attn.projection\n","vision_model.encoder.layers.18.layer_norm1\n","vision_model.encoder.layers.18.mlp\n","vision_model.encoder.layers.18.mlp.activation_fn\n","vision_model.encoder.layers.18.mlp.fc1\n","vision_model.encoder.layers.18.mlp.fc2\n","vision_model.encoder.layers.18.layer_norm2\n","vision_model.encoder.layers.19\n","vision_model.encoder.layers.19.self_attn\n","vision_model.encoder.layers.19.self_attn.dropout\n","vision_model.encoder.layers.19.self_attn.qkv\n","vision_model.encoder.layers.19.self_attn.projection\n","vision_model.encoder.layers.19.layer_norm1\n","vision_model.encoder.layers.19.mlp\n","vision_model.encoder.layers.19.mlp.activation_fn\n","vision_model.encoder.layers.19.mlp.fc1\n","vision_model.encoder.layers.19.mlp.fc2\n","vision_model.encoder.layers.19.layer_norm2\n","vision_model.encoder.layers.20\n","vision_model.encoder.layers.20.self_attn\n","vision_model.encoder.layers.20.self_attn.dropout\n","vision_model.encoder.layers.20.self_attn.qkv\n","vision_model.encoder.layers.20.self_attn.projection\n","vision_model.encoder.layers.20.layer_norm1\n","vision_model.encoder.layers.20.mlp\n","vision_model.encoder.layers.20.mlp.activation_fn\n","vision_model.encoder.layers.20.mlp.fc1\n","vision_model.encoder.layers.20.mlp.fc2\n","vision_model.encoder.layers.20.layer_norm2\n","vision_model.encoder.layers.21\n","vision_model.encoder.layers.21.self_attn\n","vision_model.encoder.layers.21.self_attn.dropout\n","vision_model.encoder.layers.21.self_attn.qkv\n","vision_model.encoder.layers.21.self_attn.projection\n","vision_model.encoder.layers.21.layer_norm1\n","vision_model.encoder.layers.21.mlp\n","vision_model.encoder.layers.21.mlp.activation_fn\n","vision_model.encoder.layers.21.mlp.fc1\n","vision_model.encoder.layers.21.mlp.fc2\n","vision_model.encoder.layers.21.layer_norm2\n","vision_model.encoder.layers.22\n","vision_model.encoder.layers.22.self_attn\n","vision_model.encoder.layers.22.self_attn.dropout\n","vision_model.encoder.layers.22.self_attn.qkv\n","vision_model.encoder.layers.22.self_attn.projection\n","vision_model.encoder.layers.22.layer_norm1\n","vision_model.encoder.layers.22.mlp\n","vision_model.encoder.layers.22.mlp.activation_fn\n","vision_model.encoder.layers.22.mlp.fc1\n","vision_model.encoder.layers.22.mlp.fc2\n","vision_model.encoder.layers.22.layer_norm2\n","vision_model.encoder.layers.23\n","vision_model.encoder.layers.23.self_attn\n","vision_model.encoder.layers.23.self_attn.dropout\n","vision_model.encoder.layers.23.self_attn.qkv\n","vision_model.encoder.layers.23.self_attn.projection\n","vision_model.encoder.layers.23.layer_norm1\n","vision_model.encoder.layers.23.mlp\n","vision_model.encoder.layers.23.mlp.activation_fn\n","vision_model.encoder.layers.23.mlp.fc1\n","vision_model.encoder.layers.23.mlp.fc2\n","vision_model.encoder.layers.23.layer_norm2\n","vision_model.encoder.layers.24\n","vision_model.encoder.layers.24.self_attn\n","vision_model.encoder.layers.24.self_attn.dropout\n","vision_model.encoder.layers.24.self_attn.qkv\n","vision_model.encoder.layers.24.self_attn.projection\n","vision_model.encoder.layers.24.layer_norm1\n","vision_model.encoder.layers.24.mlp\n","vision_model.encoder.layers.24.mlp.activation_fn\n","vision_model.encoder.layers.24.mlp.fc1\n","vision_model.encoder.layers.24.mlp.fc2\n","vision_model.encoder.layers.24.layer_norm2\n","vision_model.encoder.layers.25\n","vision_model.encoder.layers.25.self_attn\n","vision_model.encoder.layers.25.self_attn.dropout\n","vision_model.encoder.layers.25.self_attn.qkv\n","vision_model.encoder.layers.25.self_attn.projection\n","vision_model.encoder.layers.25.layer_norm1\n","vision_model.encoder.layers.25.mlp\n","vision_model.encoder.layers.25.mlp.activation_fn\n","vision_model.encoder.layers.25.mlp.fc1\n","vision_model.encoder.layers.25.mlp.fc2\n","vision_model.encoder.layers.25.layer_norm2\n","vision_model.encoder.layers.26\n","vision_model.encoder.layers.26.self_attn\n","vision_model.encoder.layers.26.self_attn.dropout\n","vision_model.encoder.layers.26.self_attn.qkv\n","vision_model.encoder.layers.26.self_attn.projection\n","vision_model.encoder.layers.26.layer_norm1\n","vision_model.encoder.layers.26.mlp\n","vision_model.encoder.layers.26.mlp.activation_fn\n","vision_model.encoder.layers.26.mlp.fc1\n","vision_model.encoder.layers.26.mlp.fc2\n","vision_model.encoder.layers.26.layer_norm2\n","vision_model.encoder.layers.27\n","vision_model.encoder.layers.27.self_attn\n","vision_model.encoder.layers.27.self_attn.dropout\n","vision_model.encoder.layers.27.self_attn.qkv\n","vision_model.encoder.layers.27.self_attn.projection\n","vision_model.encoder.layers.27.layer_norm1\n","vision_model.encoder.layers.27.mlp\n","vision_model.encoder.layers.27.mlp.activation_fn\n","vision_model.encoder.layers.27.mlp.fc1\n","vision_model.encoder.layers.27.mlp.fc2\n","vision_model.encoder.layers.27.layer_norm2\n","vision_model.encoder.layers.28\n","vision_model.encoder.layers.28.self_attn\n","vision_model.encoder.layers.28.self_attn.dropout\n","vision_model.encoder.layers.28.self_attn.qkv\n","vision_model.encoder.layers.28.self_attn.projection\n","vision_model.encoder.layers.28.layer_norm1\n","vision_model.encoder.layers.28.mlp\n","vision_model.encoder.layers.28.mlp.activation_fn\n","vision_model.encoder.layers.28.mlp.fc1\n","vision_model.encoder.layers.28.mlp.fc2\n","vision_model.encoder.layers.28.layer_norm2\n","vision_model.encoder.layers.29\n","vision_model.encoder.layers.29.self_attn\n","vision_model.encoder.layers.29.self_attn.dropout\n","vision_model.encoder.layers.29.self_attn.qkv\n","vision_model.encoder.layers.29.self_attn.projection\n","vision_model.encoder.layers.29.layer_norm1\n","vision_model.encoder.layers.29.mlp\n","vision_model.encoder.layers.29.mlp.activation_fn\n","vision_model.encoder.layers.29.mlp.fc1\n","vision_model.encoder.layers.29.mlp.fc2\n","vision_model.encoder.layers.29.layer_norm2\n","vision_model.encoder.layers.30\n","vision_model.encoder.layers.30.self_attn\n","vision_model.encoder.layers.30.self_attn.dropout\n","vision_model.encoder.layers.30.self_attn.qkv\n","vision_model.encoder.layers.30.self_attn.projection\n","vision_model.encoder.layers.30.layer_norm1\n","vision_model.encoder.layers.30.mlp\n","vision_model.encoder.layers.30.mlp.activation_fn\n","vision_model.encoder.layers.30.mlp.fc1\n","vision_model.encoder.layers.30.mlp.fc2\n","vision_model.encoder.layers.30.layer_norm2\n","vision_model.encoder.layers.31\n","vision_model.encoder.layers.31.self_attn\n","vision_model.encoder.layers.31.self_attn.dropout\n","vision_model.encoder.layers.31.self_attn.qkv\n","vision_model.encoder.layers.31.self_attn.projection\n","vision_model.encoder.layers.31.layer_norm1\n","vision_model.encoder.layers.31.mlp\n","vision_model.encoder.layers.31.mlp.activation_fn\n","vision_model.encoder.layers.31.mlp.fc1\n","vision_model.encoder.layers.31.mlp.fc2\n","vision_model.encoder.layers.31.layer_norm2\n","vision_model.encoder.layers.32\n","vision_model.encoder.layers.32.self_attn\n","vision_model.encoder.layers.32.self_attn.dropout\n","vision_model.encoder.layers.32.self_attn.qkv\n","vision_model.encoder.layers.32.self_attn.projection\n","vision_model.encoder.layers.32.layer_norm1\n","vision_model.encoder.layers.32.mlp\n","vision_model.encoder.layers.32.mlp.activation_fn\n","vision_model.encoder.layers.32.mlp.fc1\n","vision_model.encoder.layers.32.mlp.fc2\n","vision_model.encoder.layers.32.layer_norm2\n","vision_model.encoder.layers.33\n","vision_model.encoder.layers.33.self_attn\n","vision_model.encoder.layers.33.self_attn.dropout\n","vision_model.encoder.layers.33.self_attn.qkv\n","vision_model.encoder.layers.33.self_attn.projection\n","vision_model.encoder.layers.33.layer_norm1\n","vision_model.encoder.layers.33.mlp\n","vision_model.encoder.layers.33.mlp.activation_fn\n","vision_model.encoder.layers.33.mlp.fc1\n","vision_model.encoder.layers.33.mlp.fc2\n","vision_model.encoder.layers.33.layer_norm2\n","vision_model.encoder.layers.34\n","vision_model.encoder.layers.34.self_attn\n","vision_model.encoder.layers.34.self_attn.dropout\n","vision_model.encoder.layers.34.self_attn.qkv\n","vision_model.encoder.layers.34.self_attn.projection\n","vision_model.encoder.layers.34.layer_norm1\n","vision_model.encoder.layers.34.mlp\n","vision_model.encoder.layers.34.mlp.activation_fn\n","vision_model.encoder.layers.34.mlp.fc1\n","vision_model.encoder.layers.34.mlp.fc2\n","vision_model.encoder.layers.34.layer_norm2\n","vision_model.encoder.layers.35\n","vision_model.encoder.layers.35.self_attn\n","vision_model.encoder.layers.35.self_attn.dropout\n","vision_model.encoder.layers.35.self_attn.qkv\n","vision_model.encoder.layers.35.self_attn.projection\n","vision_model.encoder.layers.35.layer_norm1\n","vision_model.encoder.layers.35.mlp\n","vision_model.encoder.layers.35.mlp.activation_fn\n","vision_model.encoder.layers.35.mlp.fc1\n","vision_model.encoder.layers.35.mlp.fc2\n","vision_model.encoder.layers.35.layer_norm2\n","vision_model.encoder.layers.36\n","vision_model.encoder.layers.36.self_attn\n","vision_model.encoder.layers.36.self_attn.dropout\n","vision_model.encoder.layers.36.self_attn.qkv\n","vision_model.encoder.layers.36.self_attn.projection\n","vision_model.encoder.layers.36.layer_norm1\n","vision_model.encoder.layers.36.mlp\n","vision_model.encoder.layers.36.mlp.activation_fn\n","vision_model.encoder.layers.36.mlp.fc1\n","vision_model.encoder.layers.36.mlp.fc2\n","vision_model.encoder.layers.36.layer_norm2\n","vision_model.encoder.layers.37\n","vision_model.encoder.layers.37.self_attn\n","vision_model.encoder.layers.37.self_attn.dropout\n","vision_model.encoder.layers.37.self_attn.qkv\n","vision_model.encoder.layers.37.self_attn.projection\n","vision_model.encoder.layers.37.layer_norm1\n","vision_model.encoder.layers.37.mlp\n","vision_model.encoder.layers.37.mlp.activation_fn\n","vision_model.encoder.layers.37.mlp.fc1\n","vision_model.encoder.layers.37.mlp.fc2\n","vision_model.encoder.layers.37.layer_norm2\n","vision_model.encoder.layers.38\n","vision_model.encoder.layers.38.self_attn\n","vision_model.encoder.layers.38.self_attn.dropout\n","vision_model.encoder.layers.38.self_attn.qkv\n","vision_model.encoder.layers.38.self_attn.projection\n","vision_model.encoder.layers.38.layer_norm1\n","vision_model.encoder.layers.38.mlp\n","vision_model.encoder.layers.38.mlp.activation_fn\n","vision_model.encoder.layers.38.mlp.fc1\n","vision_model.encoder.layers.38.mlp.fc2\n","vision_model.encoder.layers.38.layer_norm2\n","vision_model.post_layernorm\n","qformer\n","qformer.embeddings\n","qformer.embeddings.word_embeddings\n","qformer.embeddings.position_embeddings\n","qformer.embeddings.layernorm\n","qformer.embeddings.dropout\n","qformer.encoder\n","qformer.encoder.layer\n","qformer.encoder.layer.0\n","qformer.encoder.layer.0.attention\n","qformer.encoder.layer.0.attention.attention\n","qformer.encoder.layer.0.attention.attention.query\n","qformer.encoder.layer.0.attention.attention.key\n","qformer.encoder.layer.0.attention.attention.value\n","qformer.encoder.layer.0.attention.attention.dropout\n","qformer.encoder.layer.0.attention.output\n","qformer.encoder.layer.0.attention.output.dense\n","qformer.encoder.layer.0.attention.output.LayerNorm\n","qformer.encoder.layer.0.attention.output.dropout\n","qformer.encoder.layer.0.crossattention\n","qformer.encoder.layer.0.crossattention.attention\n","qformer.encoder.layer.0.crossattention.attention.query\n","qformer.encoder.layer.0.crossattention.attention.key\n","qformer.encoder.layer.0.crossattention.attention.value\n","qformer.encoder.layer.0.crossattention.attention.dropout\n","qformer.encoder.layer.0.crossattention.output\n","qformer.encoder.layer.0.crossattention.output.dense\n","qformer.encoder.layer.0.crossattention.output.LayerNorm\n","qformer.encoder.layer.0.crossattention.output.dropout\n","qformer.encoder.layer.0.intermediate\n","qformer.encoder.layer.0.intermediate.dense\n","qformer.encoder.layer.0.intermediate.intermediate_act_fn\n","qformer.encoder.layer.0.output\n","qformer.encoder.layer.0.output.dense\n","qformer.encoder.layer.0.output.LayerNorm\n","qformer.encoder.layer.0.output.dropout\n","qformer.encoder.layer.0.intermediate_query\n","qformer.encoder.layer.0.intermediate_query.dense\n","qformer.encoder.layer.0.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.0.output_query\n","qformer.encoder.layer.0.output_query.dense\n","qformer.encoder.layer.0.output_query.LayerNorm\n","qformer.encoder.layer.0.output_query.dropout\n","qformer.encoder.layer.1\n","qformer.encoder.layer.1.attention\n","qformer.encoder.layer.1.attention.attention\n","qformer.encoder.layer.1.attention.attention.query\n","qformer.encoder.layer.1.attention.attention.key\n","qformer.encoder.layer.1.attention.attention.value\n","qformer.encoder.layer.1.attention.attention.dropout\n","qformer.encoder.layer.1.attention.output\n","qformer.encoder.layer.1.attention.output.dense\n","qformer.encoder.layer.1.attention.output.LayerNorm\n","qformer.encoder.layer.1.attention.output.dropout\n","qformer.encoder.layer.1.intermediate\n","qformer.encoder.layer.1.intermediate.dense\n","qformer.encoder.layer.1.intermediate.intermediate_act_fn\n","qformer.encoder.layer.1.output\n","qformer.encoder.layer.1.output.dense\n","qformer.encoder.layer.1.output.LayerNorm\n","qformer.encoder.layer.1.output.dropout\n","qformer.encoder.layer.1.intermediate_query\n","qformer.encoder.layer.1.intermediate_query.dense\n","qformer.encoder.layer.1.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.1.output_query\n","qformer.encoder.layer.1.output_query.dense\n","qformer.encoder.layer.1.output_query.LayerNorm\n","qformer.encoder.layer.1.output_query.dropout\n","qformer.encoder.layer.2\n","qformer.encoder.layer.2.attention\n","qformer.encoder.layer.2.attention.attention\n","qformer.encoder.layer.2.attention.attention.query\n","qformer.encoder.layer.2.attention.attention.key\n","qformer.encoder.layer.2.attention.attention.value\n","qformer.encoder.layer.2.attention.attention.dropout\n","qformer.encoder.layer.2.attention.output\n","qformer.encoder.layer.2.attention.output.dense\n","qformer.encoder.layer.2.attention.output.LayerNorm\n","qformer.encoder.layer.2.attention.output.dropout\n","qformer.encoder.layer.2.crossattention\n","qformer.encoder.layer.2.crossattention.attention\n","qformer.encoder.layer.2.crossattention.attention.query\n","qformer.encoder.layer.2.crossattention.attention.key\n","qformer.encoder.layer.2.crossattention.attention.value\n","qformer.encoder.layer.2.crossattention.attention.dropout\n","qformer.encoder.layer.2.crossattention.output\n","qformer.encoder.layer.2.crossattention.output.dense\n","qformer.encoder.layer.2.crossattention.output.LayerNorm\n","qformer.encoder.layer.2.crossattention.output.dropout\n","qformer.encoder.layer.2.intermediate\n","qformer.encoder.layer.2.intermediate.dense\n","qformer.encoder.layer.2.intermediate.intermediate_act_fn\n","qformer.encoder.layer.2.output\n","qformer.encoder.layer.2.output.dense\n","qformer.encoder.layer.2.output.LayerNorm\n","qformer.encoder.layer.2.output.dropout\n","qformer.encoder.layer.2.intermediate_query\n","qformer.encoder.layer.2.intermediate_query.dense\n","qformer.encoder.layer.2.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.2.output_query\n","qformer.encoder.layer.2.output_query.dense\n","qformer.encoder.layer.2.output_query.LayerNorm\n","qformer.encoder.layer.2.output_query.dropout\n","qformer.encoder.layer.3\n","qformer.encoder.layer.3.attention\n","qformer.encoder.layer.3.attention.attention\n","qformer.encoder.layer.3.attention.attention.query\n","qformer.encoder.layer.3.attention.attention.key\n","qformer.encoder.layer.3.attention.attention.value\n","qformer.encoder.layer.3.attention.attention.dropout\n","qformer.encoder.layer.3.attention.output\n","qformer.encoder.layer.3.attention.output.dense\n","qformer.encoder.layer.3.attention.output.LayerNorm\n","qformer.encoder.layer.3.attention.output.dropout\n","qformer.encoder.layer.3.intermediate\n","qformer.encoder.layer.3.intermediate.dense\n","qformer.encoder.layer.3.intermediate.intermediate_act_fn\n","qformer.encoder.layer.3.output\n","qformer.encoder.layer.3.output.dense\n","qformer.encoder.layer.3.output.LayerNorm\n","qformer.encoder.layer.3.output.dropout\n","qformer.encoder.layer.3.intermediate_query\n","qformer.encoder.layer.3.intermediate_query.dense\n","qformer.encoder.layer.3.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.3.output_query\n","qformer.encoder.layer.3.output_query.dense\n","qformer.encoder.layer.3.output_query.LayerNorm\n","qformer.encoder.layer.3.output_query.dropout\n","qformer.encoder.layer.4\n","qformer.encoder.layer.4.attention\n","qformer.encoder.layer.4.attention.attention\n","qformer.encoder.layer.4.attention.attention.query\n","qformer.encoder.layer.4.attention.attention.key\n","qformer.encoder.layer.4.attention.attention.value\n","qformer.encoder.layer.4.attention.attention.dropout\n","qformer.encoder.layer.4.attention.output\n","qformer.encoder.layer.4.attention.output.dense\n","qformer.encoder.layer.4.attention.output.LayerNorm\n","qformer.encoder.layer.4.attention.output.dropout\n","qformer.encoder.layer.4.crossattention\n","qformer.encoder.layer.4.crossattention.attention\n","qformer.encoder.layer.4.crossattention.attention.query\n","qformer.encoder.layer.4.crossattention.attention.key\n","qformer.encoder.layer.4.crossattention.attention.value\n","qformer.encoder.layer.4.crossattention.attention.dropout\n","qformer.encoder.layer.4.crossattention.output\n","qformer.encoder.layer.4.crossattention.output.dense\n","qformer.encoder.layer.4.crossattention.output.LayerNorm\n","qformer.encoder.layer.4.crossattention.output.dropout\n","qformer.encoder.layer.4.intermediate\n","qformer.encoder.layer.4.intermediate.dense\n","qformer.encoder.layer.4.intermediate.intermediate_act_fn\n","qformer.encoder.layer.4.output\n","qformer.encoder.layer.4.output.dense\n","qformer.encoder.layer.4.output.LayerNorm\n","qformer.encoder.layer.4.output.dropout\n","qformer.encoder.layer.4.intermediate_query\n","qformer.encoder.layer.4.intermediate_query.dense\n","qformer.encoder.layer.4.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.4.output_query\n","qformer.encoder.layer.4.output_query.dense\n","qformer.encoder.layer.4.output_query.LayerNorm\n","qformer.encoder.layer.4.output_query.dropout\n","qformer.encoder.layer.5\n","qformer.encoder.layer.5.attention\n","qformer.encoder.layer.5.attention.attention\n","qformer.encoder.layer.5.attention.attention.query\n","qformer.encoder.layer.5.attention.attention.key\n","qformer.encoder.layer.5.attention.attention.value\n","qformer.encoder.layer.5.attention.attention.dropout\n","qformer.encoder.layer.5.attention.output\n","qformer.encoder.layer.5.attention.output.dense\n","qformer.encoder.layer.5.attention.output.LayerNorm\n","qformer.encoder.layer.5.attention.output.dropout\n","qformer.encoder.layer.5.intermediate\n","qformer.encoder.layer.5.intermediate.dense\n","qformer.encoder.layer.5.intermediate.intermediate_act_fn\n","qformer.encoder.layer.5.output\n","qformer.encoder.layer.5.output.dense\n","qformer.encoder.layer.5.output.LayerNorm\n","qformer.encoder.layer.5.output.dropout\n","qformer.encoder.layer.5.intermediate_query\n","qformer.encoder.layer.5.intermediate_query.dense\n","qformer.encoder.layer.5.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.5.output_query\n","qformer.encoder.layer.5.output_query.dense\n","qformer.encoder.layer.5.output_query.LayerNorm\n","qformer.encoder.layer.5.output_query.dropout\n","qformer.encoder.layer.6\n","qformer.encoder.layer.6.attention\n","qformer.encoder.layer.6.attention.attention\n","qformer.encoder.layer.6.attention.attention.query\n","qformer.encoder.layer.6.attention.attention.key\n","qformer.encoder.layer.6.attention.attention.value\n","qformer.encoder.layer.6.attention.attention.dropout\n","qformer.encoder.layer.6.attention.output\n","qformer.encoder.layer.6.attention.output.dense\n","qformer.encoder.layer.6.attention.output.LayerNorm\n","qformer.encoder.layer.6.attention.output.dropout\n","qformer.encoder.layer.6.crossattention\n","qformer.encoder.layer.6.crossattention.attention\n","qformer.encoder.layer.6.crossattention.attention.query\n","qformer.encoder.layer.6.crossattention.attention.key\n","qformer.encoder.layer.6.crossattention.attention.value\n","qformer.encoder.layer.6.crossattention.attention.dropout\n","qformer.encoder.layer.6.crossattention.output\n","qformer.encoder.layer.6.crossattention.output.dense\n","qformer.encoder.layer.6.crossattention.output.LayerNorm\n","qformer.encoder.layer.6.crossattention.output.dropout\n","qformer.encoder.layer.6.intermediate\n","qformer.encoder.layer.6.intermediate.dense\n","qformer.encoder.layer.6.intermediate.intermediate_act_fn\n","qformer.encoder.layer.6.output\n","qformer.encoder.layer.6.output.dense\n","qformer.encoder.layer.6.output.LayerNorm\n","qformer.encoder.layer.6.output.dropout\n","qformer.encoder.layer.6.intermediate_query\n","qformer.encoder.layer.6.intermediate_query.dense\n","qformer.encoder.layer.6.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.6.output_query\n","qformer.encoder.layer.6.output_query.dense\n","qformer.encoder.layer.6.output_query.LayerNorm\n","qformer.encoder.layer.6.output_query.dropout\n","qformer.encoder.layer.7\n","qformer.encoder.layer.7.attention\n","qformer.encoder.layer.7.attention.attention\n","qformer.encoder.layer.7.attention.attention.query\n","qformer.encoder.layer.7.attention.attention.key\n","qformer.encoder.layer.7.attention.attention.value\n","qformer.encoder.layer.7.attention.attention.dropout\n","qformer.encoder.layer.7.attention.output\n","qformer.encoder.layer.7.attention.output.dense\n","qformer.encoder.layer.7.attention.output.LayerNorm\n","qformer.encoder.layer.7.attention.output.dropout\n","qformer.encoder.layer.7.intermediate\n","qformer.encoder.layer.7.intermediate.dense\n","qformer.encoder.layer.7.intermediate.intermediate_act_fn\n","qformer.encoder.layer.7.output\n","qformer.encoder.layer.7.output.dense\n","qformer.encoder.layer.7.output.LayerNorm\n","qformer.encoder.layer.7.output.dropout\n","qformer.encoder.layer.7.intermediate_query\n","qformer.encoder.layer.7.intermediate_query.dense\n","qformer.encoder.layer.7.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.7.output_query\n","qformer.encoder.layer.7.output_query.dense\n","qformer.encoder.layer.7.output_query.LayerNorm\n","qformer.encoder.layer.7.output_query.dropout\n","qformer.encoder.layer.8\n","qformer.encoder.layer.8.attention\n","qformer.encoder.layer.8.attention.attention\n","qformer.encoder.layer.8.attention.attention.query\n","qformer.encoder.layer.8.attention.attention.key\n","qformer.encoder.layer.8.attention.attention.value\n","qformer.encoder.layer.8.attention.attention.dropout\n","qformer.encoder.layer.8.attention.output\n","qformer.encoder.layer.8.attention.output.dense\n","qformer.encoder.layer.8.attention.output.LayerNorm\n","qformer.encoder.layer.8.attention.output.dropout\n","qformer.encoder.layer.8.crossattention\n","qformer.encoder.layer.8.crossattention.attention\n","qformer.encoder.layer.8.crossattention.attention.query\n","qformer.encoder.layer.8.crossattention.attention.key\n","qformer.encoder.layer.8.crossattention.attention.value\n","qformer.encoder.layer.8.crossattention.attention.dropout\n","qformer.encoder.layer.8.crossattention.output\n","qformer.encoder.layer.8.crossattention.output.dense\n","qformer.encoder.layer.8.crossattention.output.LayerNorm\n","qformer.encoder.layer.8.crossattention.output.dropout\n","qformer.encoder.layer.8.intermediate\n","qformer.encoder.layer.8.intermediate.dense\n","qformer.encoder.layer.8.intermediate.intermediate_act_fn\n","qformer.encoder.layer.8.output\n","qformer.encoder.layer.8.output.dense\n","qformer.encoder.layer.8.output.LayerNorm\n","qformer.encoder.layer.8.output.dropout\n","qformer.encoder.layer.8.intermediate_query\n","qformer.encoder.layer.8.intermediate_query.dense\n","qformer.encoder.layer.8.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.8.output_query\n","qformer.encoder.layer.8.output_query.dense\n","qformer.encoder.layer.8.output_query.LayerNorm\n","qformer.encoder.layer.8.output_query.dropout\n","qformer.encoder.layer.9\n","qformer.encoder.layer.9.attention\n","qformer.encoder.layer.9.attention.attention\n","qformer.encoder.layer.9.attention.attention.query\n","qformer.encoder.layer.9.attention.attention.key\n","qformer.encoder.layer.9.attention.attention.value\n","qformer.encoder.layer.9.attention.attention.dropout\n","qformer.encoder.layer.9.attention.output\n","qformer.encoder.layer.9.attention.output.dense\n","qformer.encoder.layer.9.attention.output.LayerNorm\n","qformer.encoder.layer.9.attention.output.dropout\n","qformer.encoder.layer.9.intermediate\n","qformer.encoder.layer.9.intermediate.dense\n","qformer.encoder.layer.9.intermediate.intermediate_act_fn\n","qformer.encoder.layer.9.output\n","qformer.encoder.layer.9.output.dense\n","qformer.encoder.layer.9.output.LayerNorm\n","qformer.encoder.layer.9.output.dropout\n","qformer.encoder.layer.9.intermediate_query\n","qformer.encoder.layer.9.intermediate_query.dense\n","qformer.encoder.layer.9.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.9.output_query\n","qformer.encoder.layer.9.output_query.dense\n","qformer.encoder.layer.9.output_query.LayerNorm\n","qformer.encoder.layer.9.output_query.dropout\n","qformer.encoder.layer.10\n","qformer.encoder.layer.10.attention\n","qformer.encoder.layer.10.attention.attention\n","qformer.encoder.layer.10.attention.attention.query\n","qformer.encoder.layer.10.attention.attention.key\n","qformer.encoder.layer.10.attention.attention.value\n","qformer.encoder.layer.10.attention.attention.dropout\n","qformer.encoder.layer.10.attention.output\n","qformer.encoder.layer.10.attention.output.dense\n","qformer.encoder.layer.10.attention.output.LayerNorm\n","qformer.encoder.layer.10.attention.output.dropout\n","qformer.encoder.layer.10.crossattention\n","qformer.encoder.layer.10.crossattention.attention\n","qformer.encoder.layer.10.crossattention.attention.query\n","qformer.encoder.layer.10.crossattention.attention.key\n","qformer.encoder.layer.10.crossattention.attention.value\n","qformer.encoder.layer.10.crossattention.attention.dropout\n","qformer.encoder.layer.10.crossattention.output\n","qformer.encoder.layer.10.crossattention.output.dense\n","qformer.encoder.layer.10.crossattention.output.LayerNorm\n","qformer.encoder.layer.10.crossattention.output.dropout\n","qformer.encoder.layer.10.intermediate\n","qformer.encoder.layer.10.intermediate.dense\n","qformer.encoder.layer.10.intermediate.intermediate_act_fn\n","qformer.encoder.layer.10.output\n","qformer.encoder.layer.10.output.dense\n","qformer.encoder.layer.10.output.LayerNorm\n","qformer.encoder.layer.10.output.dropout\n","qformer.encoder.layer.10.intermediate_query\n","qformer.encoder.layer.10.intermediate_query.dense\n","qformer.encoder.layer.10.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.10.output_query\n","qformer.encoder.layer.10.output_query.dense\n","qformer.encoder.layer.10.output_query.LayerNorm\n","qformer.encoder.layer.10.output_query.dropout\n","qformer.encoder.layer.11\n","qformer.encoder.layer.11.attention\n","qformer.encoder.layer.11.attention.attention\n","qformer.encoder.layer.11.attention.attention.query\n","qformer.encoder.layer.11.attention.attention.key\n","qformer.encoder.layer.11.attention.attention.value\n","qformer.encoder.layer.11.attention.attention.dropout\n","qformer.encoder.layer.11.attention.output\n","qformer.encoder.layer.11.attention.output.dense\n","qformer.encoder.layer.11.attention.output.LayerNorm\n","qformer.encoder.layer.11.attention.output.dropout\n","qformer.encoder.layer.11.intermediate\n","qformer.encoder.layer.11.intermediate.dense\n","qformer.encoder.layer.11.intermediate.intermediate_act_fn\n","qformer.encoder.layer.11.output\n","qformer.encoder.layer.11.output.dense\n","qformer.encoder.layer.11.output.LayerNorm\n","qformer.encoder.layer.11.output.dropout\n","qformer.encoder.layer.11.intermediate_query\n","qformer.encoder.layer.11.intermediate_query.dense\n","qformer.encoder.layer.11.intermediate_query.intermediate_act_fn\n","qformer.encoder.layer.11.output_query\n","qformer.encoder.layer.11.output_query.dense\n","qformer.encoder.layer.11.output_query.LayerNorm\n","qformer.encoder.layer.11.output_query.dropout\n","language_projection\n","language_model\n","language_model.shared\n","language_model.encoder\n","language_model.encoder.block\n","language_model.encoder.block.0\n","language_model.encoder.block.0.layer\n","language_model.encoder.block.0.layer.0\n","language_model.encoder.block.0.layer.0.SelfAttention\n","language_model.encoder.block.0.layer.0.SelfAttention.q\n","language_model.encoder.block.0.layer.0.SelfAttention.k\n","language_model.encoder.block.0.layer.0.SelfAttention.v\n","language_model.encoder.block.0.layer.0.SelfAttention.o\n","language_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias\n","language_model.encoder.block.0.layer.0.layer_norm\n","language_model.encoder.block.0.layer.0.dropout\n","language_model.encoder.block.0.layer.1\n","language_model.encoder.block.0.layer.1.DenseReluDense\n","language_model.encoder.block.0.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.0.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.0.layer.1.DenseReluDense.wo\n","language_model.encoder.block.0.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.0.layer.1.DenseReluDense.act\n","language_model.encoder.block.0.layer.1.layer_norm\n","language_model.encoder.block.0.layer.1.dropout\n","language_model.encoder.block.1\n","language_model.encoder.block.1.layer\n","language_model.encoder.block.1.layer.0\n","language_model.encoder.block.1.layer.0.SelfAttention\n","language_model.encoder.block.1.layer.0.SelfAttention.q\n","language_model.encoder.block.1.layer.0.SelfAttention.k\n","language_model.encoder.block.1.layer.0.SelfAttention.v\n","language_model.encoder.block.1.layer.0.SelfAttention.o\n","language_model.encoder.block.1.layer.0.layer_norm\n","language_model.encoder.block.1.layer.0.dropout\n","language_model.encoder.block.1.layer.1\n","language_model.encoder.block.1.layer.1.DenseReluDense\n","language_model.encoder.block.1.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.1.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.1.layer.1.DenseReluDense.wo\n","language_model.encoder.block.1.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.1.layer.1.DenseReluDense.act\n","language_model.encoder.block.1.layer.1.layer_norm\n","language_model.encoder.block.1.layer.1.dropout\n","language_model.encoder.block.2\n","language_model.encoder.block.2.layer\n","language_model.encoder.block.2.layer.0\n","language_model.encoder.block.2.layer.0.SelfAttention\n","language_model.encoder.block.2.layer.0.SelfAttention.q\n","language_model.encoder.block.2.layer.0.SelfAttention.k\n","language_model.encoder.block.2.layer.0.SelfAttention.v\n","language_model.encoder.block.2.layer.0.SelfAttention.o\n","language_model.encoder.block.2.layer.0.layer_norm\n","language_model.encoder.block.2.layer.0.dropout\n","language_model.encoder.block.2.layer.1\n","language_model.encoder.block.2.layer.1.DenseReluDense\n","language_model.encoder.block.2.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.2.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.2.layer.1.DenseReluDense.wo\n","language_model.encoder.block.2.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.2.layer.1.DenseReluDense.act\n","language_model.encoder.block.2.layer.1.layer_norm\n","language_model.encoder.block.2.layer.1.dropout\n","language_model.encoder.block.3\n","language_model.encoder.block.3.layer\n","language_model.encoder.block.3.layer.0\n","language_model.encoder.block.3.layer.0.SelfAttention\n","language_model.encoder.block.3.layer.0.SelfAttention.q\n","language_model.encoder.block.3.layer.0.SelfAttention.k\n","language_model.encoder.block.3.layer.0.SelfAttention.v\n","language_model.encoder.block.3.layer.0.SelfAttention.o\n","language_model.encoder.block.3.layer.0.layer_norm\n","language_model.encoder.block.3.layer.0.dropout\n","language_model.encoder.block.3.layer.1\n","language_model.encoder.block.3.layer.1.DenseReluDense\n","language_model.encoder.block.3.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.3.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.3.layer.1.DenseReluDense.wo\n","language_model.encoder.block.3.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.3.layer.1.DenseReluDense.act\n","language_model.encoder.block.3.layer.1.layer_norm\n","language_model.encoder.block.3.layer.1.dropout\n","language_model.encoder.block.4\n","language_model.encoder.block.4.layer\n","language_model.encoder.block.4.layer.0\n","language_model.encoder.block.4.layer.0.SelfAttention\n","language_model.encoder.block.4.layer.0.SelfAttention.q\n","language_model.encoder.block.4.layer.0.SelfAttention.k\n","language_model.encoder.block.4.layer.0.SelfAttention.v\n","language_model.encoder.block.4.layer.0.SelfAttention.o\n","language_model.encoder.block.4.layer.0.layer_norm\n","language_model.encoder.block.4.layer.0.dropout\n","language_model.encoder.block.4.layer.1\n","language_model.encoder.block.4.layer.1.DenseReluDense\n","language_model.encoder.block.4.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.4.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.4.layer.1.DenseReluDense.wo\n","language_model.encoder.block.4.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.4.layer.1.DenseReluDense.act\n","language_model.encoder.block.4.layer.1.layer_norm\n","language_model.encoder.block.4.layer.1.dropout\n","language_model.encoder.block.5\n","language_model.encoder.block.5.layer\n","language_model.encoder.block.5.layer.0\n","language_model.encoder.block.5.layer.0.SelfAttention\n","language_model.encoder.block.5.layer.0.SelfAttention.q\n","language_model.encoder.block.5.layer.0.SelfAttention.k\n","language_model.encoder.block.5.layer.0.SelfAttention.v\n","language_model.encoder.block.5.layer.0.SelfAttention.o\n","language_model.encoder.block.5.layer.0.layer_norm\n","language_model.encoder.block.5.layer.0.dropout\n","language_model.encoder.block.5.layer.1\n","language_model.encoder.block.5.layer.1.DenseReluDense\n","language_model.encoder.block.5.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.5.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.5.layer.1.DenseReluDense.wo\n","language_model.encoder.block.5.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.5.layer.1.DenseReluDense.act\n","language_model.encoder.block.5.layer.1.layer_norm\n","language_model.encoder.block.5.layer.1.dropout\n","language_model.encoder.block.6\n","language_model.encoder.block.6.layer\n","language_model.encoder.block.6.layer.0\n","language_model.encoder.block.6.layer.0.SelfAttention\n","language_model.encoder.block.6.layer.0.SelfAttention.q\n","language_model.encoder.block.6.layer.0.SelfAttention.k\n","language_model.encoder.block.6.layer.0.SelfAttention.v\n","language_model.encoder.block.6.layer.0.SelfAttention.o\n","language_model.encoder.block.6.layer.0.layer_norm\n","language_model.encoder.block.6.layer.0.dropout\n","language_model.encoder.block.6.layer.1\n","language_model.encoder.block.6.layer.1.DenseReluDense\n","language_model.encoder.block.6.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.6.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.6.layer.1.DenseReluDense.wo\n","language_model.encoder.block.6.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.6.layer.1.DenseReluDense.act\n","language_model.encoder.block.6.layer.1.layer_norm\n","language_model.encoder.block.6.layer.1.dropout\n","language_model.encoder.block.7\n","language_model.encoder.block.7.layer\n","language_model.encoder.block.7.layer.0\n","language_model.encoder.block.7.layer.0.SelfAttention\n","language_model.encoder.block.7.layer.0.SelfAttention.q\n","language_model.encoder.block.7.layer.0.SelfAttention.k\n","language_model.encoder.block.7.layer.0.SelfAttention.v\n","language_model.encoder.block.7.layer.0.SelfAttention.o\n","language_model.encoder.block.7.layer.0.layer_norm\n","language_model.encoder.block.7.layer.0.dropout\n","language_model.encoder.block.7.layer.1\n","language_model.encoder.block.7.layer.1.DenseReluDense\n","language_model.encoder.block.7.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.7.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.7.layer.1.DenseReluDense.wo\n","language_model.encoder.block.7.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.7.layer.1.DenseReluDense.act\n","language_model.encoder.block.7.layer.1.layer_norm\n","language_model.encoder.block.7.layer.1.dropout\n","language_model.encoder.block.8\n","language_model.encoder.block.8.layer\n","language_model.encoder.block.8.layer.0\n","language_model.encoder.block.8.layer.0.SelfAttention\n","language_model.encoder.block.8.layer.0.SelfAttention.q\n","language_model.encoder.block.8.layer.0.SelfAttention.k\n","language_model.encoder.block.8.layer.0.SelfAttention.v\n","language_model.encoder.block.8.layer.0.SelfAttention.o\n","language_model.encoder.block.8.layer.0.layer_norm\n","language_model.encoder.block.8.layer.0.dropout\n","language_model.encoder.block.8.layer.1\n","language_model.encoder.block.8.layer.1.DenseReluDense\n","language_model.encoder.block.8.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.8.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.8.layer.1.DenseReluDense.wo\n","language_model.encoder.block.8.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.8.layer.1.DenseReluDense.act\n","language_model.encoder.block.8.layer.1.layer_norm\n","language_model.encoder.block.8.layer.1.dropout\n","language_model.encoder.block.9\n","language_model.encoder.block.9.layer\n","language_model.encoder.block.9.layer.0\n","language_model.encoder.block.9.layer.0.SelfAttention\n","language_model.encoder.block.9.layer.0.SelfAttention.q\n","language_model.encoder.block.9.layer.0.SelfAttention.k\n","language_model.encoder.block.9.layer.0.SelfAttention.v\n","language_model.encoder.block.9.layer.0.SelfAttention.o\n","language_model.encoder.block.9.layer.0.layer_norm\n","language_model.encoder.block.9.layer.0.dropout\n","language_model.encoder.block.9.layer.1\n","language_model.encoder.block.9.layer.1.DenseReluDense\n","language_model.encoder.block.9.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.9.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.9.layer.1.DenseReluDense.wo\n","language_model.encoder.block.9.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.9.layer.1.DenseReluDense.act\n","language_model.encoder.block.9.layer.1.layer_norm\n","language_model.encoder.block.9.layer.1.dropout\n","language_model.encoder.block.10\n","language_model.encoder.block.10.layer\n","language_model.encoder.block.10.layer.0\n","language_model.encoder.block.10.layer.0.SelfAttention\n","language_model.encoder.block.10.layer.0.SelfAttention.q\n","language_model.encoder.block.10.layer.0.SelfAttention.k\n","language_model.encoder.block.10.layer.0.SelfAttention.v\n","language_model.encoder.block.10.layer.0.SelfAttention.o\n","language_model.encoder.block.10.layer.0.layer_norm\n","language_model.encoder.block.10.layer.0.dropout\n","language_model.encoder.block.10.layer.1\n","language_model.encoder.block.10.layer.1.DenseReluDense\n","language_model.encoder.block.10.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.10.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.10.layer.1.DenseReluDense.wo\n","language_model.encoder.block.10.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.10.layer.1.DenseReluDense.act\n","language_model.encoder.block.10.layer.1.layer_norm\n","language_model.encoder.block.10.layer.1.dropout\n","language_model.encoder.block.11\n","language_model.encoder.block.11.layer\n","language_model.encoder.block.11.layer.0\n","language_model.encoder.block.11.layer.0.SelfAttention\n","language_model.encoder.block.11.layer.0.SelfAttention.q\n","language_model.encoder.block.11.layer.0.SelfAttention.k\n","language_model.encoder.block.11.layer.0.SelfAttention.v\n","language_model.encoder.block.11.layer.0.SelfAttention.o\n","language_model.encoder.block.11.layer.0.layer_norm\n","language_model.encoder.block.11.layer.0.dropout\n","language_model.encoder.block.11.layer.1\n","language_model.encoder.block.11.layer.1.DenseReluDense\n","language_model.encoder.block.11.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.11.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.11.layer.1.DenseReluDense.wo\n","language_model.encoder.block.11.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.11.layer.1.DenseReluDense.act\n","language_model.encoder.block.11.layer.1.layer_norm\n","language_model.encoder.block.11.layer.1.dropout\n","language_model.encoder.block.12\n","language_model.encoder.block.12.layer\n","language_model.encoder.block.12.layer.0\n","language_model.encoder.block.12.layer.0.SelfAttention\n","language_model.encoder.block.12.layer.0.SelfAttention.q\n","language_model.encoder.block.12.layer.0.SelfAttention.k\n","language_model.encoder.block.12.layer.0.SelfAttention.v\n","language_model.encoder.block.12.layer.0.SelfAttention.o\n","language_model.encoder.block.12.layer.0.layer_norm\n","language_model.encoder.block.12.layer.0.dropout\n","language_model.encoder.block.12.layer.1\n","language_model.encoder.block.12.layer.1.DenseReluDense\n","language_model.encoder.block.12.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.12.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.12.layer.1.DenseReluDense.wo\n","language_model.encoder.block.12.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.12.layer.1.DenseReluDense.act\n","language_model.encoder.block.12.layer.1.layer_norm\n","language_model.encoder.block.12.layer.1.dropout\n","language_model.encoder.block.13\n","language_model.encoder.block.13.layer\n","language_model.encoder.block.13.layer.0\n","language_model.encoder.block.13.layer.0.SelfAttention\n","language_model.encoder.block.13.layer.0.SelfAttention.q\n","language_model.encoder.block.13.layer.0.SelfAttention.k\n","language_model.encoder.block.13.layer.0.SelfAttention.v\n","language_model.encoder.block.13.layer.0.SelfAttention.o\n","language_model.encoder.block.13.layer.0.layer_norm\n","language_model.encoder.block.13.layer.0.dropout\n","language_model.encoder.block.13.layer.1\n","language_model.encoder.block.13.layer.1.DenseReluDense\n","language_model.encoder.block.13.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.13.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.13.layer.1.DenseReluDense.wo\n","language_model.encoder.block.13.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.13.layer.1.DenseReluDense.act\n","language_model.encoder.block.13.layer.1.layer_norm\n","language_model.encoder.block.13.layer.1.dropout\n","language_model.encoder.block.14\n","language_model.encoder.block.14.layer\n","language_model.encoder.block.14.layer.0\n","language_model.encoder.block.14.layer.0.SelfAttention\n","language_model.encoder.block.14.layer.0.SelfAttention.q\n","language_model.encoder.block.14.layer.0.SelfAttention.k\n","language_model.encoder.block.14.layer.0.SelfAttention.v\n","language_model.encoder.block.14.layer.0.SelfAttention.o\n","language_model.encoder.block.14.layer.0.layer_norm\n","language_model.encoder.block.14.layer.0.dropout\n","language_model.encoder.block.14.layer.1\n","language_model.encoder.block.14.layer.1.DenseReluDense\n","language_model.encoder.block.14.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.14.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.14.layer.1.DenseReluDense.wo\n","language_model.encoder.block.14.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.14.layer.1.DenseReluDense.act\n","language_model.encoder.block.14.layer.1.layer_norm\n","language_model.encoder.block.14.layer.1.dropout\n","language_model.encoder.block.15\n","language_model.encoder.block.15.layer\n","language_model.encoder.block.15.layer.0\n","language_model.encoder.block.15.layer.0.SelfAttention\n","language_model.encoder.block.15.layer.0.SelfAttention.q\n","language_model.encoder.block.15.layer.0.SelfAttention.k\n","language_model.encoder.block.15.layer.0.SelfAttention.v\n","language_model.encoder.block.15.layer.0.SelfAttention.o\n","language_model.encoder.block.15.layer.0.layer_norm\n","language_model.encoder.block.15.layer.0.dropout\n","language_model.encoder.block.15.layer.1\n","language_model.encoder.block.15.layer.1.DenseReluDense\n","language_model.encoder.block.15.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.15.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.15.layer.1.DenseReluDense.wo\n","language_model.encoder.block.15.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.15.layer.1.DenseReluDense.act\n","language_model.encoder.block.15.layer.1.layer_norm\n","language_model.encoder.block.15.layer.1.dropout\n","language_model.encoder.block.16\n","language_model.encoder.block.16.layer\n","language_model.encoder.block.16.layer.0\n","language_model.encoder.block.16.layer.0.SelfAttention\n","language_model.encoder.block.16.layer.0.SelfAttention.q\n","language_model.encoder.block.16.layer.0.SelfAttention.k\n","language_model.encoder.block.16.layer.0.SelfAttention.v\n","language_model.encoder.block.16.layer.0.SelfAttention.o\n","language_model.encoder.block.16.layer.0.layer_norm\n","language_model.encoder.block.16.layer.0.dropout\n","language_model.encoder.block.16.layer.1\n","language_model.encoder.block.16.layer.1.DenseReluDense\n","language_model.encoder.block.16.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.16.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.16.layer.1.DenseReluDense.wo\n","language_model.encoder.block.16.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.16.layer.1.DenseReluDense.act\n","language_model.encoder.block.16.layer.1.layer_norm\n","language_model.encoder.block.16.layer.1.dropout\n","language_model.encoder.block.17\n","language_model.encoder.block.17.layer\n","language_model.encoder.block.17.layer.0\n","language_model.encoder.block.17.layer.0.SelfAttention\n","language_model.encoder.block.17.layer.0.SelfAttention.q\n","language_model.encoder.block.17.layer.0.SelfAttention.k\n","language_model.encoder.block.17.layer.0.SelfAttention.v\n","language_model.encoder.block.17.layer.0.SelfAttention.o\n","language_model.encoder.block.17.layer.0.layer_norm\n","language_model.encoder.block.17.layer.0.dropout\n","language_model.encoder.block.17.layer.1\n","language_model.encoder.block.17.layer.1.DenseReluDense\n","language_model.encoder.block.17.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.17.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.17.layer.1.DenseReluDense.wo\n","language_model.encoder.block.17.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.17.layer.1.DenseReluDense.act\n","language_model.encoder.block.17.layer.1.layer_norm\n","language_model.encoder.block.17.layer.1.dropout\n","language_model.encoder.block.18\n","language_model.encoder.block.18.layer\n","language_model.encoder.block.18.layer.0\n","language_model.encoder.block.18.layer.0.SelfAttention\n","language_model.encoder.block.18.layer.0.SelfAttention.q\n","language_model.encoder.block.18.layer.0.SelfAttention.k\n","language_model.encoder.block.18.layer.0.SelfAttention.v\n","language_model.encoder.block.18.layer.0.SelfAttention.o\n","language_model.encoder.block.18.layer.0.layer_norm\n","language_model.encoder.block.18.layer.0.dropout\n","language_model.encoder.block.18.layer.1\n","language_model.encoder.block.18.layer.1.DenseReluDense\n","language_model.encoder.block.18.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.18.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.18.layer.1.DenseReluDense.wo\n","language_model.encoder.block.18.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.18.layer.1.DenseReluDense.act\n","language_model.encoder.block.18.layer.1.layer_norm\n","language_model.encoder.block.18.layer.1.dropout\n","language_model.encoder.block.19\n","language_model.encoder.block.19.layer\n","language_model.encoder.block.19.layer.0\n","language_model.encoder.block.19.layer.0.SelfAttention\n","language_model.encoder.block.19.layer.0.SelfAttention.q\n","language_model.encoder.block.19.layer.0.SelfAttention.k\n","language_model.encoder.block.19.layer.0.SelfAttention.v\n","language_model.encoder.block.19.layer.0.SelfAttention.o\n","language_model.encoder.block.19.layer.0.layer_norm\n","language_model.encoder.block.19.layer.0.dropout\n","language_model.encoder.block.19.layer.1\n","language_model.encoder.block.19.layer.1.DenseReluDense\n","language_model.encoder.block.19.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.19.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.19.layer.1.DenseReluDense.wo\n","language_model.encoder.block.19.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.19.layer.1.DenseReluDense.act\n","language_model.encoder.block.19.layer.1.layer_norm\n","language_model.encoder.block.19.layer.1.dropout\n","language_model.encoder.block.20\n","language_model.encoder.block.20.layer\n","language_model.encoder.block.20.layer.0\n","language_model.encoder.block.20.layer.0.SelfAttention\n","language_model.encoder.block.20.layer.0.SelfAttention.q\n","language_model.encoder.block.20.layer.0.SelfAttention.k\n","language_model.encoder.block.20.layer.0.SelfAttention.v\n","language_model.encoder.block.20.layer.0.SelfAttention.o\n","language_model.encoder.block.20.layer.0.layer_norm\n","language_model.encoder.block.20.layer.0.dropout\n","language_model.encoder.block.20.layer.1\n","language_model.encoder.block.20.layer.1.DenseReluDense\n","language_model.encoder.block.20.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.20.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.20.layer.1.DenseReluDense.wo\n","language_model.encoder.block.20.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.20.layer.1.DenseReluDense.act\n","language_model.encoder.block.20.layer.1.layer_norm\n","language_model.encoder.block.20.layer.1.dropout\n","language_model.encoder.block.21\n","language_model.encoder.block.21.layer\n","language_model.encoder.block.21.layer.0\n","language_model.encoder.block.21.layer.0.SelfAttention\n","language_model.encoder.block.21.layer.0.SelfAttention.q\n","language_model.encoder.block.21.layer.0.SelfAttention.k\n","language_model.encoder.block.21.layer.0.SelfAttention.v\n","language_model.encoder.block.21.layer.0.SelfAttention.o\n","language_model.encoder.block.21.layer.0.layer_norm\n","language_model.encoder.block.21.layer.0.dropout\n","language_model.encoder.block.21.layer.1\n","language_model.encoder.block.21.layer.1.DenseReluDense\n","language_model.encoder.block.21.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.21.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.21.layer.1.DenseReluDense.wo\n","language_model.encoder.block.21.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.21.layer.1.DenseReluDense.act\n","language_model.encoder.block.21.layer.1.layer_norm\n","language_model.encoder.block.21.layer.1.dropout\n","language_model.encoder.block.22\n","language_model.encoder.block.22.layer\n","language_model.encoder.block.22.layer.0\n","language_model.encoder.block.22.layer.0.SelfAttention\n","language_model.encoder.block.22.layer.0.SelfAttention.q\n","language_model.encoder.block.22.layer.0.SelfAttention.k\n","language_model.encoder.block.22.layer.0.SelfAttention.v\n","language_model.encoder.block.22.layer.0.SelfAttention.o\n","language_model.encoder.block.22.layer.0.layer_norm\n","language_model.encoder.block.22.layer.0.dropout\n","language_model.encoder.block.22.layer.1\n","language_model.encoder.block.22.layer.1.DenseReluDense\n","language_model.encoder.block.22.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.22.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.22.layer.1.DenseReluDense.wo\n","language_model.encoder.block.22.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.22.layer.1.DenseReluDense.act\n","language_model.encoder.block.22.layer.1.layer_norm\n","language_model.encoder.block.22.layer.1.dropout\n","language_model.encoder.block.23\n","language_model.encoder.block.23.layer\n","language_model.encoder.block.23.layer.0\n","language_model.encoder.block.23.layer.0.SelfAttention\n","language_model.encoder.block.23.layer.0.SelfAttention.q\n","language_model.encoder.block.23.layer.0.SelfAttention.k\n","language_model.encoder.block.23.layer.0.SelfAttention.v\n","language_model.encoder.block.23.layer.0.SelfAttention.o\n","language_model.encoder.block.23.layer.0.layer_norm\n","language_model.encoder.block.23.layer.0.dropout\n","language_model.encoder.block.23.layer.1\n","language_model.encoder.block.23.layer.1.DenseReluDense\n","language_model.encoder.block.23.layer.1.DenseReluDense.wi_0\n","language_model.encoder.block.23.layer.1.DenseReluDense.wi_1\n","language_model.encoder.block.23.layer.1.DenseReluDense.wo\n","language_model.encoder.block.23.layer.1.DenseReluDense.dropout\n","language_model.encoder.block.23.layer.1.DenseReluDense.act\n","language_model.encoder.block.23.layer.1.layer_norm\n","language_model.encoder.block.23.layer.1.dropout\n","language_model.encoder.final_layer_norm\n","language_model.encoder.dropout\n","language_model.decoder\n","language_model.decoder.block\n","language_model.decoder.block.0\n","language_model.decoder.block.0.layer\n","language_model.decoder.block.0.layer.0\n","language_model.decoder.block.0.layer.0.SelfAttention\n","language_model.decoder.block.0.layer.0.SelfAttention.q\n","language_model.decoder.block.0.layer.0.SelfAttention.k\n","language_model.decoder.block.0.layer.0.SelfAttention.v\n","language_model.decoder.block.0.layer.0.SelfAttention.o\n","language_model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias\n","language_model.decoder.block.0.layer.0.layer_norm\n","language_model.decoder.block.0.layer.0.dropout\n","language_model.decoder.block.0.layer.1\n","language_model.decoder.block.0.layer.1.EncDecAttention\n","language_model.decoder.block.0.layer.1.EncDecAttention.q\n","language_model.decoder.block.0.layer.1.EncDecAttention.k\n","language_model.decoder.block.0.layer.1.EncDecAttention.v\n","language_model.decoder.block.0.layer.1.EncDecAttention.o\n","language_model.decoder.block.0.layer.1.layer_norm\n","language_model.decoder.block.0.layer.1.dropout\n","language_model.decoder.block.0.layer.2\n","language_model.decoder.block.0.layer.2.DenseReluDense\n","language_model.decoder.block.0.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.0.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.0.layer.2.DenseReluDense.wo\n","language_model.decoder.block.0.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.0.layer.2.DenseReluDense.act\n","language_model.decoder.block.0.layer.2.layer_norm\n","language_model.decoder.block.0.layer.2.dropout\n","language_model.decoder.block.1\n","language_model.decoder.block.1.layer\n","language_model.decoder.block.1.layer.0\n","language_model.decoder.block.1.layer.0.SelfAttention\n","language_model.decoder.block.1.layer.0.SelfAttention.q\n","language_model.decoder.block.1.layer.0.SelfAttention.k\n","language_model.decoder.block.1.layer.0.SelfAttention.v\n","language_model.decoder.block.1.layer.0.SelfAttention.o\n","language_model.decoder.block.1.layer.0.layer_norm\n","language_model.decoder.block.1.layer.0.dropout\n","language_model.decoder.block.1.layer.1\n","language_model.decoder.block.1.layer.1.EncDecAttention\n","language_model.decoder.block.1.layer.1.EncDecAttention.q\n","language_model.decoder.block.1.layer.1.EncDecAttention.k\n","language_model.decoder.block.1.layer.1.EncDecAttention.v\n","language_model.decoder.block.1.layer.1.EncDecAttention.o\n","language_model.decoder.block.1.layer.1.layer_norm\n","language_model.decoder.block.1.layer.1.dropout\n","language_model.decoder.block.1.layer.2\n","language_model.decoder.block.1.layer.2.DenseReluDense\n","language_model.decoder.block.1.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.1.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.1.layer.2.DenseReluDense.wo\n","language_model.decoder.block.1.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.1.layer.2.DenseReluDense.act\n","language_model.decoder.block.1.layer.2.layer_norm\n","language_model.decoder.block.1.layer.2.dropout\n","language_model.decoder.block.2\n","language_model.decoder.block.2.layer\n","language_model.decoder.block.2.layer.0\n","language_model.decoder.block.2.layer.0.SelfAttention\n","language_model.decoder.block.2.layer.0.SelfAttention.q\n","language_model.decoder.block.2.layer.0.SelfAttention.k\n","language_model.decoder.block.2.layer.0.SelfAttention.v\n","language_model.decoder.block.2.layer.0.SelfAttention.o\n","language_model.decoder.block.2.layer.0.layer_norm\n","language_model.decoder.block.2.layer.0.dropout\n","language_model.decoder.block.2.layer.1\n","language_model.decoder.block.2.layer.1.EncDecAttention\n","language_model.decoder.block.2.layer.1.EncDecAttention.q\n","language_model.decoder.block.2.layer.1.EncDecAttention.k\n","language_model.decoder.block.2.layer.1.EncDecAttention.v\n","language_model.decoder.block.2.layer.1.EncDecAttention.o\n","language_model.decoder.block.2.layer.1.layer_norm\n","language_model.decoder.block.2.layer.1.dropout\n","language_model.decoder.block.2.layer.2\n","language_model.decoder.block.2.layer.2.DenseReluDense\n","language_model.decoder.block.2.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.2.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.2.layer.2.DenseReluDense.wo\n","language_model.decoder.block.2.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.2.layer.2.DenseReluDense.act\n","language_model.decoder.block.2.layer.2.layer_norm\n","language_model.decoder.block.2.layer.2.dropout\n","language_model.decoder.block.3\n","language_model.decoder.block.3.layer\n","language_model.decoder.block.3.layer.0\n","language_model.decoder.block.3.layer.0.SelfAttention\n","language_model.decoder.block.3.layer.0.SelfAttention.q\n","language_model.decoder.block.3.layer.0.SelfAttention.k\n","language_model.decoder.block.3.layer.0.SelfAttention.v\n","language_model.decoder.block.3.layer.0.SelfAttention.o\n","language_model.decoder.block.3.layer.0.layer_norm\n","language_model.decoder.block.3.layer.0.dropout\n","language_model.decoder.block.3.layer.1\n","language_model.decoder.block.3.layer.1.EncDecAttention\n","language_model.decoder.block.3.layer.1.EncDecAttention.q\n","language_model.decoder.block.3.layer.1.EncDecAttention.k\n","language_model.decoder.block.3.layer.1.EncDecAttention.v\n","language_model.decoder.block.3.layer.1.EncDecAttention.o\n","language_model.decoder.block.3.layer.1.layer_norm\n","language_model.decoder.block.3.layer.1.dropout\n","language_model.decoder.block.3.layer.2\n","language_model.decoder.block.3.layer.2.DenseReluDense\n","language_model.decoder.block.3.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.3.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.3.layer.2.DenseReluDense.wo\n","language_model.decoder.block.3.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.3.layer.2.DenseReluDense.act\n","language_model.decoder.block.3.layer.2.layer_norm\n","language_model.decoder.block.3.layer.2.dropout\n","language_model.decoder.block.4\n","language_model.decoder.block.4.layer\n","language_model.decoder.block.4.layer.0\n","language_model.decoder.block.4.layer.0.SelfAttention\n","language_model.decoder.block.4.layer.0.SelfAttention.q\n","language_model.decoder.block.4.layer.0.SelfAttention.k\n","language_model.decoder.block.4.layer.0.SelfAttention.v\n","language_model.decoder.block.4.layer.0.SelfAttention.o\n","language_model.decoder.block.4.layer.0.layer_norm\n","language_model.decoder.block.4.layer.0.dropout\n","language_model.decoder.block.4.layer.1\n","language_model.decoder.block.4.layer.1.EncDecAttention\n","language_model.decoder.block.4.layer.1.EncDecAttention.q\n","language_model.decoder.block.4.layer.1.EncDecAttention.k\n","language_model.decoder.block.4.layer.1.EncDecAttention.v\n","language_model.decoder.block.4.layer.1.EncDecAttention.o\n","language_model.decoder.block.4.layer.1.layer_norm\n","language_model.decoder.block.4.layer.1.dropout\n","language_model.decoder.block.4.layer.2\n","language_model.decoder.block.4.layer.2.DenseReluDense\n","language_model.decoder.block.4.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.4.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.4.layer.2.DenseReluDense.wo\n","language_model.decoder.block.4.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.4.layer.2.DenseReluDense.act\n","language_model.decoder.block.4.layer.2.layer_norm\n","language_model.decoder.block.4.layer.2.dropout\n","language_model.decoder.block.5\n","language_model.decoder.block.5.layer\n","language_model.decoder.block.5.layer.0\n","language_model.decoder.block.5.layer.0.SelfAttention\n","language_model.decoder.block.5.layer.0.SelfAttention.q\n","language_model.decoder.block.5.layer.0.SelfAttention.k\n","language_model.decoder.block.5.layer.0.SelfAttention.v\n","language_model.decoder.block.5.layer.0.SelfAttention.o\n","language_model.decoder.block.5.layer.0.layer_norm\n","language_model.decoder.block.5.layer.0.dropout\n","language_model.decoder.block.5.layer.1\n","language_model.decoder.block.5.layer.1.EncDecAttention\n","language_model.decoder.block.5.layer.1.EncDecAttention.q\n","language_model.decoder.block.5.layer.1.EncDecAttention.k\n","language_model.decoder.block.5.layer.1.EncDecAttention.v\n","language_model.decoder.block.5.layer.1.EncDecAttention.o\n","language_model.decoder.block.5.layer.1.layer_norm\n","language_model.decoder.block.5.layer.1.dropout\n","language_model.decoder.block.5.layer.2\n","language_model.decoder.block.5.layer.2.DenseReluDense\n","language_model.decoder.block.5.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.5.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.5.layer.2.DenseReluDense.wo\n","language_model.decoder.block.5.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.5.layer.2.DenseReluDense.act\n","language_model.decoder.block.5.layer.2.layer_norm\n","language_model.decoder.block.5.layer.2.dropout\n","language_model.decoder.block.6\n","language_model.decoder.block.6.layer\n","language_model.decoder.block.6.layer.0\n","language_model.decoder.block.6.layer.0.SelfAttention\n","language_model.decoder.block.6.layer.0.SelfAttention.q\n","language_model.decoder.block.6.layer.0.SelfAttention.k\n","language_model.decoder.block.6.layer.0.SelfAttention.v\n","language_model.decoder.block.6.layer.0.SelfAttention.o\n","language_model.decoder.block.6.layer.0.layer_norm\n","language_model.decoder.block.6.layer.0.dropout\n","language_model.decoder.block.6.layer.1\n","language_model.decoder.block.6.layer.1.EncDecAttention\n","language_model.decoder.block.6.layer.1.EncDecAttention.q\n","language_model.decoder.block.6.layer.1.EncDecAttention.k\n","language_model.decoder.block.6.layer.1.EncDecAttention.v\n","language_model.decoder.block.6.layer.1.EncDecAttention.o\n","language_model.decoder.block.6.layer.1.layer_norm\n","language_model.decoder.block.6.layer.1.dropout\n","language_model.decoder.block.6.layer.2\n","language_model.decoder.block.6.layer.2.DenseReluDense\n","language_model.decoder.block.6.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.6.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.6.layer.2.DenseReluDense.wo\n","language_model.decoder.block.6.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.6.layer.2.DenseReluDense.act\n","language_model.decoder.block.6.layer.2.layer_norm\n","language_model.decoder.block.6.layer.2.dropout\n","language_model.decoder.block.7\n","language_model.decoder.block.7.layer\n","language_model.decoder.block.7.layer.0\n","language_model.decoder.block.7.layer.0.SelfAttention\n","language_model.decoder.block.7.layer.0.SelfAttention.q\n","language_model.decoder.block.7.layer.0.SelfAttention.k\n","language_model.decoder.block.7.layer.0.SelfAttention.v\n","language_model.decoder.block.7.layer.0.SelfAttention.o\n","language_model.decoder.block.7.layer.0.layer_norm\n","language_model.decoder.block.7.layer.0.dropout\n","language_model.decoder.block.7.layer.1\n","language_model.decoder.block.7.layer.1.EncDecAttention\n","language_model.decoder.block.7.layer.1.EncDecAttention.q\n","language_model.decoder.block.7.layer.1.EncDecAttention.k\n","language_model.decoder.block.7.layer.1.EncDecAttention.v\n","language_model.decoder.block.7.layer.1.EncDecAttention.o\n","language_model.decoder.block.7.layer.1.layer_norm\n","language_model.decoder.block.7.layer.1.dropout\n","language_model.decoder.block.7.layer.2\n","language_model.decoder.block.7.layer.2.DenseReluDense\n","language_model.decoder.block.7.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.7.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.7.layer.2.DenseReluDense.wo\n","language_model.decoder.block.7.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.7.layer.2.DenseReluDense.act\n","language_model.decoder.block.7.layer.2.layer_norm\n","language_model.decoder.block.7.layer.2.dropout\n","language_model.decoder.block.8\n","language_model.decoder.block.8.layer\n","language_model.decoder.block.8.layer.0\n","language_model.decoder.block.8.layer.0.SelfAttention\n","language_model.decoder.block.8.layer.0.SelfAttention.q\n","language_model.decoder.block.8.layer.0.SelfAttention.k\n","language_model.decoder.block.8.layer.0.SelfAttention.v\n","language_model.decoder.block.8.layer.0.SelfAttention.o\n","language_model.decoder.block.8.layer.0.layer_norm\n","language_model.decoder.block.8.layer.0.dropout\n","language_model.decoder.block.8.layer.1\n","language_model.decoder.block.8.layer.1.EncDecAttention\n","language_model.decoder.block.8.layer.1.EncDecAttention.q\n","language_model.decoder.block.8.layer.1.EncDecAttention.k\n","language_model.decoder.block.8.layer.1.EncDecAttention.v\n","language_model.decoder.block.8.layer.1.EncDecAttention.o\n","language_model.decoder.block.8.layer.1.layer_norm\n","language_model.decoder.block.8.layer.1.dropout\n","language_model.decoder.block.8.layer.2\n","language_model.decoder.block.8.layer.2.DenseReluDense\n","language_model.decoder.block.8.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.8.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.8.layer.2.DenseReluDense.wo\n","language_model.decoder.block.8.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.8.layer.2.DenseReluDense.act\n","language_model.decoder.block.8.layer.2.layer_norm\n","language_model.decoder.block.8.layer.2.dropout\n","language_model.decoder.block.9\n","language_model.decoder.block.9.layer\n","language_model.decoder.block.9.layer.0\n","language_model.decoder.block.9.layer.0.SelfAttention\n","language_model.decoder.block.9.layer.0.SelfAttention.q\n","language_model.decoder.block.9.layer.0.SelfAttention.k\n","language_model.decoder.block.9.layer.0.SelfAttention.v\n","language_model.decoder.block.9.layer.0.SelfAttention.o\n","language_model.decoder.block.9.layer.0.layer_norm\n","language_model.decoder.block.9.layer.0.dropout\n","language_model.decoder.block.9.layer.1\n","language_model.decoder.block.9.layer.1.EncDecAttention\n","language_model.decoder.block.9.layer.1.EncDecAttention.q\n","language_model.decoder.block.9.layer.1.EncDecAttention.k\n","language_model.decoder.block.9.layer.1.EncDecAttention.v\n","language_model.decoder.block.9.layer.1.EncDecAttention.o\n","language_model.decoder.block.9.layer.1.layer_norm\n","language_model.decoder.block.9.layer.1.dropout\n","language_model.decoder.block.9.layer.2\n","language_model.decoder.block.9.layer.2.DenseReluDense\n","language_model.decoder.block.9.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.9.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.9.layer.2.DenseReluDense.wo\n","language_model.decoder.block.9.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.9.layer.2.DenseReluDense.act\n","language_model.decoder.block.9.layer.2.layer_norm\n","language_model.decoder.block.9.layer.2.dropout\n","language_model.decoder.block.10\n","language_model.decoder.block.10.layer\n","language_model.decoder.block.10.layer.0\n","language_model.decoder.block.10.layer.0.SelfAttention\n","language_model.decoder.block.10.layer.0.SelfAttention.q\n","language_model.decoder.block.10.layer.0.SelfAttention.k\n","language_model.decoder.block.10.layer.0.SelfAttention.v\n","language_model.decoder.block.10.layer.0.SelfAttention.o\n","language_model.decoder.block.10.layer.0.layer_norm\n","language_model.decoder.block.10.layer.0.dropout\n","language_model.decoder.block.10.layer.1\n","language_model.decoder.block.10.layer.1.EncDecAttention\n","language_model.decoder.block.10.layer.1.EncDecAttention.q\n","language_model.decoder.block.10.layer.1.EncDecAttention.k\n","language_model.decoder.block.10.layer.1.EncDecAttention.v\n","language_model.decoder.block.10.layer.1.EncDecAttention.o\n","language_model.decoder.block.10.layer.1.layer_norm\n","language_model.decoder.block.10.layer.1.dropout\n","language_model.decoder.block.10.layer.2\n","language_model.decoder.block.10.layer.2.DenseReluDense\n","language_model.decoder.block.10.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.10.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.10.layer.2.DenseReluDense.wo\n","language_model.decoder.block.10.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.10.layer.2.DenseReluDense.act\n","language_model.decoder.block.10.layer.2.layer_norm\n","language_model.decoder.block.10.layer.2.dropout\n","language_model.decoder.block.11\n","language_model.decoder.block.11.layer\n","language_model.decoder.block.11.layer.0\n","language_model.decoder.block.11.layer.0.SelfAttention\n","language_model.decoder.block.11.layer.0.SelfAttention.q\n","language_model.decoder.block.11.layer.0.SelfAttention.k\n","language_model.decoder.block.11.layer.0.SelfAttention.v\n","language_model.decoder.block.11.layer.0.SelfAttention.o\n","language_model.decoder.block.11.layer.0.layer_norm\n","language_model.decoder.block.11.layer.0.dropout\n","language_model.decoder.block.11.layer.1\n","language_model.decoder.block.11.layer.1.EncDecAttention\n","language_model.decoder.block.11.layer.1.EncDecAttention.q\n","language_model.decoder.block.11.layer.1.EncDecAttention.k\n","language_model.decoder.block.11.layer.1.EncDecAttention.v\n","language_model.decoder.block.11.layer.1.EncDecAttention.o\n","language_model.decoder.block.11.layer.1.layer_norm\n","language_model.decoder.block.11.layer.1.dropout\n","language_model.decoder.block.11.layer.2\n","language_model.decoder.block.11.layer.2.DenseReluDense\n","language_model.decoder.block.11.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.11.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.11.layer.2.DenseReluDense.wo\n","language_model.decoder.block.11.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.11.layer.2.DenseReluDense.act\n","language_model.decoder.block.11.layer.2.layer_norm\n","language_model.decoder.block.11.layer.2.dropout"]}]},{"cell_type":"code","source":["model = prepare_model_for_kbit_training(model)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=64,\n","    target_modules=[\"q\", \"k\", \"v\", \"o\"],\n","    # target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n","    lora_dropout=0.1,\n","    bias=\"none\",\n","    task_type=\"SEQ_2_SEQ_LM\",\n","    # task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, lora_config)\n","print(\"LoRA 파인튜닝 설정 완료.\")"],"metadata":{"id":"ToqsDYspeEgt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731126410361,"user_tz":-540,"elapsed":1109,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"bc774580-1f09-455c-f164-8e306a64f08d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","language_model.decoder.block.12\n","language_model.decoder.block.12.layer\n","language_model.decoder.block.12.layer.0\n","language_model.decoder.block.12.layer.0.SelfAttention\n","language_model.decoder.block.12.layer.0.SelfAttention.q\n","language_model.decoder.block.12.layer.0.SelfAttention.k\n","language_model.decoder.block.12.layer.0.SelfAttention.v\n","language_model.decoder.block.12.layer.0.SelfAttention.o\n","language_model.decoder.block.12.layer.0.layer_norm\n","language_model.decoder.block.12.layer.0.dropout\n","language_model.decoder.block.12.layer.1\n","language_model.decoder.block.12.layer.1.EncDecAttention\n","language_model.decoder.block.12.layer.1.EncDecAttention.q\n","language_model.decoder.block.12.layer.1.EncDecAttention.k\n","language_model.decoder.block.12.layer.1.EncDecAttention.v\n","language_model.decoder.block.12.layer.1.EncDecAttention.o\n","language_model.decoder.block.12.layer.1.layer_norm\n","language_model.decoder.block.12.layer.1.dropout\n","language_model.decoder.block.12.layer.2\n","language_model.decoder.block.12.layer.2.DenseReluDense\n","language_model.decoder.block.12.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.12.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.12.layer.2.DenseReluDense.wo\n","language_model.decoder.block.12.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.12.layer.2.DenseReluDense.act\n","language_model.decoder.block.12.layer.2.layer_norm\n","language_model.decoder.block.12.layer.2.dropout\n","language_model.decoder.block.13\n","language_model.decoder.block.13.layer\n","language_model.decoder.block.13.layer.0\n","language_model.decoder.block.13.layer.0.SelfAttention\n","language_model.decoder.block.13.layer.0.SelfAttention.q\n","language_model.decoder.block.13.layer.0.SelfAttention.k\n","language_model.decoder.block.13.layer.0.SelfAttention.v\n","language_model.decoder.block.13.layer.0.SelfAttention.o\n","language_model.decoder.block.13.layer.0.layer_norm\n","language_model.decoder.block.13.layer.0.dropout\n","language_model.decoder.block.13.layer.1\n","language_model.decoder.block.13.layer.1.EncDecAttention\n","language_model.decoder.block.13.layer.1.EncDecAttention.q\n","language_model.decoder.block.13.layer.1.EncDecAttention.k\n","language_model.decoder.block.13.layer.1.EncDecAttention.v\n","language_model.decoder.block.13.layer.1.EncDecAttention.o\n","language_model.decoder.block.13.layer.1.layer_norm\n","language_model.decoder.block.13.layer.1.dropout\n","language_model.decoder.block.13.layer.2\n","language_model.decoder.block.13.layer.2.DenseReluDense\n","language_model.decoder.block.13.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.13.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.13.layer.2.DenseReluDense.wo\n","language_model.decoder.block.13.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.13.layer.2.DenseReluDense.act\n","language_model.decoder.block.13.layer.2.layer_norm\n","language_model.decoder.block.13.layer.2.dropout\n","language_model.decoder.block.14\n","language_model.decoder.block.14.layer\n","language_model.decoder.block.14.layer.0\n","language_model.decoder.block.14.layer.0.SelfAttention\n","language_model.decoder.block.14.layer.0.SelfAttention.q\n","language_model.decoder.block.14.layer.0.SelfAttention.k\n","language_model.decoder.block.14.layer.0.SelfAttention.v\n","language_model.decoder.block.14.layer.0.SelfAttention.o\n","language_model.decoder.block.14.layer.0.layer_norm\n","language_model.decoder.block.14.layer.0.dropout\n","language_model.decoder.block.14.layer.1\n","language_model.decoder.block.14.layer.1.EncDecAttention\n","language_model.decoder.block.14.layer.1.EncDecAttention.q\n","language_model.decoder.block.14.layer.1.EncDecAttention.k\n","language_model.decoder.block.14.layer.1.EncDecAttention.v\n","language_model.decoder.block.14.layer.1.EncDecAttention.o\n","language_model.decoder.block.14.layer.1.layer_norm\n","language_model.decoder.block.14.layer.1.dropout\n","language_model.decoder.block.14.layer.2\n","language_model.decoder.block.14.layer.2.DenseReluDense\n","language_model.decoder.block.14.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.14.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.14.layer.2.DenseReluDense.wo\n","language_model.decoder.block.14.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.14.layer.2.DenseReluDense.act\n","language_model.decoder.block.14.layer.2.layer_norm\n","language_model.decoder.block.14.layer.2.dropout\n","language_model.decoder.block.15\n","language_model.decoder.block.15.layer\n","language_model.decoder.block.15.layer.0\n","language_model.decoder.block.15.layer.0.SelfAttention\n","language_model.decoder.block.15.layer.0.SelfAttention.q\n","language_model.decoder.block.15.layer.0.SelfAttention.k\n","language_model.decoder.block.15.layer.0.SelfAttention.v\n","language_model.decoder.block.15.layer.0.SelfAttention.o\n","language_model.decoder.block.15.layer.0.layer_norm\n","language_model.decoder.block.15.layer.0.dropout\n","language_model.decoder.block.15.layer.1\n","language_model.decoder.block.15.layer.1.EncDecAttention\n","language_model.decoder.block.15.layer.1.EncDecAttention.q\n","language_model.decoder.block.15.layer.1.EncDecAttention.k\n","language_model.decoder.block.15.layer.1.EncDecAttention.v\n","language_model.decoder.block.15.layer.1.EncDecAttention.o\n","language_model.decoder.block.15.layer.1.layer_norm\n","language_model.decoder.block.15.layer.1.dropout\n","language_model.decoder.block.15.layer.2\n","language_model.decoder.block.15.layer.2.DenseReluDense\n","language_model.decoder.block.15.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.15.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.15.layer.2.DenseReluDense.wo\n","language_model.decoder.block.15.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.15.layer.2.DenseReluDense.act\n","language_model.decoder.block.15.layer.2.layer_norm\n","language_model.decoder.block.15.layer.2.dropout\n","language_model.decoder.block.16\n","language_model.decoder.block.16.layer\n","language_model.decoder.block.16.layer.0\n","language_model.decoder.block.16.layer.0.SelfAttention\n","language_model.decoder.block.16.layer.0.SelfAttention.q\n","language_model.decoder.block.16.layer.0.SelfAttention.k\n","language_model.decoder.block.16.layer.0.SelfAttention.v\n","language_model.decoder.block.16.layer.0.SelfAttention.o\n","language_model.decoder.block.16.layer.0.layer_norm\n","language_model.decoder.block.16.layer.0.dropout\n","language_model.decoder.block.16.layer.1\n","language_model.decoder.block.16.layer.1.EncDecAttention\n","language_model.decoder.block.16.layer.1.EncDecAttention.q\n","language_model.decoder.block.16.layer.1.EncDecAttention.k\n","language_model.decoder.block.16.layer.1.EncDecAttention.v\n","language_model.decoder.block.16.layer.1.EncDecAttention.o\n","language_model.decoder.block.16.layer.1.layer_norm\n","language_model.decoder.block.16.layer.1.dropout\n","language_model.decoder.block.16.layer.2\n","language_model.decoder.block.16.layer.2.DenseReluDense\n","language_model.decoder.block.16.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.16.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.16.layer.2.DenseReluDense.wo\n","language_model.decoder.block.16.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.16.layer.2.DenseReluDense.act\n","language_model.decoder.block.16.layer.2.layer_norm\n","language_model.decoder.block.16.layer.2.dropout\n","language_model.decoder.block.17\n","language_model.decoder.block.17.layer\n","language_model.decoder.block.17.layer.0\n","language_model.decoder.block.17.layer.0.SelfAttention\n","language_model.decoder.block.17.layer.0.SelfAttention.q\n","language_model.decoder.block.17.layer.0.SelfAttention.k\n","language_model.decoder.block.17.layer.0.SelfAttention.v\n","language_model.decoder.block.17.layer.0.SelfAttention.o\n","language_model.decoder.block.17.layer.0.layer_norm\n","language_model.decoder.block.17.layer.0.dropout\n","language_model.decoder.block.17.layer.1\n","language_model.decoder.block.17.layer.1.EncDecAttention\n","language_model.decoder.block.17.layer.1.EncDecAttention.q\n","language_model.decoder.block.17.layer.1.EncDecAttention.k\n","language_model.decoder.block.17.layer.1.EncDecAttention.v\n","language_model.decoder.block.17.layer.1.EncDecAttention.o\n","language_model.decoder.block.17.layer.1.layer_norm\n","language_model.decoder.block.17.layer.1.dropout\n","language_model.decoder.block.17.layer.2\n","language_model.decoder.block.17.layer.2.DenseReluDense\n","language_model.decoder.block.17.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.17.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.17.layer.2.DenseReluDense.wo\n","language_model.decoder.block.17.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.17.layer.2.DenseReluDense.act\n","language_model.decoder.block.17.layer.2.layer_norm\n","language_model.decoder.block.17.layer.2.dropout\n","language_model.decoder.block.18\n","language_model.decoder.block.18.layer\n","language_model.decoder.block.18.layer.0\n","language_model.decoder.block.18.layer.0.SelfAttention\n","language_model.decoder.block.18.layer.0.SelfAttention.q\n","language_model.decoder.block.18.layer.0.SelfAttention.k\n","language_model.decoder.block.18.layer.0.SelfAttention.v\n","language_model.decoder.block.18.layer.0.SelfAttention.o\n","language_model.decoder.block.18.layer.0.layer_norm\n","language_model.decoder.block.18.layer.0.dropout\n","language_model.decoder.block.18.layer.1\n","language_model.decoder.block.18.layer.1.EncDecAttention\n","language_model.decoder.block.18.layer.1.EncDecAttention.q\n","language_model.decoder.block.18.layer.1.EncDecAttention.k\n","language_model.decoder.block.18.layer.1.EncDecAttention.v\n","language_model.decoder.block.18.layer.1.EncDecAttention.o\n","language_model.decoder.block.18.layer.1.layer_norm\n","language_model.decoder.block.18.layer.1.dropout\n","language_model.decoder.block.18.layer.2\n","language_model.decoder.block.18.layer.2.DenseReluDense\n","language_model.decoder.block.18.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.18.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.18.layer.2.DenseReluDense.wo\n","language_model.decoder.block.18.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.18.layer.2.DenseReluDense.act\n","language_model.decoder.block.18.layer.2.layer_norm\n","language_model.decoder.block.18.layer.2.dropout\n","language_model.decoder.block.19\n","language_model.decoder.block.19.layer\n","language_model.decoder.block.19.layer.0\n","language_model.decoder.block.19.layer.0.SelfAttention\n","language_model.decoder.block.19.layer.0.SelfAttention.q\n","language_model.decoder.block.19.layer.0.SelfAttention.k\n","language_model.decoder.block.19.layer.0.SelfAttention.v\n","language_model.decoder.block.19.layer.0.SelfAttention.o\n","language_model.decoder.block.19.layer.0.layer_norm\n","language_model.decoder.block.19.layer.0.dropout\n","language_model.decoder.block.19.layer.1\n","language_model.decoder.block.19.layer.1.EncDecAttention\n","language_model.decoder.block.19.layer.1.EncDecAttention.q\n","language_model.decoder.block.19.layer.1.EncDecAttention.k\n","language_model.decoder.block.19.layer.1.EncDecAttention.v\n","language_model.decoder.block.19.layer.1.EncDecAttention.o\n","language_model.decoder.block.19.layer.1.layer_norm\n","language_model.decoder.block.19.layer.1.dropout\n","language_model.decoder.block.19.layer.2\n","language_model.decoder.block.19.layer.2.DenseReluDense\n","language_model.decoder.block.19.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.19.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.19.layer.2.DenseReluDense.wo\n","language_model.decoder.block.19.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.19.layer.2.DenseReluDense.act\n","language_model.decoder.block.19.layer.2.layer_norm\n","language_model.decoder.block.19.layer.2.dropout\n","language_model.decoder.block.20\n","language_model.decoder.block.20.layer\n","language_model.decoder.block.20.layer.0\n","language_model.decoder.block.20.layer.0.SelfAttention\n","language_model.decoder.block.20.layer.0.SelfAttention.q\n","language_model.decoder.block.20.layer.0.SelfAttention.k\n","language_model.decoder.block.20.layer.0.SelfAttention.v\n","language_model.decoder.block.20.layer.0.SelfAttention.o\n","language_model.decoder.block.20.layer.0.layer_norm\n","language_model.decoder.block.20.layer.0.dropout\n","language_model.decoder.block.20.layer.1\n","language_model.decoder.block.20.layer.1.EncDecAttention\n","language_model.decoder.block.20.layer.1.EncDecAttention.q\n","language_model.decoder.block.20.layer.1.EncDecAttention.k\n","language_model.decoder.block.20.layer.1.EncDecAttention.v\n","language_model.decoder.block.20.layer.1.EncDecAttention.o\n","language_model.decoder.block.20.layer.1.layer_norm\n","language_model.decoder.block.20.layer.1.dropout\n","language_model.decoder.block.20.layer.2\n","language_model.decoder.block.20.layer.2.DenseReluDense\n","language_model.decoder.block.20.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.20.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.20.layer.2.DenseReluDense.wo\n","language_model.decoder.block.20.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.20.layer.2.DenseReluDense.act\n","language_model.decoder.block.20.layer.2.layer_norm\n","language_model.decoder.block.20.layer.2.dropout\n","language_model.decoder.block.21\n","language_model.decoder.block.21.layer\n","language_model.decoder.block.21.layer.0\n","language_model.decoder.block.21.layer.0.SelfAttention\n","language_model.decoder.block.21.layer.0.SelfAttention.q\n","language_model.decoder.block.21.layer.0.SelfAttention.k\n","language_model.decoder.block.21.layer.0.SelfAttention.v\n","language_model.decoder.block.21.layer.0.SelfAttention.o\n","language_model.decoder.block.21.layer.0.layer_norm\n","language_model.decoder.block.21.layer.0.dropout\n","language_model.decoder.block.21.layer.1\n","language_model.decoder.block.21.layer.1.EncDecAttention\n","language_model.decoder.block.21.layer.1.EncDecAttention.q\n","language_model.decoder.block.21.layer.1.EncDecAttention.k\n","language_model.decoder.block.21.layer.1.EncDecAttention.v\n","language_model.decoder.block.21.layer.1.EncDecAttention.o\n","language_model.decoder.block.21.layer.1.layer_norm\n","language_model.decoder.block.21.layer.1.dropout\n","language_model.decoder.block.21.layer.2\n","language_model.decoder.block.21.layer.2.DenseReluDense\n","language_model.decoder.block.21.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.21.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.21.layer.2.DenseReluDense.wo\n","language_model.decoder.block.21.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.21.layer.2.DenseReluDense.act\n","language_model.decoder.block.21.layer.2.layer_norm\n","language_model.decoder.block.21.layer.2.dropout\n","language_model.decoder.block.22\n","language_model.decoder.block.22.layer\n","language_model.decoder.block.22.layer.0\n","language_model.decoder.block.22.layer.0.SelfAttention\n","language_model.decoder.block.22.layer.0.SelfAttention.q\n","language_model.decoder.block.22.layer.0.SelfAttention.k\n","language_model.decoder.block.22.layer.0.SelfAttention.v\n","language_model.decoder.block.22.layer.0.SelfAttention.o\n","language_model.decoder.block.22.layer.0.layer_norm\n","language_model.decoder.block.22.layer.0.dropout\n","language_model.decoder.block.22.layer.1\n","language_model.decoder.block.22.layer.1.EncDecAttention\n","language_model.decoder.block.22.layer.1.EncDecAttention.q\n","language_model.decoder.block.22.layer.1.EncDecAttention.k\n","language_model.decoder.block.22.layer.1.EncDecAttention.v\n","language_model.decoder.block.22.layer.1.EncDecAttention.o\n","language_model.decoder.block.22.layer.1.layer_norm\n","language_model.decoder.block.22.layer.1.dropout\n","language_model.decoder.block.22.layer.2\n","language_model.decoder.block.22.layer.2.DenseReluDense\n","language_model.decoder.block.22.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.22.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.22.layer.2.DenseReluDense.wo\n","language_model.decoder.block.22.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.22.layer.2.DenseReluDense.act\n","language_model.decoder.block.22.layer.2.layer_norm\n","language_model.decoder.block.22.layer.2.dropout\n","language_model.decoder.block.23\n","language_model.decoder.block.23.layer\n","language_model.decoder.block.23.layer.0\n","language_model.decoder.block.23.layer.0.SelfAttention\n","language_model.decoder.block.23.layer.0.SelfAttention.q\n","language_model.decoder.block.23.layer.0.SelfAttention.k\n","language_model.decoder.block.23.layer.0.SelfAttention.v\n","language_model.decoder.block.23.layer.0.SelfAttention.o\n","language_model.decoder.block.23.layer.0.layer_norm\n","language_model.decoder.block.23.layer.0.dropout\n","language_model.decoder.block.23.layer.1\n","language_model.decoder.block.23.layer.1.EncDecAttention\n","language_model.decoder.block.23.layer.1.EncDecAttention.q\n","language_model.decoder.block.23.layer.1.EncDecAttention.k\n","language_model.decoder.block.23.layer.1.EncDecAttention.v\n","language_model.decoder.block.23.layer.1.EncDecAttention.o\n","language_model.decoder.block.23.layer.1.layer_norm\n","language_model.decoder.block.23.layer.1.dropout\n","language_model.decoder.block.23.layer.2\n","language_model.decoder.block.23.layer.2.DenseReluDense\n","language_model.decoder.block.23.layer.2.DenseReluDense.wi_0\n","language_model.decoder.block.23.layer.2.DenseReluDense.wi_1\n","language_model.decoder.block.23.layer.2.DenseReluDense.wo\n","language_model.decoder.block.23.layer.2.DenseReluDense.dropout\n","language_model.decoder.block.23.layer.2.DenseReluDense.act\n","language_model.decoder.block.23.layer.2.layer_norm\n","language_model.decoder.block.23.layer.2.dropout\n","language_model.decoder.final_layer_norm\n","language_model.decoder.dropout\n","language_model.lm_head\n","LoRA 파인튜닝 설정 완료.\n"]}]},{"cell_type":"markdown","source":["## 5. 학습 가능한 파라미터 확인\n","전체 파라미터 중 학습 가능한 파라미터와 비율을 확인합니다.\n","\n","> 이 부분에 대한 코드는 수정해서는 안 됩니다! 수정을 진행하였을 시 평가에 영향이 있을 수 있습니다. 채점 기준 중 하나인 **학습 가능한 파라미터의 수**와 직결되는 부분입니다. 이와 관련된 부분을 허위로 기재한 것이 적발될 시 평가에 불이익이 있을 수 있습니다.\n","\n"],"metadata":{"id":"VJR8ZYjv-64b"}},{"cell_type":"code","source":["def print_trainable_params(model):\n","    trainable_params = 0\n","    all_params = 0\n","    for _, param in model.named_parameters():\n","        all_params += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(f\"전체 파라미터 수: {all_params / 1e6:.2f}M\")\n","    print(f\"학습 가능한 파라미터 수: {trainable_params}\")\n","    print(f\"파라미터 비율: {100 * trainable_params / all_params:.2f}%\")\n","\n","print_trainable_params(model)"],"metadata":{"id":"88yX8b81eHqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731126410362,"user_tz":-540,"elapsed":11,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"f6d0329b-021f-41fd-f9ab-24f393ebda45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 파라미터 수: 4041.84M\n","학습 가능한 파라미터 수: 18874368\n","파라미터 비율: 0.47%\n"]}]},{"cell_type":"markdown","source":["## 6. 데이터셋 로드 및 분할\n","데이터셋을 로드하고 학습, 검증, 테스트 세트로 나눕니다.\n","\n","> 이 부분에 대한 코드는 수정해서는 안 됩니다! 수정을 진행하였을 시 평가에 영향이 있을 수 있습니다. 채점 기준 중 하나인 **사용된 데이터셋의 크기**와 직결되는 부분입니다. 이와 관련된 부분을 허위로 기재한 것이 적발될 시 평가에 불이익이 있을 수 있습니다."],"metadata":{"id":"awj7t6jH_W57"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import random\n","\n","dataset_path = os.path.join('/content/drive/MyDrive/InThon', 'dataset.csv')\n","data_df = pd.read_csv(dataset_path)\n","\n","train_df = data_df[data_df['train'] == True]\n","val_df = data_df[data_df['val'] == True]\n","test_df = data_df[data_df['test'] == True]\n","print(f\"Training set size: {len(train_df)}, Validation set size: {len(val_df)}, Test set size: {len(test_df)}\")\n","\n","num_epochs = 1\n","print(f\"Total training data point size: {len(train_df) * num_epochs}\")"],"metadata":{"id":"Gg9Sf-C1jnMa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731129415322,"user_tz":-540,"elapsed":572,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"8fa8cca6-bb07-490b-85ee-4e00298a5ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set size: 3013, Validation set size: 200, Test set size: 200\n","Total training data point size: 3013\n"]}]},{"cell_type":"markdown","source":["## 7. 커스텀 데이터셋 클래스 및 DataLoader 생성\n","\n","### 개념 설명\n","이 단계에서는 `CustomImageCaptionDataset` 클래스를 정의하여 데이터셋을 PyTorch 형식으로 로드합니다. 각 샘플을 이미지와 텍스트 형태로 받아 모델의 입력 형식에 맞게 전처리합니다.\n","\n","### 이론 및 수식\n","텍스트는 정수 인코딩을 통해 모델 입력으로 들어가고, 이미지 데이터는 픽셀 값이 `[0, 1]` 범위로 정규화됩니다.\n","\n","1. **텍스트 인코딩**:\n","   $\n","   \\text{input_ids} = \\text{tokenizer(text)}\n","   $\n","   \n","   `inputs['input_ids']`는 텍스트를 정수 형태로 변환한 결과입니다.\n","\n","2. **이미지 정규화**:\n","   $\n","   \\text{pixel_values} = \\frac{\\text{image} - \\text{min(image)}}{\\text{max(image)} - \\text{min(image)}}\n","   $\n","\n","   이 정규화는 모델이 입력 픽셀값(`inputs['pixel_values']`)을 일정한 범위 내에서 처리할 수 있게 하여 학습의 안정성을 높입니다.\n"],"metadata":{"id":"voO4tj3D_aDu"}},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","\n","class CustomImageCaptionDataset(Dataset):\n","    def __init__(self, df, processor, test=False):\n","        self.df = df\n","        self.processor = processor\n","        self.test = test\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        if not self.test:\n","            image_url = self.df.iloc[idx][\"url\"]\n","            image_id = self.df.iloc[idx][\"Image_ID\"]\n","            caption = self.df.iloc[idx][\"Paragraph\"]\n","\n","            response = requests.get(image_url)\n","            image = Image.open(BytesIO(response.content)).convert('RGB')\n","\n","            inputs = self.processor(\n","                images=image,\n","                text=caption,\n","                padding=\"max_length\",\n","                truncation=True,\n","                max_length=256,\n","                return_tensors=\"pt\"\n","            )\n","            inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n","            inputs['labels'] = inputs['input_ids'].clone()\n","\n","            inputs['image_url'] = image_url\n","            inputs['Image_ID'] = image_id\n","            inputs['reference_caption'] = caption\n","\n","        else:\n","            image_url = self.df.iloc[idx][\"url\"]\n","            image_id = self.df.iloc[idx][\"Image_ID\"]\n","\n","            inputs = dict()\n","            inputs['image_url'] = image_url\n","            inputs['Image_ID'] = image_id\n","\n","        return inputs"],"metadata":{"id":"Fgg3RNjeeUo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomImageCaptionDataset(train_df, processor)\n","train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n","\n","val_dataset = CustomImageCaptionDataset(val_df, processor)\n","val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=8)\n","\n","test_dataset = CustomImageCaptionDataset(test_df, processor, test=True)\n","test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=8)"],"metadata":{"id":"aziATQWeglTv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 8. 옵티마이저와 스케줄러 설정\n","\n","### 개념 설명\n","**옵티마이저**는 모델 파라미터를 조정하는 방법을 정의합니다. **AdamW**는 Adam 옵티마이저의 변형으로, L2 정규화 대신 가중치 감쇠(Weight Decay)를 적용하여 과적합을 방지합니다. **스케줄러**는 학습 중 학습률을 동적으로 조정하여 학습 효율을 높입니다.\n","\n","### 이론 및 수식\n","1. **AdamW 옵티마이저**:\n","   Adam 옵티마이저는 모멘텀을 사용하는 SGD 방식입니다. 각 파라미터에 대해 다음과 같은 방식으로 업데이트가 이루어집니다.\n","\n","   $\n","   m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t\n","   $\n","\n","   $\n","   v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2\n","   $\n","\n","   $\n","   \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n","   $\n","\n","   $\n","   \\theta_{t+1} = \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} - \\eta \\lambda \\theta_t\n","   $\n","\n","   여기서 $( \\theta )$는 모델 파라미터, $( g_t )$는 현재 그라디언트, $( \\lambda )$는 가중치 감쇠 계수입니다.\n","\n","2. **스케줄러**: 학습률 감소를 위한 스케줄러는 StepLR을 사용합니다. 이 스케줄러는 주어진 스텝마다 학습률을 감소시킵니다.\n","\n","   $\n","   \\eta_{t+1} = \\gamma \\cdot \\eta_t\n","   $\n","\n","   여기서 $( \\gamma )$는 감소율입니다."],"metadata":{"id":"VUpx1jKP_hRh"}},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","for name, param in model.named_parameters():\n","    if \"lora\" in name:\n","        param.requires_grad = True\n","\n","optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\n","total_steps = len(train_dataloader) * num_epochs\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=total_steps // 2, gamma=0.1)"],"metadata":{"id":"GSvAnp4PgqsS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. 학습 루프\n","\n","### 1. Autoregressive 모델\n","여기 사용된 모델은 **autoregressive** 모델로, 각 타임 스텝에서 이전 타임 스텝의 출력을 바탕으로 다음 토큰을 순차적으로 예측합니다. 이 방식은 자연어 생성에서 주로 쓰이며, 이미지 캡션 생성 작업에서도 각 단어가 이전 단어와의 관계를 통해 예측됩니다.\n","\n","### 2. 교차 엔트로피 손실 (Cross-Entropy Loss)\n","손실 함수로는 **교차 엔트로피 손실**(Cross-Entropy Loss)을 사용합니다. 모델이 예측한 확률 분포와 실제 정답 레이블 간의 차이를 측정하여, 모델의 예측이 실제 정답과 얼마나 일치하는지 평가합니다.\n","\n","#### 수식\n","주어진 입력 시퀀스 $x$에 대해 모델이 각 시간 단계 $t$에서 다음 토큰 $y_t$를 예측하도록 학습하는 과정에서 교차 엔트로피 손실 $L$은 다음과 같이 정의됩니다.\n","\n","$L = -\\sum_{t=1}^{T} \\log p(y_t | x)$\n","\n","여기서:\n","- $T$는 시퀀스의 길이입니다.\n","- $y_t$는 $t$번째 타임 스텝에서의 실제 정답 토큰입니다.\n","- $p(y_t | x)$는 모델이 $x$를 입력받았을 때 $y_t$ 토큰을 예측할 확률입니다.\n","\n","이 수식에서 모델은 각 토큰의 예측 확률이 실제 정답 토큰에 가까워질수록 손실이 작아지며, 모델이 더 정확해집니다.\n","\n","### 3. Softmax 함수와 Temperature 조정\n","모델은 각 타임 스텝에서 다음 토큰의 확률을 예측할 때 **softmax** 함수를 사용하여 출력 확률 분포를 만듭니다.\n","\n","#### Softmax 함수\n","Softmax는 벡터 $z = (z_1, z_2, \\dots, z_n)$를 입력받아 각 요소의 확률을 계산합니다.\n","\n","$p(y_t | x) = \\frac{\\exp(z_t / T)}{\\sum_{i=1}^{n} \\exp(z_i / T)}$\n","\n","여기서:\n","- $z_i$는 모델의 출력 로짓(logit)입니다.\n","- $T$는 temperature 값으로, softmax의 **temperature**를 조정해 확률 분포의 집중도를 제어할 수 있습니다.\n","\n","#### Temperature의 역할\n","- $T = 1$: 기본적인 softmax로, 확률 분포의 집중도에 변화가 없습니다.\n","- $T > 1$: 확률 분포를 평탄화시켜 더 다양한 토큰이 선택될 가능성을 높여 **탐색적** 예측을 가능하게 합니다.\n","- $T < 1$: 확률 분포를 더 예리하게 만들어 가장 높은 확률을 가진 토큰이 더 자주 선택되며 **보수적** 예측을 가능하게 합니다.\n","\n","이렇게 softmax와 temperature 조정은 모델이 생성하는 문장의 다양성을 조절하는 데 중요한 역할을 합니다.\n","\n","### 4. 코드 내 손실 누적 및 그라디언트 업데이트\n","이 코드에서는 `accumulation_steps`를 통해 여러 미니배치의 손실을 누적하여 메모리 사용량을 조절합니다. 손실은 다음과 같이 누적됩니다.\n","\n","1. **손실 누적**:\n","   $L_{\\text{acc}} = \\sum_{i=1}^{S} L_i$\n","   여기서 $S$는 `accumulation_steps` 값입니다.\n","\n","2. **손실의 평균 계산**:\n","   최종적으로 누적 손실을 $S$로 나눈 평균 손실로 그라디언트를 계산하여 역전파합니다.\n","   $\\bar{L} = \\frac{L_{\\text{acc}}}{S} = \\frac{1}{S} \\sum_{i=1}^{S} L_i$\n","\n","3. **역전파 및 파라미터 업데이트**:\n","   손실 $\\bar{L}$에 대해 그라디언트를 계산하고 역전파를 수행하여 파라미터를 업데이트합니다.\n","\n","이 과정을 통해 모델이 예측 성능을 점차적으로 개선해 나갑니다."],"metadata":{"id":"M1b0IUJh_zhN"}},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from types import MethodType\n","\n","# 평가 객체 목록 정의\n","evaluation_objects = [\n","    \"man\", \"woman\", \"tree\", \"sky\", \"building\", \"window\", \"shirt\", \"wall\",\n","    \"sign\", \"grass\", \"water\", \"table\", \"train\", \"plate\", \"car\", \"dog\", \"cat\",\n","    \"giraffe\", \"light\", \"pole\", \"plane\", \"boy\", \"zebra\", \"bus\", \"elephant\",\n","    \"ground\", \"hair\", \"girl\", \"horse\", \"cloud\", \"hand\", \"clock\", \"people\",\n","    \"snow\", \"bird\", \"chair\", \"fence\", \"glass\", \"floor\", \"bear\", \"boat\",\n","    \"street\", \"head\", \"door\", \"road\", \"shoe\", \"leg\", \"eye\", \"hat\"\n","]\n","\n","# 객체 단어 인덱스 추출 함수 정의\n","def get_object_token_indices(labels, tokenizer):\n","    object_token_indices = []\n","    for obj in evaluation_objects:\n","        obj_token_id = tokenizer.convert_tokens_to_ids(obj)\n","        object_token_indices.append(obj_token_id)\n","    mask = torch.isin(labels, torch.tensor(object_token_indices, device=labels.device))\n","    return mask\n","\n","# 객체 포함 손실 함수 정의\n","def object_inclusion_loss(logits, labels, tokenizer):\n","    object_mask = get_object_token_indices(labels, tokenizer)\n","    object_logits = logits[object_mask]\n","    object_labels = labels[object_mask]\n","    if object_logits.size(0) > 0:\n","        loss_fct = torch.nn.CrossEntropyLoss()\n","        object_loss = loss_fct(object_logits.view(-1, logits.size(-1)), object_labels.view(-1))\n","    else:\n","        object_loss = torch.tensor(0.0, device=logits.device)\n","    return object_loss\n","\n","# 객체 할루시네이션 손실 함수 정의\n","def object_hallucination_loss(logits, labels, tokenizer):\n","    # 정답 캡션에 없는 객체 단어를 찾기 위한 반전 마스크\n","    non_object_mask = ~get_object_token_indices(labels, tokenizer)\n","    hallucinated_logits = logits[non_object_mask]\n","    if hallucinated_logits.size(0) > 0:\n","        # 할루시네이션 객체 단어에 대한 로그 확률을 낮추기 위한 손실\n","        hallucination_penalty = F.softmax(hallucinated_logits, dim=-1).mean()\n","    else:\n","        hallucination_penalty = torch.tensor(0.0, device=logits.device)\n","    return hallucination_penalty\n","\n","def new_forward(self, *args, **kwargs):\n","    if 'inputs_embeds' in kwargs:\n","        kwargs.pop('inputs_embeds')\n","    return self.base_model.forward(*args, **kwargs)\n","\n","model.forward = MethodType(new_forward, model)\n","\n","# forward_pass에서 사용 예시\n","def forward_pass(input_ids, pixel_values, qformer_input_ids, qformer_attention_mask, labels, tokenizer):\n","    outputs = model(\n","        input_ids=input_ids,\n","        pixel_values=pixel_values,\n","        qformer_input_ids=qformer_input_ids,\n","        qformer_attention_mask=qformer_attention_mask,\n","        labels=labels\n","    )\n","    logits = outputs.logits\n","\n","    if logits.size(1) > labels.size(1):\n","        logits = logits[:, :labels.size(1), :]\n","    elif logits.size(1) < labels.size(1):\n","        padding = torch.zeros((logits.size(0), labels.size(1) - logits.size(1), logits.size(2)), device=logits.device)\n","        logits = torch.cat([logits, padding], dim=1)\n","\n","    # 교차 엔트로피 손실 계산\n","    loss_fct = torch.nn.CrossEntropyLoss()\n","    cross_entropy_loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n","\n","    # 객체 포함 손실 계산\n","    object_loss = object_inclusion_loss(logits, labels, tokenizer)\n","\n","    # 객체 할루시네이션 손실 계산\n","    hallucination_loss = object_hallucination_loss(logits, labels, tokenizer)\n","\n","    # 총 손실 계산\n","    total_loss = cross_entropy_loss + object_loss + hallucination_loss\n","    return total_loss\n"],"metadata":{"id":"q6jB6quMubwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from types import MethodType\n","\n","def new_forward(self, *args, **kwargs):\n","    if 'inputs_embeds' in kwargs:\n","        kwargs.pop('inputs_embeds')\n","    return self.base_model.forward(*args, **kwargs)\n","\n","model.forward = MethodType(new_forward, model)\n","\n","def forward_pass(input_ids, pixel_values, qformer_input_ids, qformer_attention_mask, labels):\n","    outputs = model(\n","        input_ids=input_ids,\n","        pixel_values=pixel_values,\n","        qformer_input_ids=qformer_input_ids,\n","        qformer_attention_mask=qformer_attention_mask,\n","        labels=labels\n","    )\n","    logits = outputs.logits\n","\n","    if logits.size(1) > labels.size(1):\n","        logits = logits[:, :labels.size(1), :]\n","    elif logits.size(1) < labels.size(1):\n","        padding = torch.zeros((logits.size(0), labels.size(1) - logits.size(1), logits.size(2)), device=logits.device)\n","        logits = torch.cat([logits, padding], dim=1)\n","\n","    loss_fct = torch.nn.CrossEntropyLoss()\n","    loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n","    return loss"],"metadata":{"id":"T-V4EYp2w8yL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","accumulation_steps = 4\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    print(f\"Epoch {epoch+1} / {num_epochs}\")\n","\n","    with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1} (Training)\", postfix={'Train Loss': 0.0}) as pbar:\n","        for idx, batch in enumerate(train_dataloader):\n","            instruction_text = [\"Describe this image in detail.\"] * batch[\"pixel_values\"].size(0)\n","\n","            pixel_values = (batch[\"pixel_values\"] - batch[\"pixel_values\"].min()) / (batch[\"pixel_values\"].max() - batch[\"pixel_values\"].min())\n","            inputs = processor(\n","                images=pixel_values,\n","                text=instruction_text,\n","                return_tensors=\"pt\",\n","                padding=True\n","            ).to(device)\n","\n","            labels = batch[\"labels\"].to(device)\n","\n","            loss = forward_pass(\n","                inputs[\"input_ids\"],\n","                inputs[\"pixel_values\"],\n","                inputs.get(\"qformer_input_ids\", None),\n","                inputs.get(\"qformer_attention_mask\", None),\n","                labels\n","            ) / accumulation_steps\n","\n","            loss.backward()\n","            epoch_loss += loss.item()\n","\n","            if (idx + 1) % accumulation_steps == 0 or (idx + 1 == len(train_dataloader)):\n","                optimizer.step()\n","                optimizer.zero_grad()\n","                torch.cuda.empty_cache()\n","\n","            pbar.set_postfix({'Train Loss': epoch_loss / (idx + 1)})\n","            pbar.update(1)\n","\n","    scheduler.step()\n","\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        with tqdm(total=len(val_dataloader), desc=f\"Epoch {epoch+1} (Validation)\", postfix={'Val Loss': 0.0}) as pbar:\n","            for idx, batch in enumerate(val_dataloader):\n","                instruction_text = [\"Describe this image in detail.\"] * batch[\"pixel_values\"].size(0)\n","\n","                pixel_values = (batch[\"pixel_values\"] - batch[\"pixel_values\"].min()) / (batch[\"pixel_values\"].max() - batch[\"pixel_values\"].min())\n","                inputs = processor(\n","                    images=pixel_values,\n","                    text=instruction_text,\n","                    return_tensors=\"pt\",\n","                    padding=True\n","                ).to(device)\n","\n","                labels = batch[\"labels\"].to(device)\n","\n","                loss = forward_pass(\n","                    inputs[\"input_ids\"],\n","                    inputs[\"pixel_values\"],\n","                    inputs.get(\"qformer_input_ids\", None),\n","                    inputs.get(\"qformer_attention_mask\", None),\n","                    labels\n","                )\n","                val_loss += loss.item()\n","\n","                pbar.set_postfix({'Val Loss': val_loss / (idx + 1)})\n","                pbar.update(1)\n","\n","    avg_train_loss = epoch_loss / len(train_dataloader)\n","    avg_val_loss = val_loss / len(val_dataloader)\n","    print(f\"Epoch {epoch+1} completed | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n","\n","torch.cuda.empty_cache()"],"metadata":{"id":"u-X1MlpZgsMy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731131946379,"user_tz":-540,"elapsed":2526729,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"7a0487db-6269-4e13-bc8a-3560c38b3970"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 / 1\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 1 (Training):   0%|          | 0/189 [00:00<?, ?it/s, Train Loss=0]/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","Epoch 1 (Training): 100%|██████████| 189/189 [39:35<00:00, 12.57s/it, Train Loss=0.511]\n","Epoch 1 (Validation): 100%|██████████| 25/25 [02:30<00:00,  6.01s/it, Val Loss=0.771]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 completed | Train Loss: 0.5107 | Val Loss: 0.7711\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## 10. 평가 및 메트릭 계산\n","테스트 데이터셋에 대해 **SPICE, CLIPScore, CHAIRf** 메트릭을 계산합니다.\n","\n","**SPICE**: 텍스트의 질을 평가하는 점수로, 이미지 캡션의 내용과 관련된 객체, 관계, 속성 등을 기반으로 측정합니다.\n","\n","**CLIPScore**: CLIP 모델을 사용해 이미지와 텍스트의 유사도를 측정하는 점수입니다.\n","\n","**CHAIR**: 캡션이 이미지와 얼마나 잘 일치하는지 평가하는 지표입니다. 특히, 캡션에 어떤 객체가 포함되었는지를 검토하는 데 초점을 둡니다. Precision의 성격이 강한 CHAIRi, CHAIRs와 달리 CHAIRf는 Recall의 성격도 같이 고려하는 평가 지표입니다.\n","\n","SPICE: https://arxiv.org/abs/1607.08822\n","\n","CLIPScore: https://arxiv.org/abs/2104.08718\n","\n","CHAIR: https://arxiv.org/abs/1809.02156\n","\n"],"metadata":{"id":"1tuHBOkh_2iJ"}},{"cell_type":"code","source":["from transformers import CLIPProcessor, CLIPModel\n","import torch\n","from tqdm import tqdm\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","from pycocoevalcap.spice.spice import Spice\n","from collections import Counter\n","import spacy\n","from concurrent.futures import ThreadPoolExecutor\n","from multiprocessing import Pool\n","import numpy as np\n","\n","def download_image(image_url):\n","    response = requests.get(image_url)\n","    image = Image.open(BytesIO(response.content)).convert('RGB')\n","    return image\n","\n","def extract_objects_from_captions(captions, object_list):\n","    docs = nlp.pipe(captions)\n","    objects_in_captions = []\n","\n","    for doc in docs:\n","        objects_in_caption = set()\n","        for token in doc:\n","            word = token.lemma_.lower()\n","            if word in object_list:\n","                objects_in_caption.add(word)\n","        objects_in_captions.append(objects_in_caption)\n","\n","    return objects_in_captions\n","\n","def calculate_spice(args):\n","    idx, generated_caption, reference_caption = args\n","    spice_score, _ = spice_scorer.compute_score({0: [reference_caption]}, {0: [generated_caption]})\n","    return idx, spice_score\n","\n","def calculate_metrics_batch(images, generated_captions, reference_captions, image_objects_batch):\n","    # SPICE 점수 계산\n","    spice_inputs = {i: [ref] for i, ref in enumerate(reference_captions)}\n","    spice_predictions = {i: [gen] for i, gen in enumerate(generated_captions)}\n","    spice_scores, _ = spice_scorer.compute_score(spice_inputs, spice_predictions)\n","\n","    # spice_scores가 단일 값일 경우 리스트로 변환\n","    if isinstance(spice_scores, (float, np.float64)):\n","        spice_scores = [spice_scores] * len(generated_captions)\n","\n","    # CLIP 점수 계산\n","    inputs = clip_processor(text=generated_captions,\n","                            images=images,\n","                            return_tensors=\"pt\",\n","                            padding=\"max_length\",\n","                            truncation=True,\n","                            max_length=77).to(device)\n","    outputs = clip_model(**inputs)\n","    clip_scores = outputs.logits_per_image.squeeze().tolist()\n","\n","    if isinstance(clip_scores, float):  # clip_scores가 단일 값일 경우 리스트로 변환\n","        clip_scores = [clip_scores]\n","\n","    # CHAIRf 점수 및 중간 집계 출력\n","    chairf_scores = []\n","    for idx, (generated_caption, image_objects) in enumerate(zip(generated_captions, image_objects_batch)):\n","        chairf = calculate_chair_metrics(generated_caption, image_objects)\n","        chairf_scores.append(chairf)\n","\n","        # 중간 결과 출력\n","        hallucinated_objects = set(extract_objects_from_caption(generated_caption, evaluation_objects)) - set(image_objects)\n","        missing_objects = set(image_objects) - set(extract_objects_from_caption(generated_caption, evaluation_objects))\n","        caption_objects = set(extract_objects_from_caption(generated_caption, evaluation_objects))\n","\n","        print(f\"환각 객체: {hallucinated_objects}, 누락 객체: {missing_objects}, 캡션 객체: {caption_objects}, 이미지 객체: {image_objects}\")\n","        print(f\"spice_score: {spice_scores[idx]}, clip_score: {clip_scores[idx]}, chairf: {chairf}\")\n","\n","    return spice_scores, clip_scores, chairf_scores\n","\n","val_results = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(val_dataloader, desc=\"Calculating SPICE, CLIPScore, and CHAIRf\"):\n","        image_urls = batch['image_url']\n","        image_ids = batch['Image_ID']\n","        reference_captions = batch['reference_caption']\n","\n","        # 이미지 다운로드 병렬화\n","        with ThreadPoolExecutor() as executor:\n","            images = list(executor.map(download_image, image_urls))\n","\n","        # 캡션 처리 일괄화\n","        image_objects_batch = extract_objects_from_captions(reference_captions, evaluation_objects)\n","\n","        inputs = processor(\n","            images=images,\n","            text=['Describe this image in detail.'] * len(images),\n","            return_tensors=\"pt\",\n","            padding=True\n","        ).to(device)\n","\n","        # 모델 추론 최적화\n","        generated_ids = model.generate(\n","            **inputs,\n","            do_sample=False,\n","            num_beams=2,\n","            max_length=128,\n","            repetition_penalty=1.2,\n","            length_penalty=0.8\n","        )\n","\n","        generated_captions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n","        generated_captions = [caption.strip() for caption in generated_captions]\n","\n","        # 메트릭 계산 배치화\n","        spice_scores, clip_scores, chairf_scores = calculate_metrics_batch(\n","            images, generated_captions, reference_captions, image_objects_batch\n","        )\n","\n","        for idx, (image_id, generated_caption, reference_caption, spice_score, clip_score, chairf) in enumerate(zip(\n","            image_ids, generated_captions, reference_captions, spice_scores, clip_scores, chairf_scores\n","        )):\n","            val_results.append({\n","                \"Image_ID\": image_id,\n","                \"generated_caption\": generated_caption,\n","                \"reference_caption\": reference_caption,\n","                \"spice_score\": spice_score,\n","                \"clip_score\": clip_score,\n","                \"chairf\": chairf,\n","            })\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7fqToAkyDdK2","executionInfo":{"status":"error","timestamp":1731141636904,"user_tz":-540,"elapsed":62983,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"b82b0ed0-37d8-4b4d-c359-3bbc9774e501"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   0%|          | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: set(), 이미지 객체: {'wall'}\n","환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: set(), 이미지 객체: {'wall'}\n","spice_score: 0.2213741335431273, clip_score: [30.816980361938477, 17.464008331298828, 10.294953346252441, 20.053409576416016, 19.168697357177734, 15.150542259216309, 19.65251350402832, 17.761436462402344], chairf: 0\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'table'}, 이미지 객체: {'table'}\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'table'}, 이미지 객체: {'table'}\n","spice_score: 0.2213741335431273, clip_score: [12.487818717956543, 32.70064163208008, 9.184746742248535, 19.66475486755371, 18.322351455688477, 16.400423049926758, 11.857498168945312, 13.279247283935547], chairf: 1.0\n","환각 객체: set(), 누락 객체: {'hair', 'shirt'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'hair', 'shirt'}\n","환각 객체: set(), 누락 객체: {'hair', 'shirt'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'hair', 'shirt'}\n","spice_score: 0.2213741335431273, clip_score: [14.293331146240234, 17.878665924072266, 30.639738082885742, 14.318366050720215, 13.378397941589355, 11.140311241149902, 8.934067726135254, 16.619449615478516], chairf: 0.5\n","환각 객체: set(), 누락 객체: {'ground', 'light', 'tree', 'grass', 'building'}, 캡션 객체: set(), 이미지 객체: {'ground', 'tree', 'grass', 'light', 'building'}\n","환각 객체: set(), 누락 객체: {'ground', 'light', 'tree', 'grass', 'building'}, 캡션 객체: set(), 이미지 객체: {'ground', 'tree', 'grass', 'light', 'building'}\n","spice_score: 0.2213741335431273, clip_score: [14.337430953979492, 17.49919891357422, 14.253539085388184, 24.489870071411133, 18.932065963745117, 17.886716842651367, 12.283536911010742, 16.840364456176758], chairf: 0\n","환각 객체: set(), 누락 객체: {'door'}, 캡션 객체: {'street'}, 이미지 객체: {'door', 'street'}\n","환각 객체: set(), 누락 객체: {'door'}, 캡션 객체: {'street'}, 이미지 객체: {'door', 'street'}\n","spice_score: 0.2213741335431273, clip_score: [15.990903854370117, 14.415240287780762, 8.879182815551758, 14.42431640625, 30.908275604248047, 18.368913650512695, 16.925683975219727, 23.931991577148438], chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'tree', 'road', 'grass', 'people', 'pole', 'building'}, 캡션 객체: {'street', 'bus'}, 이미지 객체: {'tree', 'road', 'street', 'grass', 'bus', 'people', 'pole', 'building'}\n","환각 객체: set(), 누락 객체: {'tree', 'road', 'grass', 'people', 'pole', 'building'}, 캡션 객체: {'street', 'bus'}, 이미지 객체: {'tree', 'road', 'street', 'grass', 'bus', 'people', 'pole', 'building'}\n","spice_score: 0.2213741335431273, clip_score: [13.6582612991333, 17.614826202392578, 13.159981727600098, 20.97690773010254, 24.68531036376953, 29.65467643737793, 9.087749481201172, 23.258716583251953], chairf: 0.4\n","환각 객체: {'door'}, 누락 객체: {'window', 'floor'}, 캡션 객체: {'dog', 'door'}, 이미지 객체: {'dog', 'window', 'floor'}\n","환각 객체: {'door'}, 누락 객체: {'window', 'floor'}, 캡션 객체: {'dog', 'door'}, 이미지 객체: {'dog', 'window', 'floor'}\n","spice_score: 0.2213741335431273, clip_score: [22.063236236572266, 19.306150436401367, 11.606014251708984, 18.923477172851562, 22.8712158203125, 18.462095260620117, 26.716371536254883, 19.63634490966797], chairf: 0.4\n","환각 객체: set(), 누락 객체: {'shirt', 'tree'}, 캡션 객체: set(), 이미지 객체: {'shirt', 'tree'}\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   4%|▍         | 1/25 [00:19<07:55, 19.81s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'shirt', 'tree'}, 캡션 객체: set(), 이미지 객체: {'shirt', 'tree'}\n","spice_score: 0.2213741335431273, clip_score: [18.634105682373047, 17.82807159423828, 12.192940711975098, 17.011144638061523, 24.019987106323242, 19.151708602905273, 16.221946716308594, 33.491661071777344], chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: {'sky'}, 이미지 객체: {'sky'}\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'sky'}, 이미지 객체: {'sky'}\n","spice_score: 0.18730072046502066, clip_score: [25.805912017822266, 6.476367950439453, 7.782558917999268, 16.546899795532227, 12.269862174987793, 13.248591423034668, 11.26240348815918, 9.905160903930664], chairf: 1.0\n","환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'wall'}\n","환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'wall'}\n","spice_score: 0.18730072046502066, clip_score: [15.592334747314453, 35.3991813659668, 17.826866149902344, 13.815702438354492, 18.005538940429688, 15.253440856933594, 20.834579467773438, 13.103374481201172], chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'fence', 'table'}, 캡션 객체: {'chair'}, 이미지 객체: {'fence', 'chair', 'table'}\n","환각 객체: set(), 누락 객체: {'fence', 'table'}, 캡션 객체: {'chair'}, 이미지 객체: {'fence', 'chair', 'table'}\n","spice_score: 0.18730072046502066, clip_score: [17.399625778198242, 12.42940902709961, 31.92485809326172, 20.46002960205078, 18.684450149536133, 15.430198669433594, 12.499383926391602, 9.549747467041016], chairf: 0.5\n","환각 객체: set(), 누락 객체: {'ground', 'grass'}, 캡션 객체: {'water', 'elephant'}, 이미지 객체: {'ground', 'water', 'grass', 'elephant'}\n","환각 객체: set(), 누락 객체: {'ground', 'grass'}, 캡션 객체: {'water', 'elephant'}, 이미지 객체: {'ground', 'water', 'grass', 'elephant'}\n","spice_score: 0.18730072046502066, clip_score: [15.519021034240723, 7.37939453125, 17.33650779724121, 32.67789840698242, 15.317956924438477, 15.729999542236328, 13.11846923828125, 15.349713325500488], chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'plate', 'wall'}, 캡션 객체: set(), 이미지 객체: {'plate', 'wall'}\n","환각 객체: set(), 누락 객체: {'plate', 'wall'}, 캡션 객체: set(), 이미지 객체: {'plate', 'wall'}\n","spice_score: 0.18730072046502066, clip_score: [13.624140739440918, 18.021982192993164, 17.821983337402344, 21.754446029663086, 24.792585372924805, 18.245635986328125, 12.324824333190918, 10.850099563598633], chairf: 0\n","환각 객체: set(), 누락 객체: {'plate', 'sign', 'ground', 'tree'}, 캡션 객체: set(), 이미지 객체: {'plate', 'sign', 'ground', 'tree'}\n","환각 객체: set(), 누락 객체: {'plate', 'sign', 'ground', 'tree'}, 캡션 객체: set(), 이미지 객체: {'plate', 'sign', 'ground', 'tree'}\n","spice_score: 0.18730072046502066, clip_score: [17.28839874267578, 8.781070709228516, 11.966955184936523, 16.61178970336914, 18.855716705322266, 24.189144134521484, 14.785822868347168, 14.956416130065918], chairf: 0\n","환각 객체: set(), 누락 객체: {'car', 'building'}, 캡션 객체: {'woman', 'street'}, 이미지 객체: {'woman', 'car', 'street', 'building'}\n","환각 객체: set(), 누락 객체: {'car', 'building'}, 캡션 객체: {'woman', 'street'}, 이미지 객체: {'woman', 'car', 'street', 'building'}\n","spice_score: 0.18730072046502066, clip_score: [17.373891830444336, 19.394824981689453, 24.40239906311035, 20.315858840942383, 17.169193267822266, 15.633174896240234, 36.230812072753906, 26.02456283569336], chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'shirt', 'tree', 'road', 'car', 'building'}, 캡션 객체: {'sign', 'man', 'street'}, 이미지 객체: {'man', 'shirt', 'street', 'road', 'tree', 'car', 'sign', 'building'}\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   8%|▊         | 2/25 [00:39<07:33, 19.72s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'shirt', 'tree', 'road', 'car', 'building'}, 캡션 객체: {'sign', 'man', 'street'}, 이미지 객체: {'man', 'shirt', 'street', 'road', 'tree', 'car', 'sign', 'building'}\n","spice_score: 0.18730072046502066, clip_score: [11.023848533630371, 4.1079487800598145, 9.078054428100586, 16.737382888793945, 6.791241645812988, 14.735145568847656, 13.927741050720215, 30.855127334594727], chairf: 0.5454545454545454\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","Calculating SPICE, CLIPScore, and CHAIRf:   8%|▊         | 2/25 [01:02<11:57, 31.20s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-6d186698b44f>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# 메트릭 계산 배치화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         spice_scores, clip_scores, chairf_scores = calculate_metrics_batch(\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_objects_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         )\n","\u001b[0;32m<ipython-input-35-6d186698b44f>\u001b[0m in \u001b[0;36mcalculate_metrics_batch\u001b[0;34m(images, generated_captions, reference_captions, image_objects_batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mspice_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mspice_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mspice_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspice_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspice_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspice_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# spice_scores가 단일 값일 경우 리스트로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycocoevalcap/spice/spice.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(self, gts, res)\u001b[0m\n\u001b[1;32m     73\u001b[0m           \u001b[0;34m'-silent'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         ]\n\u001b[0;32m---> 75\u001b[0;31m         subprocess.check_call(spice_cmd, \n\u001b[0m\u001b[1;32m     76\u001b[0m             cwd=os.path.dirname(os.path.abspath(__file__)))\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1960\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from transformers import CLIPProcessor, CLIPModel\n","import torch\n","from tqdm import tqdm\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","from pycocoevalcap.spice.spice import Spice\n","from collections import Counter\n","import spacy\n","\n","evaluation_objects = [\n","    \"man\", \"woman\", \"tree\", \"sky\", \"building\", \"window\", \"shirt\", \"wall\",\n","    \"sign\", \"grass\", \"water\", \"table\", \"train\", \"plate\", \"car\", \"dog\", \"cat\",\n","    \"giraffe\", \"light\", \"pole\", \"plane\", \"boy\", \"zebra\", \"bus\", \"elephant\",\n","    \"ground\", \"hair\", \"girl\", \"horse\", \"cloud\", \"hand\", \"clock\", \"people\",\n","    \"snow\", \"bird\", \"chair\", \"fence\", \"glass\", \"floor\", \"bear\", \"boat\",\n","    \"street\", \"head\", \"door\", \"road\", \"shoe\", \"leg\", \"eye\", \"hat\"\n","]\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n","clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n","spice_scorer = Spice()\n","\n","def get_singular_form(word):\n","    return word.lemma_\n","\n","def extract_objects_from_caption(caption, object_list):\n","    doc = nlp(caption)\n","    objects_in_caption = set()\n","\n","    for token in doc:\n","        word = token.lemma_.lower()\n","        if word in object_list:\n","            objects_in_caption.add(word)\n","\n","    return objects_in_caption\n","\n","def calculate_chair_metrics(generated_caption, image_objects):\n","    caption_objects = extract_objects_from_caption(generated_caption, evaluation_objects)\n","\n","    hallucinated_objects = caption_objects - set(image_objects)\n","    missing_objects = set(image_objects) - caption_objects\n","    true_positives = caption_objects & set(image_objects)\n","\n","    precision = len(true_positives) / (len(true_positives) + len(hallucinated_objects)) if len(caption_objects) > 0 else 0\n","    recall = len(true_positives) / (len(true_positives) + len(missing_objects)) if len(image_objects) > 0 else 0\n","\n","    chairf = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    print(f\"환각 객체: {hallucinated_objects}, 누락 객체: {missing_objects}, 캡션 객체: {caption_objects}, 이미지 객체: {image_objects}\")\n","\n","    return chairf\n","\n","def calculate_metrics(image, generated_caption, reference_caption, image_objects):\n","    spice_score, _ = spice_scorer.compute_score({0: [reference_caption]}, {0: [generated_caption]})\n","\n","    inputs = clip_processor(text=generated_caption,\n","                            images=image,\n","                            return_tensors=\"pt\",\n","                            padding=\"max_length\",\n","                            truncation=True,\n","                            max_length=77).to(device)\n","    outputs = clip_model(**inputs)\n","    logits_per_image = outputs.logits_per_image\n","    clip_score = logits_per_image.item()\n","\n","    chairf = calculate_chair_metrics(generated_caption, image_objects)\n","    print(f'spice_score: {spice_score}, clip_score: {clip_score}, chairf: {chairf}')\n","\n","    return spice_score, clip_score, chairf"],"metadata":{"id":"rrFXFyLgguSF","colab":{"base_uri":"https://localhost:8080/","height":400,"referenced_widgets":["45ab943b65da4c589af68ea8a7300240","99775743652148399d977b6676380252","17d725e60ffc4a7daf6124a646d48606","94d4b2eb39e34949ba847aff64d0d210","c8925c5744424139a528e6339010106e","741fcdc1801743d6a2cfdb4f9f3bc2a7","aa6a9266359b47609445edc09c769d39","f6c9f8554a944b7885e89188e9418847","0afb5ddfaf9a4d1d8013d75d5e7318b0","dd9de7381db54669b295c4f3403c01d8","4f6292585a35414d9dc70d55e43c653a","851acae8bdee4488bf5ee8a8dc4ac48c","17c00bb9e5714958a3da2909f6291db0","176a302b07ef4ea8910ac02c1dd2022a","f7d480b879f34dcab2baa19147bf5785","0c9bfb3d86d8461582e62f0ba7481974","e8c98f19d39c464392d617cc26c6afed","5240b5c61e0e48a5a9f98762e8485b93","03a2bcb86f6e4a27808dfc3533eea4d0","c4dde289fce2417da3c0072f61c4fd5b","94b2cf3933a9492b812f96a1ca83e758","9aa4a57077fb416bbc7080a56618d0db","51d91bf6aed54064b6bc8bb6f2986cb2","549ee42eee5d4cf1ba40028d7e358fba","0b685c2d613f49cc90e064f2da509b7d","20d4f1caf6b04bf49c40971c29ba38a2","b8c6e1c340a24abdbbb8e9c70f9356e0","ad5bb27a29bd4c11b07fceb7b1a1a144","839d1d370a3b4b389c9388aa40567d2f","0981b2d1072c4d7080f54e11083f107f","b1ef901dffe44e2f90aef04c3d9ff227","8a942da0cf44492ead62003d9648a3c6","6e143360a7e04774b64cae65d109c618","3ce4638005484627a0d9061ecd0dc489","6560c72cadd340299defd1036941a295","5303ab8805244e27a062d849c2ff219f","6014125b23914301b0cb051bf50064d8","dad3744ea7934aa4841590ffbdc27223","84248ef7f7744b559e3b7570a30fe26a","b15c4ae8ab2f47a0aa55827b9c46b73f","0848fba6740a428b95b883c345c70df1","6396b4176b1b451abb6bd90cb8e305ae","c4b0623e31aa4c3198299eeb81a45be8","a633333a21dc41f0a566e59ea37d22dc","bd1698916bb44852b0aa82cde1c49e8f","fdfbaa7d1d734b68abce234fa2fe03e4","d49b439af7af4157be0acb64040fa780","5e0ffb7c8d48496f88e4a51d12e2dd44","d0768f0121fa4d2fb8bf807395c8b1e2","784eb7a88644417d88ac082658c940a7","abfb996b5a674757a055814c5652aa16","190a993dfec84fa9b8a9ad73fa3fb0a0","bf69cd44b20f423483d709c6dce2a0e9","839cb52704aa43fdacd6fda62c17eec2","4af50359562a4f9b9e53f38dd4f29a85","f06c1e2d049543619f73cef84368b276","e7710fe20a764e57b450022813b0711d","00b1e7a3f6714bc68b1c22ca22538496","64a7cfdb8bb54b4b8b0b4127a1176610","c99f1557728141c9916b1302dab59f38","2072220aece142e18e1b7b06abe6ec57","70a4491f1db1459789cff72336f0ea5b","72263af83be445058fb089f7b143148a","efa0c8c5ab0c43449666f1f99542e200","8fa724c65a44473a9c310214bf825d52","a78b3ec7b73e4777b646e77fe913dba8","991efcb219f74207a898c3510198e12b","5320ffe4c60f44b68c686077aef39712","59352a463b7046de852de0210c38489c","f823e2b8faa145b9b8295cd7bbd4d963","390fc5399ef04b85998ff5d5025f8bec","376c320effc04f4c96348f88e68b28d5","a48e1e7ce45d4c8089de03f92ab80e3a","c290fae9ac2a4bc6832dfbec72909178","d96ec60add0346fdbf4c3dba0157e58a","a712bf350df84a3bba696ca16655d379","0b3216eda1be469f9a5173dbd1196cc8","5b63be9fc9e844a3aaf364ab77290bd8","88892d5ee18841dd8b1018f9f0600f5b","f636c702707b4e7ea0858c460df05da8","85d87b4089a44daaa7592606e07a3f8f","c4c6767545e14964a505beb403230ab8","977b8d771d5b44afbaa7356386647599","86bd943773fc44c490922f306777f43a","b516a25612ea40bcaafb09a39fd5af3d","4667abd8cb274a37ad16d5a871a26245","85d40a0c50334b9ebf6ce34a12f842d8","6a5efa5def894b65a4c6bdd46d485fa1"]},"executionInfo":{"status":"ok","timestamp":1731132769769,"user_tz":-540,"elapsed":91343,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"001e844b-8675-4452-b8be-d64378a99861"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45ab943b65da4c589af68ea8a7300240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851acae8bdee4488bf5ee8a8dc4ac48c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d91bf6aed54064b6bc8bb6f2986cb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ce4638005484627a0d9061ecd0dc489"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1698916bb44852b0aa82cde1c49e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06c1e2d049543619f73cef84368b276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991efcb219f74207a898c3510198e12b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b63be9fc9e844a3aaf364ab77290bd8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Downloading stanford-corenlp-3.6.0 for SPICE ...\n","Progress: 384.5M / 384.5M (100.0%)\n","Extracting stanford-corenlp-3.6.0 ...\n","Done.\n"]}]},{"cell_type":"code","source":["val_results = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(val_dataloader, desc=\"Calculating SPICE, CLIPScore, and CHAIRf\"):\n","        image_urls = batch['image_url']\n","        image_ids = batch['Image_ID']\n","        reference_captions = batch['reference_caption']\n","\n","        images = []\n","        for image_url in image_urls:\n","            response = requests.get(image_url)\n","            image = Image.open(BytesIO(response.content)).convert('RGB')\n","            images.append(image)\n","\n","        image_objects_batch = [\n","            extract_objects_from_caption(ref_caption, evaluation_objects)\n","            for ref_caption in reference_captions\n","        ]\n","\n","        inputs = processor(images=images, text=['Describe this image in detail.'] * len(images), return_tensors=\"pt\").to(device)\n","\n","        generated_ids = model.generate(**inputs,\n","                                       do_sample=True,\n","                                       num_beams=5,\n","                                       max_length=256,\n","                                       min_length=32,\n","                                       top_p=0.9,\n","                                       repetition_penalty=1.5,\n","                                       length_penalty=1.0,\n","                                       temperature=1)\n","\n","        generated_captions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n","        generated_captions = [caption.strip() for caption in generated_captions]\n","\n","        for image_id, generated_caption, reference_caption, image, image_objects in zip(\n","            image_ids, generated_captions, reference_captions, images, image_objects_batch\n","        ):\n","            spice_score, clip_score, chairf = calculate_metrics(\n","                image, generated_caption, reference_caption, image_objects\n","            )\n","\n","            val_results.append({\n","                \"Image_ID\": image_id,\n","                \"generated_caption\": generated_caption,\n","                \"reference_caption\": reference_caption,\n","                \"spice_score\": spice_score,\n","                \"clip_score\": clip_score,\n","                \"chairf\": chairf,\n","            })"],"metadata":{"id":"jTODC3vMuRkn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ce11031-a39d-489b-da27-d92e026e7dbb","executionInfo":{"status":"ok","timestamp":1731136179320,"user_tz":-540,"elapsed":2384203,"user":{"displayName":"서연우","userId":"17766624651891144537"}}},"execution_count":21,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   0%|          | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: set(), 이미지 객체: {'wall'}\n","spice_score: 0.4210526315789474, clip_score: 31.135454177856445, chairf: 0\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'table'}, 이미지 객체: {'table'}\n","spice_score: 0.3043478260869565, clip_score: 32.939659118652344, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'hair', 'shirt'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'hair', 'shirt'}\n","spice_score: 0.1818181818181818, clip_score: 27.208757400512695, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'ground', 'light', 'tree', 'grass', 'building'}, 캡션 객체: set(), 이미지 객체: {'ground', 'tree', 'grass', 'light', 'building'}\n","spice_score: 0.057142857142857134, clip_score: 26.977617263793945, chairf: 0\n","환각 객체: set(), 누락 객체: {'door'}, 캡션 객체: {'street'}, 이미지 객체: {'door', 'street'}\n","spice_score: 0.3809523809523809, clip_score: 34.09202575683594, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'pole', 'grass', 'tree', 'building'}, 캡션 객체: {'road', 'street', 'bus', 'people'}, 이미지 객체: {'tree', 'road', 'street', 'grass', 'bus', 'people', 'pole', 'building'}\n","spice_score: 0.08333333333333333, clip_score: 31.407821655273438, chairf: 0.6666666666666666\n","환각 객체: {'door', 'chair'}, 누락 객체: {'window', 'floor'}, 캡션 객체: {'dog', 'door', 'chair'}, 이미지 객체: {'dog', 'window', 'floor'}\n","spice_score: 0.19999999999999998, clip_score: 30.21019744873047, chairf: 0.3333333333333333\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   4%|▍         | 1/25 [02:11<52:29, 131.24s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'shirt', 'tree'}, 캡션 객체: set(), 이미지 객체: {'shirt', 'tree'}\n","spice_score: 0.18181818181818185, clip_score: 28.89893341064453, chairf: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: {'sky'}, 이미지 객체: {'sky'}\n","spice_score: 0.29411764705882354, clip_score: 25.918357849121094, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'wall'}\n","spice_score: 0.19672131147540983, clip_score: 34.686092376708984, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'fence', 'table'}, 캡션 객체: {'chair'}, 이미지 객체: {'fence', 'chair', 'table'}\n","spice_score: 0.3076923076923077, clip_score: 31.108001708984375, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'ground', 'grass'}, 캡션 객체: {'water', 'elephant'}, 이미지 객체: {'ground', 'water', 'grass', 'elephant'}\n","spice_score: 0.3333333333333333, clip_score: 30.768531799316406, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'plate', 'wall'}, 캡션 객체: set(), 이미지 객체: {'plate', 'wall'}\n","spice_score: 0.04545454545454545, clip_score: 24.21000862121582, chairf: 0\n","환각 객체: set(), 누락 객체: {'plate', 'sign', 'ground', 'tree'}, 캡션 객체: set(), 이미지 객체: {'plate', 'sign', 'ground', 'tree'}\n","spice_score: 0.05797101449275361, clip_score: 25.79677963256836, chairf: 0\n","환각 객체: {'hand'}, 누락 객체: {'car', 'building'}, 캡션 객체: {'woman', 'hand', 'street'}, 이미지 객체: {'woman', 'car', 'street', 'building'}\n","spice_score: 0.12765957446808512, clip_score: 34.18682861328125, chairf: 0.5714285714285715\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:   8%|▊         | 2/25 [05:42<1:08:16, 178.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'shirt', 'tree', 'road', 'car', 'building'}, 캡션 객체: {'sign', 'man', 'street'}, 이미지 객체: {'man', 'shirt', 'street', 'road', 'tree', 'car', 'sign', 'building'}\n","spice_score: 0.18518518518518517, clip_score: 30.166950225830078, chairf: 0.5454545454545454\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'water', 'tree'}, 캡션 객체: {'grass', 'zebra'}, 이미지 객체: {'water', 'grass', 'zebra', 'tree'}\n","spice_score: 0.14634146341463414, clip_score: 30.184879302978516, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'ground', 'snow', 'tree'}, 캡션 객체: {'fence', 'road', 'bus'}, 이미지 객체: {'ground', 'tree', 'road', 'snow', 'bus', 'fence'}\n","spice_score: 0.22727272727272727, clip_score: 32.62453079223633, chairf: 0.6666666666666666\n","환각 객체: {'street', 'road'}, 누락 객체: {'window', 'car', 'building'}, 캡션 객체: {'sign', 'road', 'street', 'bus'}, 이미지 객체: {'window', 'car', 'bus', 'sign', 'building'}\n","spice_score: 0.13157894736842107, clip_score: 32.622833251953125, chairf: 0.4444444444444445\n","환각 객체: {'hand'}, 누락 객체: {'head', 'glass'}, 캡션 객체: {'shirt', 'hand', 'people'}, 이미지 객체: {'glass', 'shirt', 'head', 'people'}\n","spice_score: 0.17543859649122806, clip_score: 31.755828857421875, chairf: 0.5714285714285715\n","환각 객체: set(), 누락 객체: {'shirt', 'people'}, 캡션 객체: {'girl', 'hand'}, 이미지 객체: {'girl', 'shirt', 'hand', 'people'}\n","spice_score: 0.4666666666666667, clip_score: 36.19526672363281, chairf: 0.6666666666666666\n","환각 객체: {'woman', 'hand'}, 누락 객체: {'fence', 'man'}, 캡션 객체: {'woman', 'hand'}, 이미지 객체: {'fence', 'man'}\n","spice_score: 0.12500000000000003, clip_score: 29.86689567565918, chairf: 0\n","환각 객체: set(), 누락 객체: {'ground', 'leg', 'glass'}, 캡션 객체: {'bear'}, 이미지 객체: {'ground', 'bear', 'leg', 'glass'}\n","spice_score: 0.2285714285714286, clip_score: 33.93415069580078, chairf: 0.4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  12%|█▏        | 3/25 [09:15<1:11:15, 194.33s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'light', 'glass'}, 캡션 객체: {'table'}, 이미지 객체: {'table', 'light', 'glass'}\n","spice_score: 0.20512820512820512, clip_score: 28.785234451293945, chairf: 0.5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: {'cat'}, 이미지 객체: {'cat'}\n","spice_score: 0.4, clip_score: 33.55595016479492, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'window'}, 캡션 객체: {'train'}, 이미지 객체: {'window', 'train'}\n","spice_score: 0.21052631578947367, clip_score: 24.87929916381836, chairf: 0.6666666666666666\n","환각 객체: {'woman'}, 누락 객체: {'pole', 'snow', 'shirt', 'cloud'}, 캡션 객체: {'woman', 'tree'}, 이미지 객체: {'shirt', 'tree', 'cloud', 'snow', 'pole'}\n","spice_score: 0.11111111111111112, clip_score: 29.358232498168945, chairf: 0.28571428571428575\n","환각 객체: {'hand'}, 누락 객체: {'window', 'shirt', 'tree', 'boy'}, 캡션 객체: {'table', 'girl', 'plate', 'hand'}, 이미지 객체: {'plate', 'girl', 'shirt', 'tree', 'window', 'boy', 'table'}\n","spice_score: 0.14035087719298245, clip_score: 26.031360626220703, chairf: 0.5454545454545454\n","환각 객체: set(), 누락 객체: {'light', 'wall', 'window', 'floor', 'head'}, 캡션 객체: set(), 이미지 객체: {'window', 'floor', 'head', 'light', 'wall'}\n","spice_score: 0.07407407407407408, clip_score: 34.885982513427734, chairf: 0\n","환각 객체: {'street'}, 누락 객체: set(), 캡션 객체: {'sign', 'street'}, 이미지 객체: {'sign'}\n","spice_score: 0.09090909090909091, clip_score: 28.13705825805664, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'grass', 'tree'}, 캡션 객체: set(), 이미지 객체: {'grass', 'tree'}\n","spice_score: 0.08695652173913045, clip_score: 25.236679077148438, chairf: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  16%|█▌        | 4/25 [11:21<58:31, 167.23s/it]  "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'snow', 'head'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'snow', 'head'}\n","spice_score: 0.09523809523809525, clip_score: 30.678707122802734, chairf: 0.5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'light', 'grass'}, 캡션 객체: {'elephant', 'tree'}, 이미지 객체: {'light', 'grass', 'elephant', 'tree'}\n","spice_score: 0.2051282051282051, clip_score: 38.062564849853516, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'shirt'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'shirt'}\n","spice_score: 0.14634146341463417, clip_score: 27.157623291015625, chairf: 0.6666666666666666\n","환각 객체: {'table', 'hand', 'glass'}, 누락 객체: {'wall', 'shirt'}, 캡션 객체: {'man', 'hand', 'woman', 'glass', 'table'}, 이미지 객체: {'woman', 'man', 'wall', 'shirt'}\n","spice_score: 0.0909090909090909, clip_score: 31.66356658935547, chairf: 0.4444444444444445\n","환각 객체: {'man', 'hat'}, 누락 객체: {'shirt', 'hair', 'eye', 'head', 'people', 'leg'}, 캡션 객체: {'man', 'hat', 'bird'}, 이미지 객체: {'shirt', 'hair', 'bird', 'eye', 'head', 'people', 'leg'}\n","spice_score: 0.11764705882352941, clip_score: 33.6163444519043, chairf: 0.2\n","환각 객체: set(), 누락 객체: {'people'}, 캡션 객체: {'sign', 'car', 'street'}, 이미지 객체: {'sign', 'car', 'street', 'people'}\n","spice_score: 0.2962962962962963, clip_score: 27.420135498046875, chairf: 0.8571428571428571\n","환각 객체: set(), 누락 객체: {'car'}, 캡션 객체: {'train', 'people'}, 이미지 객체: {'car', 'train', 'people'}\n","spice_score: 0.13114754098360654, clip_score: 26.336669921875, chairf: 0.8\n","환각 객체: set(), 누락 객체: {'light'}, 캡션 객체: {'sign', 'road'}, 이미지 객체: {'sign', 'light', 'road'}\n","spice_score: 0.16216216216216217, clip_score: 33.9852409362793, chairf: 0.8\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  20%|██        | 5/25 [13:25<50:35, 151.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: {'road'}, 누락 객체: {'car', 'street', 'building'}, 캡션 객체: {'road'}, 이미지 객체: {'car', 'street', 'building'}\n","spice_score: 0.23076923076923075, clip_score: 31.838947296142578, chairf: 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: set(), 누락 객체: {'window', 'sky', 'building', 'cloud'}, 캡션 객체: {'clock'}, 이미지 객체: {'cloud', 'window', 'clock', 'sky', 'building'}\n","spice_score: 0.12244897959183672, clip_score: 27.036718368530273, chairf: 0.33333333333333337\n","환각 객체: {'people'}, 누락 객체: {'woman', 'hair', 'shirt'}, 캡션 객체: {'dog', 'people'}, 이미지 객체: {'woman', 'hair', 'dog', 'shirt'}\n","spice_score: 0.2, clip_score: 33.00513458251953, chairf: 0.3333333333333333\n","환각 객체: set(), 누락 객체: {'shirt'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'shirt'}\n","spice_score: 0.26666666666666666, clip_score: 38.67162322998047, chairf: 0.6666666666666666\n","환각 객체: {'ground', 'car'}, 누락 객체: {'man', 'tree', 'road', 'woman', 'hat'}, 캡션 객체: {'ground', 'grass', 'car'}, 이미지 객체: {'man', 'tree', 'road', 'woman', 'grass', 'hat'}\n","spice_score: 0.06779661016949153, clip_score: 33.59376907348633, chairf: 0.2222222222222222\n","환각 객체: set(), 누락 객체: {'fence', 'shirt', 'tree'}, 캡션 객체: {'man', 'hand'}, 이미지 객체: {'man', 'shirt', 'hand', 'tree', 'fence'}\n","spice_score: 0.2222222222222222, clip_score: 31.410587310791016, chairf: 0.5714285714285715\n","환각 객체: {'people'}, 누락 객체: {'ground', 'man', 'hand', 'woman'}, 캡션 객체: {'snow', 'people'}, 이미지 객체: {'ground', 'man', 'hand', 'woman', 'snow'}\n","spice_score: 0.0816326530612245, clip_score: 32.892662048339844, chairf: 0.28571428571428575\n","환각 객체: set(), 누락 객체: {'ground', 'man', 'boy'}, 캡션 객체: {'hat'}, 이미지 객체: {'ground', 'man', 'hat', 'boy'}\n","spice_score: 0.11428571428571427, clip_score: 30.593793869018555, chairf: 0.4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  24%|██▍       | 6/25 [15:30<45:06, 142.45s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["환각 객체: {'street'}, 누락 객체: {'car', 'road'}, 캡션 객체: {'street', 'bus'}, 이미지 객체: {'car', 'bus', 'road'}\n","spice_score: 0.14814814814814814, clip_score: 32.094398498535156, chairf: 0.4\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'light', 'wall'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'wall', 'light'}\n","spice_score: 0.2978723404255319, clip_score: 35.848079681396484, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'glass'}, 캡션 객체: {'plate', 'table'}, 이미지 객체: {'plate', 'table', 'glass'}\n","spice_score: 0.2758620689655172, clip_score: 32.270355224609375, chairf: 0.8\n","환각 객체: {'woman'}, 누락 객체: {'head', 'man', 'hat', 'building'}, 캡션 객체: {'woman', 'dog', 'ground'}, 이미지 객체: {'ground', 'man', 'dog', 'hat', 'head', 'building'}\n","spice_score: 0.14285714285714288, clip_score: 30.96732521057129, chairf: 0.4444444444444444\n","환각 객체: set(), 누락 객체: {'head'}, 캡션 객체: {'water', 'bear'}, 이미지 객체: {'water', 'bear', 'head'}\n","spice_score: 0.23529411764705882, clip_score: 31.84568214416504, chairf: 0.8\n","환각 객체: set(), 누락 객체: {'plane'}, 캡션 객체: {'people'}, 이미지 객체: {'plane', 'people'}\n","spice_score: 0.3636363636363637, clip_score: 34.6474723815918, chairf: 0.6666666666666666\n","환각 객체: {'road'}, 누락 객체: {'man', 'shirt', 'street', 'tree'}, 캡션 객체: {'road'}, 이미지 객체: {'man', 'shirt', 'street', 'tree'}\n","spice_score: 0.15384615384615383, clip_score: 24.36336898803711, chairf: 0\n","환각 객체: {'cat'}, 누락 객체: {'window', 'floor', 'eye', 'light', 'leg'}, 캡션 객체: {'cat', 'chair'}, 이미지 객체: {'chair', 'window', 'floor', 'eye', 'light', 'leg'}\n","spice_score: 0.05128205128205128, clip_score: 30.386028289794922, chairf: 0.25\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  28%|██▊       | 7/25 [17:37<41:15, 137.55s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'building', 'tree'}, 캡션 객체: {'clock'}, 이미지 객체: {'clock', 'building', 'tree'}\n","spice_score: 0.1142857142857143, clip_score: 28.500629425048828, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'grass', 'street', 'hand', 'building'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'hand', 'street', 'grass', 'building'}\n","spice_score: 0.23076923076923078, clip_score: 37.03264617919922, chairf: 0.33333333333333337\n","환각 객체: {'man'}, 누락 객체: {'hat'}, 캡션 객체: {'man', 'shirt'}, 이미지 객체: {'hat', 'shirt'}\n","spice_score: 0.22222222222222224, clip_score: 27.865272521972656, chairf: 0.5\n","환각 객체: {'man'}, 누락 객체: {'wall', 'hand'}, 캡션 객체: {'man'}, 이미지 객체: {'wall', 'hand'}\n","spice_score: 0.3076923076923077, clip_score: 34.83952331542969, chairf: 0\n","환각 객체: {'shirt'}, 누락 객체: {'snow', 'sky', 'hat'}, 캡션 객체: {'shirt'}, 이미지 객체: {'sky', 'snow', 'hat'}\n","spice_score: 0.11538461538461538, clip_score: 30.981327056884766, chairf: 0\n","환각 객체: set(), 누락 객체: {'shirt'}, 캡션 객체: {'woman'}, 이미지 객체: {'woman', 'shirt'}\n","spice_score: 0.09090909090909091, clip_score: 29.092124938964844, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'grass', 'head'}, 캡션 객체: {'water', 'elephant'}, 이미지 객체: {'water', 'grass', 'elephant', 'head'}\n","spice_score: 0.3225806451612903, clip_score: 31.631261825561523, chairf: 0.6666666666666666\n","환각 객체: {'man', 'water'}, 누락 객체: set(), 캡션 객체: {'man', 'water', 'people'}, 이미지 객체: {'people'}\n","spice_score: 0.13333333333333333, clip_score: 28.811311721801758, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  32%|███▏      | 8/25 [19:48<38:22, 135.45s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'shirt'}, 누락 객체: {'cloud'}, 캡션 객체: {'sky', 'shirt', 'plane', 'people'}, 이미지 객체: {'sky', 'cloud', 'plane', 'people'}\n","spice_score: 0.24390243902439027, clip_score: 32.88450241088867, chairf: 0.75\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'table'}, 누락 객체: set(), 캡션 객체: {'table'}, 이미지 객체: set()\n","spice_score: 0.0, clip_score: 25.2811279296875, chairf: 0\n","환각 객체: set(), 누락 객체: {'fence', 'man', 'sky'}, 캡션 객체: set(), 이미지 객체: {'fence', 'man', 'sky'}\n","spice_score: 0.06060606060606061, clip_score: 27.72148323059082, chairf: 0\n","환각 객체: set(), 누락 객체: {'shirt'}, 캡션 객체: {'table', 'man'}, 이미지 객체: {'table', 'man', 'shirt'}\n","spice_score: 0.3333333333333333, clip_score: 26.71239471435547, chairf: 0.8\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'shirt', 'boy'}, 이미지 객체: {'shirt', 'boy'}\n","spice_score: 0.23809523809523808, clip_score: 34.70876693725586, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'hat', 'cloud'}, 캡션 객체: {'train'}, 이미지 객체: {'hat', 'train', 'cloud'}\n","spice_score: 0.1764705882352941, clip_score: 33.872188568115234, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'woman', 'man'}, 캡션 객체: {'building'}, 이미지 객체: {'woman', 'man', 'building'}\n","spice_score: 0.04761904761904761, clip_score: 24.261999130249023, chairf: 0.5\n","환각 객체: {'street', 'people'}, 누락 객체: {'woman', 'door', 'building', 'road'}, 캡션 객체: {'man', 'street', 'hat', 'horse', 'people'}, 이미지 객체: {'man', 'door', 'road', 'woman', 'hat', 'horse', 'building'}\n","spice_score: 0.22641509433962265, clip_score: 33.259700775146484, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  36%|███▌      | 9/25 [21:54<35:21, 132.58s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'man', 'shirt', 'people'}, 캡션 객체: {'tree'}, 이미지 객체: {'man', 'shirt', 'tree', 'people'}\n","spice_score: 0.13793103448275862, clip_score: 34.204612731933594, chairf: 0.4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'water', 'people'}, 캡션 객체: {'tree'}, 이미지 객체: {'water', 'tree', 'people'}\n","spice_score: 0.18749999999999997, clip_score: 30.33452606201172, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'table', 'glass'}, 캡션 객체: {'plate'}, 이미지 객체: {'plate', 'table', 'glass'}\n","spice_score: 0.15384615384615383, clip_score: 29.93706703186035, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'hair', 'wall', 'shirt'}, 캡션 객체: {'woman', 'floor', 'head'}, 이미지 객체: {'shirt', 'woman', 'hair', 'floor', 'head', 'wall'}\n","spice_score: 0.18181818181818182, clip_score: 30.866409301757812, chairf: 0.6666666666666666\n","환각 객체: {'road'}, 누락 객체: {'tree', 'window', 'glass', 'pole', 'building'}, 캡션 객체: {'sign', 'street', 'road'}, 이미지 객체: {'street', 'tree', 'window', 'sign', 'glass', 'pole', 'building'}\n","spice_score: 0.1142857142857143, clip_score: 40.45024108886719, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'water'}, 캡션 객체: {'table'}, 이미지 객체: {'table', 'water'}\n","spice_score: 0.14634146341463417, clip_score: 33.11134719848633, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'window', 'wall', 'eye', 'head'}, 캡션 객체: {'dog'}, 이미지 객체: {'dog', 'window', 'eye', 'head', 'wall'}\n","spice_score: 0.15, clip_score: 27.847457885742188, chairf: 0.33333333333333337\n","환각 객체: set(), 누락 객체: {'ground', 'grass', 'wall'}, 캡션 객체: set(), 이미지 객체: {'ground', 'grass', 'wall'}\n","spice_score: 0.05714285714285714, clip_score: 27.81430435180664, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  40%|████      | 10/25 [24:05<32:57, 131.85s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'plate', 'man', 'tree', 'grass', 'light', 'people'}, 캡션 객체: {'car'}, 이미지 객체: {'plate', 'man', 'tree', 'grass', 'car', 'light', 'people'}\n","spice_score: 0.04878048780487805, clip_score: 31.57988739013672, chairf: 0.25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'light'}, 캡션 객체: {'dog'}, 이미지 객체: {'dog', 'light'}\n","spice_score: 0.1276595744680851, clip_score: 26.657176971435547, chairf: 0.6666666666666666\n","환각 객체: {'woman'}, 누락 객체: {'hat', 'head'}, 캡션 객체: {'woman', 'horse', 'people'}, 이미지 객체: {'head', 'hat', 'horse', 'people'}\n","spice_score: 0.11538461538461538, clip_score: 26.004535675048828, chairf: 0.5714285714285715\n","환각 객체: {'pole'}, 누락 객체: {'street', 'hand'}, 캡션 객체: {'pole', 'man', 'shirt'}, 이미지 객체: {'hand', 'man', 'shirt', 'street'}\n","spice_score: 0.25, clip_score: 31.52082061767578, chairf: 0.5714285714285715\n","환각 객체: set(), 누락 객체: {'window', 'chair'}, 캡션 객체: {'wall', 'floor', 'table'}, 이미지 객체: {'chair', 'window', 'floor', 'wall', 'table'}\n","spice_score: 0.2962962962962963, clip_score: 29.4310302734375, chairf: 0.7499999999999999\n","환각 객체: set(), 누락 객체: {'man', 'people'}, 캡션 객체: {'water', 'hand'}, 이미지 객체: {'man', 'water', 'hand', 'people'}\n","spice_score: 0.2448979591836735, clip_score: 28.411087036132812, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'chair', 'woman', 'floor', 'wall', 'table', 'building'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'chair', 'woman', 'floor', 'wall', 'table', 'building'}\n","spice_score: 0.03571428571428572, clip_score: 25.203248977661133, chairf: 0.25\n","환각 객체: {'street'}, 누락 객체: {'pole', 'car', 'road'}, 캡션 객체: {'sign', 'street'}, 이미지 객체: {'sign', 'pole', 'car', 'road'}\n","spice_score: 0.08333333333333333, clip_score: 32.52632522583008, chairf: 0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  44%|████▍     | 11/25 [26:13<30:31, 130.82s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'woman', 'hair'}, 캡션 객체: {'girl', 'shirt', 'bus'}, 이미지 객체: {'girl', 'shirt', 'woman', 'hair', 'bus'}\n","spice_score: 0.2325581395348837, clip_score: 37.74381637573242, chairf: 0.7499999999999999\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'man'}, 누락 객체: {'grass'}, 캡션 객체: {'man', 'road'}, 이미지 객체: {'grass', 'road'}\n","spice_score: 0.19354838709677416, clip_score: 31.98053550720215, chairf: 0.5\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'cat', 'door'}, 이미지 객체: {'door', 'cat'}\n","spice_score: 0.32, clip_score: 32.195281982421875, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'ground', 'window', 'plane', 'door'}, 캡션 객체: set(), 이미지 객체: {'ground', 'window', 'plane', 'door'}\n","spice_score: 0.05405405405405405, clip_score: 28.412845611572266, chairf: 0\n","환각 객체: set(), 누락 객체: {'window'}, 캡션 객체: {'chair'}, 이미지 객체: {'window', 'chair'}\n","spice_score: 0.18181818181818182, clip_score: 28.196006774902344, chairf: 0.6666666666666666\n","환각 객체: {'road'}, 누락 객체: {'light', 'tree'}, 캡션 객체: {'car', 'street', 'road'}, 이미지 객체: {'light', 'car', 'street', 'tree'}\n","spice_score: 0.23809523809523808, clip_score: 35.41661071777344, chairf: 0.5714285714285715\n","환각 객체: {'street', 'people'}, 누락 객체: {'man', 'tree', 'woman', 'car', 'sign', 'sky'}, 캡션 객체: {'street', 'road', 'people'}, 이미지 객체: {'man', 'tree', 'road', 'woman', 'car', 'sign', 'sky'}\n","spice_score: 0.16666666666666666, clip_score: 32.15944290161133, chairf: 0.2\n","환각 객체: set(), 누락 객체: {'glass'}, 캡션 객체: {'table'}, 이미지 객체: {'table', 'glass'}\n","spice_score: 0.125, clip_score: 28.702608108520508, chairf: 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  48%|████▊     | 12/25 [28:20<28:04, 129.61s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'wall', 'hand'}, 캡션 객체: {'clock', 'building'}, 이미지 객체: {'hand', 'clock', 'wall', 'building'}\n","spice_score: 0.4444444444444444, clip_score: 32.4915657043457, chairf: 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'sky', 'water'}, 캡션 객체: {'woman', 'horse', 'people'}, 이미지 객체: {'water', 'woman', 'horse', 'sky', 'people'}\n","spice_score: 0.3043478260869565, clip_score: 36.50529479980469, chairf: 0.7499999999999999\n","환각 객체: {'grass'}, 누락 객체: {'building'}, 캡션 객체: {'grass'}, 이미지 객체: {'building'}\n","spice_score: 0.1, clip_score: 36.876060485839844, chairf: 0\n","환각 객체: {'light', 'road'}, 누락 객체: {'street', 'tree', 'building'}, 캡션 객체: {'sign', 'light', 'road'}, 이미지 객체: {'sign', 'tree', 'street', 'building'}\n","spice_score: 0.07547169811320754, clip_score: 34.22380828857422, chairf: 0.28571428571428575\n","환각 객체: set(), 누락 객체: {'man', 'tree', 'road'}, 캡션 객체: {'street', 'bus'}, 이미지 객체: {'man', 'street', 'road', 'tree', 'bus'}\n","spice_score: 0.16216216216216217, clip_score: 31.808435440063477, chairf: 0.5714285714285715\n","환각 객체: set(), 누락 객체: {'plane'}, 캡션 객체: {'sky'}, 이미지 객체: {'sky', 'plane'}\n","spice_score: 0.36363636363636365, clip_score: 30.030187606811523, chairf: 0.6666666666666666\n","환각 객체: {'light', 'street'}, 누락 객체: {'sign', 'bus', 'people'}, 캡션 객체: {'light', 'car', 'street', 'road'}, 이미지 객체: {'road', 'car', 'bus', 'sign', 'people'}\n","spice_score: 0.13333333333333333, clip_score: 29.965478897094727, chairf: 0.4444444444444445\n","환각 객체: {'street'}, 누락 객체: {'tree'}, 캡션 객체: {'street'}, 이미지 객체: {'tree'}\n","spice_score: 0.16216216216216214, clip_score: 33.39161682128906, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  52%|█████▏    | 13/25 [30:29<25:52, 129.35s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'hand'}, 누락 객체: {'man', 'shirt'}, 캡션 객체: {'water', 'hand'}, 이미지 객체: {'shirt', 'man', 'water'}\n","spice_score: 0.18181818181818182, clip_score: 25.013813018798828, chairf: 0.4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'man'}, 누락 객체: {'people'}, 캡션 객체: {'fence', 'man'}, 이미지 객체: {'fence', 'people'}\n","spice_score: 0.2105263157894737, clip_score: 30.575599670410156, chairf: 0.5\n","환각 객체: {'hand'}, 누락 객체: {'wall', 'grass', 'sky'}, 캡션 객체: {'woman', 'dog', 'hand'}, 이미지 객체: {'woman', 'dog', 'grass', 'sky', 'wall'}\n","spice_score: 0.19047619047619047, clip_score: 33.52299880981445, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'window', 'sky', 'building', 'cloud'}, 캡션 객체: set(), 이미지 객체: {'window', 'sky', 'building', 'cloud'}\n","spice_score: 0.03571428571428571, clip_score: 31.84840965270996, chairf: 0\n","환각 객체: {'people'}, 누락 객체: {'pole', 'light', 'building'}, 캡션 객체: {'shirt', 'people'}, 이미지 객체: {'pole', 'light', 'shirt', 'building'}\n","spice_score: 0.2033898305084746, clip_score: 30.734634399414062, chairf: 0.3333333333333333\n","환각 객체: set(), 누락 객체: {'window', 'sky', 'people'}, 캡션 객체: {'clock', 'train'}, 이미지 객체: {'window', 'train', 'clock', 'sky', 'people'}\n","spice_score: 0.2325581395348837, clip_score: 29.552040100097656, chairf: 0.5714285714285715\n","환각 객체: {'girl'}, 누락 객체: {'grass', 'shirt', 'building', 'boy'}, 캡션 객체: {'dog', 'girl', 'tree'}, 이미지 객체: {'shirt', 'tree', 'dog', 'grass', 'boy', 'building'}\n","spice_score: 0.23809523809523808, clip_score: 30.135683059692383, chairf: 0.4444444444444444\n","환각 객체: set(), 누락 객체: {'fence'}, 캡션 객체: {'zebra', 'tree'}, 이미지 객체: {'fence', 'zebra', 'tree'}\n","spice_score: 0.19999999999999998, clip_score: 36.644832611083984, chairf: 0.8\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  56%|█████▌    | 14/25 [32:38<23:44, 129.47s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'man', 'shirt'}, 누락 객체: {'snow', 'tree'}, 캡션 객체: {'man', 'shirt'}, 이미지 객체: {'snow', 'tree'}\n","spice_score: 0.03225806451612903, clip_score: 32.43476104736328, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'table', 'elephant'}, 누락 객체: set(), 캡션 객체: {'table', 'elephant'}, 이미지 객체: set()\n","spice_score: 0.23529411764705882, clip_score: 33.053123474121094, chairf: 0\n","환각 객체: set(), 누락 객체: {'light', 'sky', 'grass', 'cloud'}, 캡션 객체: {'water'}, 이미지 객체: {'water', 'cloud', 'grass', 'light', 'sky'}\n","spice_score: 0.13043478260869568, clip_score: 31.997913360595703, chairf: 0.33333333333333337\n","환각 객체: set(), 누락 객체: {'people'}, 캡션 객체: {'wall'}, 이미지 객체: {'wall', 'people'}\n","spice_score: 0.25, clip_score: 31.713836669921875, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'table', 'glass'}, 캡션 객체: {'plate'}, 이미지 객체: {'plate', 'table', 'glass'}\n","spice_score: 0.1111111111111111, clip_score: 27.79165267944336, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'sky', 'cloud'}, 캡션 객체: {'sign', 'pole'}, 이미지 객체: {'pole', 'sky', 'sign', 'cloud'}\n","spice_score: 0.26666666666666666, clip_score: 33.76253128051758, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'ground', 'sign', 'light', 'sky', 'cloud'}, 캡션 객체: set(), 이미지 객체: {'ground', 'cloud', 'sign', 'light', 'sky'}\n","spice_score: 0.14285714285714285, clip_score: 36.03653335571289, chairf: 0\n","환각 객체: set(), 누락 객체: {'grass', 'sky', 'head', 'tree'}, 캡션 객체: set(), 이미지 객체: {'grass', 'sky', 'head', 'tree'}\n","spice_score: 0.0909090909090909, clip_score: 25.831798553466797, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  60%|██████    | 15/25 [34:52<21:48, 130.85s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'hand'}, 누락 객체: {'window', 'wall', 'shirt', 'tree'}, 캡션 객체: {'table', 'man', 'hand'}, 이미지 객체: {'man', 'shirt', 'tree', 'window', 'wall', 'table'}\n","spice_score: 0.07017543859649122, clip_score: 23.531095504760742, chairf: 0.4444444444444444\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'man', 'shirt', 'tree', 'fence', 'pole', 'building'}, 캡션 객체: set(), 이미지 객체: {'man', 'shirt', 'tree', 'pole', 'fence', 'building'}\n","spice_score: 0.15, clip_score: 28.69780731201172, chairf: 0\n","환각 객체: set(), 누락 객체: {'ground'}, 캡션 객체: set(), 이미지 객체: {'ground'}\n","spice_score: 0.13043478260869565, clip_score: 31.6590518951416, chairf: 0\n","환각 객체: set(), 누락 객체: {'sign', 'people'}, 캡션 객체: {'train'}, 이미지 객체: {'sign', 'train', 'people'}\n","spice_score: 0.20408163265306123, clip_score: 30.14006996154785, chairf: 0.5\n","환각 객체: {'table', 'clock'}, 누락 객체: {'window', 'wall', 'chair', 'floor'}, 캡션 객체: {'table', 'clock'}, 이미지 객체: {'wall', 'window', 'floor', 'chair'}\n","spice_score: 0.19999999999999998, clip_score: 31.692197799682617, chairf: 0\n","환각 객체: {'hand'}, 누락 객체: {'shirt', 'head'}, 캡션 객체: {'man', 'hand'}, 이미지 객체: {'man', 'shirt', 'head'}\n","spice_score: 0.20833333333333331, clip_score: 28.3714656829834, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'ground', 'grass', 'tree'}, 캡션 객체: {'zebra'}, 이미지 객체: {'ground', 'grass', 'zebra', 'tree'}\n","spice_score: 0.05128205128205128, clip_score: 38.00689697265625, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'table'}, 캡션 객체: {'plate'}, 이미지 객체: {'plate', 'table'}\n","spice_score: 0.14814814814814817, clip_score: 34.466087341308594, chairf: 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  64%|██████▍   | 16/25 [37:00<19:28, 129.78s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: set(), 이미지 객체: set()\n","spice_score: 0.23529411764705882, clip_score: 34.12485122680664, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'shirt', 'water', 'tree'}, 캡션 객체: {'man'}, 이미지 객체: {'water', 'man', 'shirt', 'tree'}\n","spice_score: 0.18181818181818182, clip_score: 32.68496322631836, chairf: 0.4\n","환각 객체: {'woman', 'wall'}, 누락 객체: {'hair', 'sign'}, 캡션 객체: {'woman', 'wall'}, 이미지 객체: {'hair', 'sign'}\n","spice_score: 0.0425531914893617, clip_score: 34.19029235839844, chairf: 0\n","환각 객체: {'pole'}, 누락 객체: {'snow', 'hat'}, 캡션 객체: {'pole', 'people'}, 이미지 객체: {'snow', 'hat', 'people'}\n","spice_score: 0.13333333333333333, clip_score: 27.22451400756836, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'leg', 'hand', 'people'}, 캡션 객체: set(), 이미지 객체: {'hand', 'leg', 'people'}\n","spice_score: 0.1951219512195122, clip_score: 28.550094604492188, chairf: 0\n","환각 객체: set(), 누락 객체: {'door', 'wall', 'tree'}, 캡션 객체: {'street', 'bus'}, 이미지 객체: {'door', 'street', 'tree', 'bus', 'wall'}\n","spice_score: 0.10909090909090909, clip_score: 31.654415130615234, chairf: 0.5714285714285715\n","환각 객체: set(), 누락 객체: {'wall'}, 캡션 객체: set(), 이미지 객체: {'wall'}\n","spice_score: 0.2580645161290323, clip_score: 32.268436431884766, chairf: 0\n","환각 객체: set(), 누락 객체: {'hat'}, 캡션 객체: {'sign', 'man', 'horse', 'road'}, 이미지 객체: {'man', 'road', 'hat', 'horse', 'sign'}\n","spice_score: 0.28, clip_score: 36.376312255859375, chairf: 0.888888888888889\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  68%|██████▊   | 17/25 [39:09<17:17, 129.71s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'sign', 'wall', 'people'}, 캡션 객체: set(), 이미지 객체: {'sign', 'wall', 'people'}\n","spice_score: 0.08823529411764706, clip_score: 32.683616638183594, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'grass', 'head'}, 캡션 객체: {'water', 'zebra'}, 이미지 객체: {'water', 'grass', 'zebra', 'head'}\n","spice_score: 0.17142857142857146, clip_score: 28.986793518066406, chairf: 0.6666666666666666\n","환각 객체: {'hand'}, 누락 객체: {'hat', 'shirt'}, 캡션 객체: {'man', 'hand'}, 이미지 객체: {'man', 'hat', 'shirt'}\n","spice_score: 0.20512820512820512, clip_score: 34.08175277709961, chairf: 0.4\n","환각 객체: {'table', 'clock'}, 누락 객체: {'chair'}, 캡션 객체: {'table', 'clock', 'wall'}, 이미지 객체: {'wall', 'chair'}\n","spice_score: 0.17391304347826086, clip_score: 27.150169372558594, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'ground'}, 캡션 객체: {'zebra', 'tree'}, 이미지 객체: {'ground', 'zebra', 'tree'}\n","spice_score: 0.25, clip_score: 32.138694763183594, chairf: 0.8\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'dog'}, 이미지 객체: {'dog'}\n","spice_score: 0.11320754716981131, clip_score: 31.270402908325195, chairf: 1.0\n","환각 객체: {'sign'}, 누락 객체: {'woman', 'man', 'plane'}, 캡션 객체: {'sign', 'people'}, 이미지 객체: {'woman', 'man', 'plane', 'people'}\n","spice_score: 0.12903225806451615, clip_score: 33.20194625854492, chairf: 0.3333333333333333\n","환각 객체: set(), 누락 객체: {'hat', 'hand', 'tree'}, 캡션 객체: {'water', 'boat', 'people'}, 이미지 객체: {'water', 'hand', 'tree', 'hat', 'boat', 'people'}\n","spice_score: 0.2777777777777778, clip_score: 31.67698097229004, chairf: 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  72%|███████▏  | 18/25 [41:13<14:54, 127.76s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'hand'}, 누락 객체: {'shirt'}, 캡션 객체: {'man', 'hand'}, 이미지 객체: {'man', 'shirt'}\n","spice_score: 0.3448275862068965, clip_score: 24.693683624267578, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: set(), 이미지 객체: set()\n","spice_score: 0.1379310344827586, clip_score: 27.15941047668457, chairf: 0\n","환각 객체: {'street', 'building'}, 누락 객체: {'woman', 'man', 'shirt', 'road'}, 캡션 객체: {'building', 'street', 'bus', 'people'}, 이미지 객체: {'man', 'shirt', 'road', 'woman', 'bus', 'people'}\n","spice_score: 0.25925925925925924, clip_score: 30.93351173400879, chairf: 0.4\n","환각 객체: {'bear'}, 누락 객체: set(), 캡션 객체: {'bear'}, 이미지 객체: set()\n","spice_score: 0.20689655172413793, clip_score: 27.226308822631836, chairf: 0\n","환각 객체: {'hand'}, 누락 객체: {'hair', 'wall', 'shirt', 'people'}, 캡션 객체: {'woman', 'hand'}, 이미지 객체: {'shirt', 'woman', 'hair', 'wall', 'people'}\n","spice_score: 0.11320754716981132, clip_score: 32.236873626708984, chairf: 0.28571428571428575\n","환각 객체: {'dog'}, 누락 객체: {'glass', 'hand', 'building'}, 캡션 객체: {'dog', 'man'}, 이미지 객체: {'man', 'hand', 'building', 'glass'}\n","spice_score: 0.19354838709677416, clip_score: 27.394676208496094, chairf: 0.3333333333333333\n","환각 객체: set(), 누락 객체: {'ground', 'man', 'hand', 'grass', 'shoe'}, 캡션 객체: set(), 이미지 객체: {'ground', 'man', 'hand', 'grass', 'shoe'}\n","spice_score: 0.0, clip_score: 28.88922691345215, chairf: 0\n","환각 객체: {'table'}, 누락 객체: {'wall', 'chair', 'eye', 'floor'}, 캡션 객체: {'table', 'cat'}, 이미지 객체: {'chair', 'floor', 'eye', 'cat', 'wall'}\n","spice_score: 0.10714285714285712, clip_score: 23.608118057250977, chairf: 0.28571428571428575\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  76%|███████▌  | 19/25 [43:22<12:50, 128.37s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'people'}, 누락 객체: {'girl', 'man', 'tree', 'hair', 'boat'}, 캡션 객체: {'water', 'people'}, 이미지 객체: {'girl', 'man', 'water', 'tree', 'hair', 'boat'}\n","spice_score: 0.0606060606060606, clip_score: 34.02609634399414, chairf: 0.25\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'head'}, 누락 객체: {'ground', 'grass', 'leg'}, 캡션 객체: {'head', 'giraffe', 'tree'}, 이미지 객체: {'ground', 'giraffe', 'tree', 'grass', 'leg'}\n","spice_score: 0.1702127659574468, clip_score: 34.76322937011719, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'plate', 'grass', 'boy'}, 캡션 객체: {'fence'}, 이미지 객체: {'fence', 'grass', 'plate', 'boy'}\n","spice_score: 0.1081081081081081, clip_score: 29.90230369567871, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'grass', 'water'}, 캡션 객체: {'elephant'}, 이미지 객체: {'water', 'grass', 'elephant'}\n","spice_score: 0.05, clip_score: 37.83119583129883, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'sign', 'tree', 'building'}, 캡션 객체: {'light', 'car', 'street', 'road'}, 이미지 객체: {'tree', 'road', 'street', 'car', 'sign', 'light', 'building'}\n","spice_score: 0.18181818181818182, clip_score: 28.49326515197754, chairf: 0.7272727272727273\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'man', 'shirt'}, 이미지 객체: {'man', 'shirt'}\n","spice_score: 0.3333333333333333, clip_score: 30.61029815673828, chairf: 1.0\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: set(), 이미지 객체: set()\n","spice_score: 0.2962962962962963, clip_score: 31.52105712890625, chairf: 0\n","환각 객체: set(), 누락 객체: {'door'}, 캡션 객체: {'wall', 'shirt', 'boy'}, 이미지 객체: {'door', 'wall', 'shirt', 'boy'}\n","spice_score: 0.2222222222222222, clip_score: 36.04367446899414, chairf: 0.8571428571428571\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  80%|████████  | 20/25 [46:32<12:13, 146.65s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'sign', 'window', 'door'}, 캡션 객체: {'wall'}, 이미지 객체: {'window', 'door', 'wall', 'sign'}\n","spice_score: 0.15873015873015872, clip_score: 24.507997512817383, chairf: 0.4\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'window'}, 누락 객체: {'wall'}, 캡션 객체: {'window', 'cat'}, 이미지 객체: {'cat', 'wall'}\n","spice_score: 0.13333333333333333, clip_score: 30.845169067382812, chairf: 0.5\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'shirt', 'man', 'grass'}, 이미지 객체: {'man', 'grass', 'shirt'}\n","spice_score: 0.3448275862068965, clip_score: 33.887203216552734, chairf: 1.0\n","환각 객체: {'plane'}, 누락 객체: {'chair', 'hand', 'floor', 'table', 'building'}, 캡션 객체: {'plane', 'people'}, 이미지 객체: {'chair', 'hand', 'floor', 'people', 'table', 'building'}\n","spice_score: 0.1702127659574468, clip_score: 27.57904815673828, chairf: 0.25\n","환각 객체: {'people'}, 누락 객체: {'ground'}, 캡션 객체: {'people'}, 이미지 객체: {'ground'}\n","spice_score: 0.045454545454545456, clip_score: 35.298641204833984, chairf: 0\n","환각 객체: {'people'}, 누락 객체: {'pole', 'man'}, 캡션 객체: {'people'}, 이미지 객체: {'pole', 'man'}\n","spice_score: 0.0, clip_score: 31.27692985534668, chairf: 0\n","환각 객체: set(), 누락 객체: {'plate', 'grass', 'people'}, 캡션 객체: set(), 이미지 객체: {'plate', 'grass', 'people'}\n","spice_score: 0.14814814814814814, clip_score: 28.923173904418945, chairf: 0\n","환각 객체: set(), 누락 객체: {'hand'}, 캡션 객체: {'boy'}, 이미지 객체: {'hand', 'boy'}\n","spice_score: 0.26666666666666666, clip_score: 28.472455978393555, chairf: 0.6666666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  84%|████████▍ | 21/25 [48:33<09:16, 139.10s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'plane'}, 누락 객체: {'grass'}, 캡션 객체: {'man', 'plane'}, 이미지 객체: {'man', 'grass'}\n","spice_score: 0.24999999999999994, clip_score: 33.675048828125, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: {'clock', 'tree'}, 누락 객체: {'sky', 'cloud'}, 캡션 객체: {'bird', 'clock', 'building', 'tree'}, 이미지 객체: {'bird', 'sky', 'building', 'cloud'}\n","spice_score: 0.11428571428571427, clip_score: 32.50627517700195, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'hand'}, 캡션 객체: set(), 이미지 객체: {'hand'}\n","spice_score: 0.21428571428571427, clip_score: 31.092208862304688, chairf: 0\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'table', 'plate'}, 이미지 객체: {'table', 'plate'}\n","spice_score: 0.13636363636363635, clip_score: 27.708452224731445, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'ground', 'sign'}, 캡션 객체: {'train', 'people'}, 이미지 객체: {'ground', 'train', 'sign', 'people'}\n","spice_score: 0.1568627450980392, clip_score: 31.24350929260254, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'plate'}, 이미지 객체: {'plate'}\n","spice_score: 0.4444444444444445, clip_score: 39.36964416503906, chairf: 1.0\n","환각 객체: {'table', 'chair'}, 누락 객체: {'tree'}, 캡션 객체: {'table', 'chair', 'street'}, 이미지 객체: {'street', 'tree'}\n","spice_score: 0.05714285714285714, clip_score: 35.59141159057617, chairf: 0.4\n","환각 객체: {'hand', 'people'}, 누락 객체: {'sky', 'man', 'hat'}, 캡션 객체: {'pole', 'hand', 'people'}, 이미지 객체: {'man', 'pole', 'hat', 'sky'}\n","spice_score: 0.08695652173913043, clip_score: 31.242427825927734, chairf: 0.28571428571428575\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  88%|████████▊ | 22/25 [50:35<06:41, 133.96s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'door', 'shirt', 'head', 'glass'}, 캡션 객체: {'man', 'wall'}, 이미지 객체: {'man', 'door', 'shirt', 'head', 'wall', 'glass'}\n","spice_score: 0.13636363636363635, clip_score: 36.827430725097656, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: set(), 캡션 객체: {'plate'}, 이미지 객체: {'plate'}\n","spice_score: 0.1904761904761905, clip_score: 29.140026092529297, chairf: 1.0\n","환각 객체: set(), 누락 객체: {'man', 'people', 'hat', 'horse', 'building'}, 캡션 객체: set(), 이미지 객체: {'man', 'hat', 'horse', 'people', 'building'}\n","spice_score: 0.033898305084745756, clip_score: 30.857425689697266, chairf: 0\n","환각 객체: {'hat'}, 누락 객체: {'eye', 'head'}, 캡션 객체: {'cat', 'hat'}, 이미지 객체: {'cat', 'eye', 'head'}\n","spice_score: 0.11764705882352941, clip_score: 33.54052734375, chairf: 0.4\n","환각 객체: {'building'}, 누락 객체: {'ground', 'wall', 'sign', 'people'}, 캡션 객체: {'train', 'building'}, 이미지 객체: {'ground', 'train', 'sign', 'wall', 'people'}\n","spice_score: 0.12765957446808512, clip_score: 26.31586265563965, chairf: 0.28571428571428575\n","환각 객체: {'road'}, 누락 객체: {'light', 'building'}, 캡션 객체: {'man', 'car', 'street', 'road'}, 이미지 객체: {'man', 'street', 'car', 'light', 'building'}\n","spice_score: 0.3684210526315789, clip_score: 24.55060386657715, chairf: 0.6666666666666665\n","환각 객체: set(), 누락 객체: {'shirt'}, 캡션 객체: {'man'}, 이미지 객체: {'man', 'shirt'}\n","spice_score: 0.23076923076923075, clip_score: 30.584972381591797, chairf: 0.6666666666666666\n","환각 객체: set(), 누락 객체: {'zebra', 'head'}, 캡션 객체: set(), 이미지 객체: {'zebra', 'head'}\n","spice_score: 0.15384615384615383, clip_score: 27.497920989990234, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  92%|█████████▏| 23/25 [52:44<04:24, 132.41s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'hat', 'wall', 'shirt', 'people'}, 캡션 객체: {'man', 'water'}, 이미지 객체: {'man', 'water', 'shirt', 'hat', 'wall', 'people'}\n","spice_score: 0.25, clip_score: 31.229982376098633, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'tree'}, 캡션 객체: {'fence', 'elephant'}, 이미지 객체: {'fence', 'elephant', 'tree'}\n","spice_score: 0.2, clip_score: 29.145092010498047, chairf: 0.8\n","환각 객체: {'fence'}, 누락 객체: {'grass', 'tree'}, 캡션 객체: {'fence', 'man'}, 이미지 객체: {'man', 'grass', 'tree'}\n","spice_score: 0.3703703703703703, clip_score: 28.222387313842773, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'wall', 'people'}, 캡션 객체: {'shirt'}, 이미지 객체: {'wall', 'shirt', 'people'}\n","spice_score: 0.18867924528301885, clip_score: 30.435026168823242, chairf: 0.5\n","환각 객체: {'hand'}, 누락 객체: {'wall', 'people'}, 캡션 객체: {'shirt', 'hand'}, 이미지 객체: {'wall', 'shirt', 'people'}\n","spice_score: 0.1702127659574468, clip_score: 29.54280662536621, chairf: 0.4\n","환각 객체: set(), 누락 객체: {'floor', 'eye', 'head'}, 캡션 객체: set(), 이미지 객체: {'floor', 'eye', 'head'}\n","spice_score: 0.08888888888888888, clip_score: 33.60344696044922, chairf: 0\n","환각 객체: set(), 누락 객체: {'light', 'building'}, 캡션 객체: set(), 이미지 객체: {'light', 'building'}\n","spice_score: 0.14285714285714288, clip_score: 27.169921875, chairf: 0\n","환각 객체: set(), 누락 객체: {'water', 'shirt', 'cloud', 'hat', 'boat', 'light', 'sky'}, 캡션 객체: {'woman', 'man'}, 이미지 객체: {'man', 'shirt', 'water', 'cloud', 'woman', 'hat', 'boat', 'light', 'sky'}\n","spice_score: 0.11267605633802817, clip_score: 29.715883255004883, chairf: 0.3636363636363636\n"]},{"output_type":"stream","name":"stderr","text":["\rCalculating SPICE, CLIPScore, and CHAIRf:  96%|█████████▌| 24/25 [54:48<02:09, 129.93s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'water', 'building'}, 캡션 객체: {'clock'}, 이미지 객체: {'clock', 'water', 'building'}\n","spice_score: 0.08, clip_score: 25.26276969909668, chairf: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'window'}, 캡션 객체: {'table'}, 이미지 객체: {'table', 'window'}\n","spice_score: 0.31999999999999995, clip_score: 26.807785034179688, chairf: 0.6666666666666666\n","환각 객체: {'wall'}, 누락 객체: {'fence', 'hair', 'water'}, 캡션 객체: {'giraffe', 'wall', 'grass'}, 이미지 객체: {'giraffe', 'water', 'hair', 'grass', 'fence'}\n","spice_score: 0.12903225806451613, clip_score: 34.386199951171875, chairf: 0.5\n","환각 객체: set(), 누락 객체: {'man', 'hat', 'shirt'}, 캡션 객체: {'street', 'horse'}, 이미지 객체: {'man', 'shirt', 'street', 'hat', 'horse'}\n","spice_score: 0.3448275862068966, clip_score: 33.19480514526367, chairf: 0.5714285714285715\n","환각 객체: set(), 누락 객체: {'pole', 'light'}, 캡션 객체: {'train'}, 이미지 객체: {'pole', 'light', 'train'}\n","spice_score: 0.28571428571428575, clip_score: 30.318870544433594, chairf: 0.5\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: set(), 이미지 객체: set()\n","spice_score: 0.3125, clip_score: 30.125825881958008, chairf: 0\n","환각 객체: set(), 누락 객체: set(), 캡션 객체: {'bird', 'water'}, 이미지 객체: {'bird', 'water'}\n","spice_score: 0.11764705882352941, clip_score: 27.65911293029785, chairf: 1.0\n","환각 객체: {'head', 'road'}, 누락 객체: {'ground'}, 캡션 객체: {'zebra', 'head', 'road'}, 이미지 객체: {'ground', 'zebra'}\n","spice_score: 0.08695652173913043, clip_score: 34.89484786987305, chairf: 0.4\n"]},{"output_type":"stream","name":"stderr","text":["Calculating SPICE, CLIPScore, and CHAIRf: 100%|██████████| 25/25 [56:49<00:00, 136.38s/it]"]},{"output_type":"stream","name":"stdout","text":["환각 객체: set(), 누락 객체: {'plate', 'light', 'wall', 'window', 'head'}, 캡션 객체: set(), 이미지 객체: {'plate', 'window', 'head', 'light', 'wall'}\n","spice_score: 0.12244897959183675, clip_score: 27.93665885925293, chairf: 0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["results_df = pd.DataFrame(val_results)\n","\n","average_spice = results_df[\"spice_score\"].mean()\n","average_clip_score = results_df[\"clip_score\"].mean()\n","average_chairf = results_df[\"chairf\"].mean()\n","\n","print(f\"Average SPICE Score: {average_spice:.4f}\")\n","print(f\"Average CLIPScore: {average_clip_score:.4f}\")\n","print(f\"Average CHAIRf Score: {average_chairf:.4f}\")\n","\n","def calculate_custom_score(spice_score, clip_score, chairf):\n","    custom_score = (0.4 * spice_score) + (0.2 * (clip_score / 250)) + (0.4 * chairf)\n","    return custom_score\n","\n","results_df[\"custom_score\"] = results_df.apply(\n","    lambda row: calculate_custom_score(\n","        row[\"spice_score\"], row[\"clip_score\"], row[\"chairf\"]\n","    ), axis=1\n",")\n","\n","average_custom_score = results_df[\"custom_score\"].mean()\n","print(f\"Average Custom Score: {average_custom_score:.4f}\")"],"metadata":{"id":"1_Xwr5PP6Rfp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731136179322,"user_tz":-540,"elapsed":22,"user":{"displayName":"서연우","userId":"17766624651891144537"}},"outputId":"cca41946-72d3-497a-caa1-bdbb9fa4c181"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Average SPICE Score: 0.1790\n","Average CLIPScore: 30.9230\n","Average CHAIRf Score: 0.4339\n","Average Custom Score: 0.2699\n"]}]},{"cell_type":"markdown","source":["## 11. 결과 저장 및 평균 점수 출력\n","평균 점수를 출력하고 결과를 CSV 파일로 저장하여 제출에 활용할 수 있도록 합니다."],"metadata":{"id":"78IFiqtTACTx"}},{"cell_type":"code","source":["submission_data = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Generating Captions\"):\n","        image_urls = batch['image_url']\n","        image_ids = batch['Image_ID']\n","\n","        images = []\n","        for image_url in image_urls:\n","            response = requests.get(image_url)\n","            image = Image.open(BytesIO(response.content)).convert('RGB')\n","            images.append(image)\n","\n","        inputs = processor(images=images, text=['Describe this image in detail.'] * len(images), return_tensors=\"pt\").to(device)\n","\n","        generated_ids = model.generate(**inputs,\n","                                       do_sample=True,\n","                                       num_beams=5,\n","                                       max_length=256,\n","                                       min_length=32,\n","                                       top_p=0.9,\n","                                       repetition_penalty=1.5,\n","                                       length_penalty=1.0,\n","                                       temperature=1)\n","\n","        generated_captions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n","        generated_captions = [caption.strip() for caption in generated_captions]\n","\n","        for image_id, generated_caption in zip(\n","            image_ids, generated_captions\n","        ):\n","            submission_data.append({\n","                \"Image_ID\": image_id,\n","                \"generated_caption\": generated_caption\n","            })"],"metadata":{"id":"w-xnmvaSuUqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_df = pd.DataFrame(submission_data)\n","submission_df.to_csv(\"submission.csv\", index=False)\n","\n","print(\"Submission file 'submission.csv' created successfully.\")"],"metadata":{"id":"ruhRNzz8kWDX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 예시 1 - 프롬프트 엔지니어링 (Prompt Engineering)"],"metadata":{"id":"YagIvs-L1eAQ"}},{"cell_type":"markdown","source":["## 1. 이미지 불러오기 및 전처리\n","주어진 이미지 URL을 통해 이미지를 불러오고, `processor`를 사용하여 모델의 입력 형식에 맞게 전처리합니다. 이 과정에서 이미지를 RGB로 변환하고, 입력 텐서를 생성하여 모델이 이해할 수 있도록 처리합니다."],"metadata":{"id":"6OzxBmFpAXPs"}},{"cell_type":"code","source":["img_url = 'https://storage.googleapis.com/sfr-vision-language-research/LAVIS/assets/merlion.png'\n","raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n","raw_image = raw_image.resize((596, 437))\n","display(raw_image)"],"metadata":{"id":"o4EDtfUaeCYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 빔 서치와 누클리어스 샘플링을 통한 캡션 생성"],"metadata":{"id":"wgIX-wmOAdfD"}},{"cell_type":"markdown","source":["### 빔 서치 (Beam Search)\n","빔 서치는 여러 후보 캡션 경로를 동시에 탐색하며 최적의 문장을 생성하는 방식입니다. `num_beams=5`로 설정해 5개의 경로를 탐색합니다. 이 방법은 높은 품질의 캡션을 생성하는 데 유리합니다."],"metadata":{"id":"q3P2NxKwAWKl"}},{"cell_type":"code","source":["inputs = processor(images=raw_image, text='Please describe this image briefly.', return_tensors=\"pt\").to(device)\n","generated_ids = model.generate(**inputs,\n","                               num_beams=5,\n","                               max_length=50)\n","generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n","print(f\"생성된 캡션 (빔 서치): {generated_text}\")"],"metadata":{"id":"pdZC-1z_eKDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 누클리어스 샘플링 (Nucleus Sampling)\n","누클리어스 샘플링은 특정 누적 확률 (top-p) 이하의 단어들 중에서만 다음 단어를 선택하는 방식입니다. `top_p=0.9`로 설정해, 상위 90% 확률에 해당하는 단어들 중에서만 다음 단어를 샘플링하여 다양한 문장 생성을 유도합니다."],"metadata":{"id":"4IevfhOpAjJL"}},{"cell_type":"code","source":["generated_sequences = []\n","for _ in range(3):\n","    generated_ids = model.generate(\n","        **inputs,\n","        do_sample=True,\n","        top_p=0.9,\n","        max_length=50\n","    )\n","    generated_sequences.append(generated_ids)\n","\n","print(\"생성된 캡션 (누클리어스 샘플링):\")\n","for i, generated_ids in enumerate(generated_sequences):\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n","    print(f\"캡션 {i + 1}: {generated_text}\")"],"metadata":{"id":"EA-10nVWeNNl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. 이미지 기반 Q&A\n","주어진 프롬프트와 함께 이미지를 입력으로 사용하여 질문에 대한 답변을 생성합니다. 프롬프트에 질문-응답 쌍을 기반으로 문맥을 생성하여, 모델이 문맥에 맞는 답변을 생성하도록 합니다."],"metadata":{"id":"v0UZ5jqoAo8T"}},{"cell_type":"code","source":["prompt = \"Question: which city is this? Answer: singapore. Question: why?\"\n","inputs = processor(\n","    images=raw_image,\n","    text=prompt,\n","    return_tensors=\"pt\"\n",").to(device)\n","\n","generated_ids = model.generate(**inputs, max_length=100)\n","generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n","print(f\"생성된 응답: {generated_text}\")"],"metadata":{"id":"3T3E1lqqePrV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. 프롬프트 확장 및 이미지 기반 질문 응답\n","문맥을 제공하여 모델이 좀 더 정교한 응답을 생성하도록 합니다. 여기서 주어진 질문-응답 쌍들을 바탕으로 프롬프트를 구성하고, 이어지는 질문에 대해 모델이 답변하도록 합니다."],"metadata":{"id":"GFR4uEEAAtLw"}},{"cell_type":"code","source":["context = [\n","    (\"which city is this?\", \"singapore\"),\n","    (\"why?\", \"it has a statue of a merlion\"),\n","]\n","question = \"where is the name merlion coming from?\"\n","template = \"Question: {} Answer: {}.\"\n","\n","prompt = \" \".join([template.format(q, a) for q, a in context]) + f\" Question: {question} Answer:\"\n","print(f\"프롬프트: {prompt}\")\n","\n","inputs = processor(\n","    images=raw_image,\n","    text=prompt,\n","    return_tensors=\"pt\"\n",").to(device)\n","\n","generated_ids = model.generate(**inputs, max_length=100)\n","generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n","print(f\"생성된 응답: {generated_text}\")"],"metadata":{"id":"z9xkWqe2eRxj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 예시 2 - 간단한 학습 자유 (training-free) 방법\n","\n","아래 예시는 참가자들의 training-free 방법론에 대한 이해를 돕고자 간단하게 구상한 것입니다. 실제로 효과가 검증이 되어 있지 않는 방법임을 참고하여 주시길 바랍니다. 여러분들의 창의적인 아이디어를 기대하고 있습니다!\n","\n","이 코드는 이미지 캡션 생성을 위해 `generate_with_boost` 함수를 사용해 이미지 및 텍스트 데이터를 처리하고, 다양한 성능 지표를 계산하여 평가합니다. 특히, 임베딩 벡터의 요소별로 평균을 기준으로 가중치를 조정하여 생성된 캡션의 품질에 영향을 줄 수 있습니다."],"metadata":{"id":"yquTWYVhqXhJ"}},{"cell_type":"markdown","source":["\n","\n","## 1. Boosted Embeddings 설정\n","### `generate_with_boost` 함수\n","이 함수는 모델의 임베딩 가중치를 조정하여 입력 텍스트에 대해 더 집중된 응답을 생성할 수 있도록 합니다. 임베딩 가중치는 전체 임베딩 벡터의 평균을 기준으로 증감되며, **평균보다 큰 값에는 `boost_factor`를 곱하고, 작은 값에는 나눕니다**. 이를 통해 특정 임베딩 벡터의 영향을 강조하거나 약화시킵니다.\n","\n","- `mean_embedding_value`는 임베딩 벡터의 평균값입니다.\n","- `torch.where`를 사용하여 **임베딩 벡터 요소가 평균보다 클 경우 `boost_factor`를 곱하고, 작을 경우 나눕니다**."],"metadata":{"id":"_4Qk15bsDzR8"}},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","\n","def generate_with_boost(model, inputs, boost_factor=1.5):\n","    with torch.no_grad():\n","        embeddings = model.get_input_embeddings()\n","        mean_embedding_value = embeddings.weight.mean()\n","\n","        boosted_embeddings_weight = torch.where(\n","            embeddings.weight > mean_embedding_value,\n","            embeddings.weight * boost_factor,\n","            embeddings.weight / boost_factor\n","        )\n","\n","        model.get_input_embeddings().weight.data = boosted_embeddings_weight\n","\n","        generated_ids = model.generate(**inputs,\n","                                do_sample=True,\n","                                num_beams=5,\n","                                max_length=256,\n","                                min_length=32,\n","                                top_p=0.9,\n","                                repetition_penalty=1.5,\n","                                length_penalty=1.0,\n","                                temperature=1)\n","        generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n","\n","    return generated_caption"],"metadata":{"id":"3Z-WFVnsqYUn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 데이터 처리 및 캡션 생성\n","이미지 데이터와 참조 캡션을 기반으로 이미지의 객체 정보를 추출하고, 이를 통해 **임베딩 가중치가 조정된 모델로 캡션을 생성**합니다. 결과 캡션과 성능 지표를 저장해 평가할 수 있도록 합니다."],"metadata":{"id":"R7qkKn0hEAvQ"}},{"cell_type":"code","source":["val_results = []\n","\n","with torch.no_grad():\n","    for idx, row in tqdm(val_df.iloc[:3].iterrows(), total=len(val_df.iloc[:3]), desc=\"Calculating SPICE, CLIPScore, and CHAIRf\"):\n","        image_url = row['url']\n","        image_id = row['Image_ID']\n","        reference_caption = row['Paragraph']\n","\n","        response = requests.get(image_url)\n","        image = Image.open(BytesIO(response.content)).convert('RGB')\n","        image_objects = extract_objects_from_caption(reference_caption, evaluation_objects)\n","\n","        inputs = processor(images=image, text='Describe this image in detail.', return_tensors=\"pt\").to(device)\n","        generated_caption = generate_with_boost(model, inputs, boost_factor=1.5)\n","        print(generated_caption)\n","\n","        spice_score, clip_score, chairf = calculate_metrics(\n","            image, generated_caption, reference_caption, image_objects\n","        )\n","\n","        val_results.append({\n","            \"Image_ID\": image_id,\n","            \"generated_caption\": generated_caption,\n","            \"reference_caption\": reference_caption,\n","            \"spice_score\": spice_score,\n","            \"clip_score\": clip_score,\n","            \"chairf\": chairf\n","        })"],"metadata":{"id":"t721_RcTukAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_df = pd.DataFrame(val_results)\n","\n","average_spice = results_df[\"spice_score\"].mean()\n","average_clip_score = results_df[\"clip_score\"].mean()\n","average_chairf = results_df[\"chairf\"].mean()\n","\n","print(f\"Average SPICE Score: {average_spice:.4f}\")\n","print(f\"Average CLIPScore: {average_clip_score:.4f}\")\n","print(f\"Average CHAIRf Score: {average_chairf:.4f}\")\n","\n","def calculate_custom_score(spice_score, clip_score, chairf):\n","    custom_score = (0.4 * spice_score) + (0.2 * (clip_score / 250)) + (0.4 * chairf)\n","    return custom_score\n","\n","results_df[\"custom_score\"] = results_df.apply(\n","    lambda row: calculate_custom_score(\n","        row[\"spice_score\"], row[\"clip_score\"], row[\"chairf\"]\n","    ), axis=1\n",")\n","\n","average_custom_score = results_df[\"custom_score\"].mean()\n","print(f\"Average Custom Score: {average_custom_score:.4f}\")"],"metadata":{"id":"cEYBMc2gsWUA","collapsed":true},"execution_count":null,"outputs":[]}]}